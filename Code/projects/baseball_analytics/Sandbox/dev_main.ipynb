{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01078c0e",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "37b6a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import pybaseball as pyb\n",
    "import pybaseball.cache # Ensure caching is imported\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "from datetime import date, timedelta\n",
    "from sqlalchemy.engine import Engine\n",
    "from sqlalchemy import text\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import WebDriverException, TimeoutException\n",
    "from rapidfuzz import process\n",
    "import re\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import pylahman\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891da24a",
   "metadata": {},
   "source": [
    "### Load environment and connect to the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f549c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Build the PostgreSQL connection string\n",
    "DB_URL = f\"postgresql://{os.environ['DB_USER']}:{os.environ['DB_PASS']}@{os.environ['DB_HOST']}:5432/{os.environ['DB_NAME']}\"\n",
    "\n",
    "# Create the engine object for connecting\n",
    "engine = create_engine(DB_URL)\n",
    "\n",
    "print(\"Database connection established.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b036bfa2",
   "metadata": {},
   "source": [
    "### Create dim_players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ccce45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_players(engine: Engine):   \n",
    "    try:\n",
    "        players_lahman = pylahman.People()\n",
    "        player_chadwick = pyb.chadwick_register()\n",
    "\n",
    "        # Join lahman and chadwick on key identifiers and bring all the columns from lahman\n",
    "        # Ignore if key_bbref is empty in chadwick\n",
    "        players_chadwick_clean = player_chadwick[player_chadwick['key_retro'].notna()]\n",
    "        players_lahman_clean   = players_lahman[players_lahman['retroID'].notna()]\n",
    "\n",
    "        players_df = pd.merge(\n",
    "            players_chadwick_clean,\n",
    "            players_lahman_clean,\n",
    "            left_on=['key_retro'],\n",
    "            right_on=['retroID'],\n",
    "            how='left',\n",
    "        )\n",
    "\n",
    "        # Remove unnecesary columns and drop them from the dataframe\n",
    "        cols_to_remove = ['retroID', 'bbrefID', 'mlb_played_first', 'mlb_played_last']\n",
    "        players_df = players_df.drop(columns= cols_to_remove)\n",
    "\n",
    "        # Rename the fields\n",
    "        rename_map = {\n",
    "            # IDs\n",
    "            \"key_mlbam\":     \"key_mlbam\",\n",
    "            \"key_retro\":     \"key_retro\",\n",
    "            \"key_bbref\":     \"key_bbref\",\n",
    "            \"key_fangraphs\": \"key_fangraphs\",\n",
    "            \"ID\":            \"id_lahman\",\n",
    "            \"playerID\":      \"player_id_lahman\",\n",
    "\n",
    "            # Names\n",
    "            \"name_last\":     \"last_name_chadwick\",\n",
    "            \"name_first\":    \"first_name_chadwick\",\n",
    "            \"nameLast\":      \"last_name_lahman\",\n",
    "            \"nameFirst\":     \"first_name_lahman\",\n",
    "            \"nameGiven\":     \"first_and_second_name_lahman\",\n",
    "\n",
    "            # Debut/Final game\n",
    "            \"debut\":         \"debut\",\n",
    "            \"finalGame\":     \"final_game\",\n",
    "\n",
    "            # Info\n",
    "            \"weight\":        \"weight\",\n",
    "            \"height\":        \"height\",\n",
    "            \"bats\":          \"bats\",\n",
    "            \"throws\":        \"throws\",\n",
    "\n",
    "            # Birth/Death\n",
    "            \"birthYear\":     \"birth_year\",\n",
    "            \"birthMonth\":    \"birth_month\",\n",
    "            \"birthDay\":      \"birth_day\",\n",
    "            \"birthCity\":     \"birth_city\",\n",
    "            \"birthCountry\":  \"birth_country\",\n",
    "            \"birthState\":    \"birth_state\",\n",
    "            \"deathYear\":     \"death_year\",\n",
    "            \"deathMonth\":    \"death_month\",\n",
    "            \"deathDay\":      \"death_day\",\n",
    "            \"deathCountry\":  \"death_country\",\n",
    "            \"deathState\":    \"death_state\",\n",
    "            \"deathCity\":     \"death_city\",\n",
    "        }\n",
    "\n",
    "        # Apply the rename\n",
    "        players_df = players_df.rename(columns= rename_map)\n",
    "\n",
    "        # Order the new columns\n",
    "        ordered_cols = [\n",
    "            \"key_mlbam\",\n",
    "            \"key_retro\",\n",
    "            \"key_bbref\",\n",
    "            \"key_fangraphs\",\n",
    "            \"id_lahman\",\n",
    "            \"player_id_lahman\",\n",
    "            \"last_name_chadwick\",\n",
    "            \"first_name_chadwick\",\n",
    "            \"last_name_lahman\",\n",
    "            \"first_name_lahman\",\n",
    "            \"first_and_second_name_lahman\",\n",
    "            \"debut\",\n",
    "            \"final_game\",\n",
    "            \"weight\",\n",
    "            \"height\",\n",
    "            \"bats\",\n",
    "            \"throws\",\n",
    "            \"birth_year\",\n",
    "            \"birth_month\",\n",
    "            \"birth_day\",\n",
    "            \"birth_city\",\n",
    "            \"birth_country\",\n",
    "            \"birth_state\",\n",
    "            \"death_year\",\n",
    "            \"death_month\",\n",
    "            \"death_day\",\n",
    "            \"death_country\",\n",
    "            \"death_state\",\n",
    "            \"death_city\"\n",
    "        ]\n",
    "\n",
    "        # Apply the order\n",
    "        players_df = players_df[ordered_cols]\n",
    "\n",
    "        # This selects only columns with numbers and fills their nulls with -1\n",
    "        numeric_cols = players_df.select_dtypes(include=['number']).columns\n",
    "        players_df[numeric_cols] = players_df[numeric_cols].fillna(-1)\n",
    "\n",
    "        # Replace nulls in the text columns\n",
    "        text_cols = [\n",
    "            \"key_retro\",\n",
    "            \"key_bbref\",\n",
    "            \"player_id_lahman\",\n",
    "            \"last_name_chadwick\",\n",
    "            \"first_name_chadwick\",\n",
    "            \"last_name_lahman\",\n",
    "            \"first_name_lahman\",\n",
    "            \"first_and_second_name_lahman\",\n",
    "            \"bats\",\n",
    "            \"throws\",\n",
    "            \"birth_city\",\n",
    "            \"birth_country\",\n",
    "            \"birth_state\",\n",
    "            \"death_country\",\n",
    "            \"death_state\",\n",
    "            \"death_city\"\n",
    "        ]\n",
    "\n",
    "        # Convert to a standard object type first and then fill the nulls with N/A\n",
    "        for col in text_cols:\n",
    "            players_df[col] = players_df[col].astype(object).fillna('N/A')\n",
    "            \n",
    "\n",
    "        # List the date columns\n",
    "        date_cols = [\n",
    "            \"debut\",\n",
    "            \"final_game\"\n",
    "        ]\n",
    "        # Fill null dates with January 1st, 1700\n",
    "        for col in date_cols:\n",
    "            players_df[col] = players_df[col].fillna(pd.Timestamp('1700-01-01'))\n",
    "\n",
    "        # Check for nulls in my table - there shouldn't be any\n",
    "        if (players_df.isnull().sum() == 0).all():\n",
    "            print(\"‚úÖ No nulls found.\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è WARNING - There are nulls in some columns in the dataframe.\")\n",
    "\n",
    "        # # --- STEP 5: LOADING ---\n",
    "        print(f\"Loading {len(players_df)} new rows into 'players'...\")\n",
    "        \n",
    "        players_df.to_sql(\n",
    "            'players', \n",
    "            engine, \n",
    "            if_exists='replace',\n",
    "            index=False, \n",
    "            chunksize=5000\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Players successfully added {len(players_df)} new rows of players data.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ETL Failed during extraction or loading: {e}\")\n",
    "        \n",
    "\n",
    "# Execute the players function\n",
    "update_players(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1195f56",
   "metadata": {},
   "source": [
    "### Create dim_franchises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebce9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_team_franchises(engine: Engine):\n",
    "    try:\n",
    "        # Import the franchises\n",
    "        #? Note: As of 2025-12-18 there is only data up to the 2024 season\n",
    "        team_franchises = pylahman.TeamsFranchises()\n",
    "        \n",
    "        # Data cleaning\n",
    "        # Identify all text columns\n",
    "        text_cols = team_franchises.select_dtypes(include=['object', 'string']).columns\n",
    "\n",
    "        # Convert to object first, then fill (since the columns are literal strings)\n",
    "        for col in text_cols:\n",
    "            # Converting to object allows 'N/A' to be treated as a normal string\n",
    "            team_franchises[col] = team_franchises[col].astype(object).fillna('N/A')\n",
    "            \n",
    "            # Just in case some were literal 'nan' strings:\n",
    "            team_franchises[col] = team_franchises[col].replace(['nan', 'None', '<NA>'], 'N/A')\n",
    "\n",
    "        # Final verification\n",
    "        null_count = team_franchises[text_cols].isnull().sum().sum()\n",
    "        if null_count == 0:\n",
    "            print(\"‚úÖ All string columns are clean. No nulls found!\")\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è Warning: {null_count} nulls still remain in text columns.\")\n",
    "            \n",
    "        \n",
    "        # Loading\n",
    "        print(f\"Loading {len(team_franchises)} new rows into 'team_franchises'...\")\n",
    "        \n",
    "        team_franchises.to_sql(\n",
    "            'team_franchises', \n",
    "            engine, \n",
    "            if_exists='replace',\n",
    "            index=False, \n",
    "            chunksize=5000\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Team franchises successfully added {len(team_franchises)} new rows of data.\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ETL Failed during extraction or loading: {e}\")\n",
    "\n",
    "        \n",
    "# Apply the function\n",
    "update_team_franchises(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b52b44",
   "metadata": {},
   "source": [
    "### Teams info ***NOT IN USE***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe940a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def update_team_info(engine: Engine):\n",
    "#     try:\n",
    "#         team_info = pylahman.Teams()\n",
    "\n",
    "#         # Identify all text columns\n",
    "#         text_cols = team_info.select_dtypes(include=['object', 'string']).columns\n",
    "\n",
    "#         # Convert to object first, then fill with N/A\n",
    "#         for col in text_cols:\n",
    "#             # Converting to object allows 'N/A' to be treated as a normal string\n",
    "#             team_info[col] = team_info[col].astype(object).fillna('N/A')\n",
    "            \n",
    "#             # Just in case some were literal 'nan' strings:\n",
    "#             team_info[col] = team_info[col].replace(['nan', 'None', '<NA>'], 'N/A')\n",
    "\n",
    "#         # This selects only columns with numbers and fills their nulls with -1\n",
    "#         numeric_cols = team_info.select_dtypes(include=['number']).columns\n",
    "#         team_info[numeric_cols] = team_info[numeric_cols].fillna(-1)\n",
    "\n",
    "#         # Final verification\n",
    "#         null_count_text    = team_info[text_cols].isnull().sum().sum()\n",
    "#         null_count_numeric = team_info[numeric_cols].isnull().sum().sum()\n",
    "#         total_nulls        = null_count_text + null_count_numeric\n",
    "\n",
    "#         if total_nulls == 0:\n",
    "#             print(\"‚úÖ All columns are clean. No nulls found!\")\n",
    "#         else:\n",
    "#             print(f\"‚ö†Ô∏è Warning: {total_nulls} nulls still remain some columns.\")\n",
    "\n",
    "#         # Loading\n",
    "#         print(f\"Loading {len(team_info)} new rows into 'team_info'...\")\n",
    "        \n",
    "#         team_info.to_sql(\n",
    "#             'team_info', \n",
    "#             engine, \n",
    "#             if_exists='replace',\n",
    "#             index=False, \n",
    "#             chunksize=5000\n",
    "#         )\n",
    "        \n",
    "#         print(f\"‚úÖ Team information successfully added {len(team_info)} new rows of data.\")\n",
    "    \n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ùå ETL Failed during extraction or loading: {e}\")\n",
    "\n",
    "\n",
    "# # Apply the function\n",
    "# update_team_info(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f6532c",
   "metadata": {},
   "source": [
    "### Create fact_team_tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8153a255",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 330 new rows into 'team_info'...\n",
      "‚úÖ Team information successfully added 330 new rows of data.\n",
      "Loading 330 new rows into 'team_info'...\n",
      "‚úÖ Team information successfully added 330 new rows of data.\n",
      "Loading 330 new rows into 'team_info'...\n",
      "‚úÖ Team information successfully added 330 new rows of data.\n"
     ]
    }
   ],
   "source": [
    "def create_fact_team_tables(engine: Engine):    \n",
    "    def load_fact_team_tables(engine: Engine, df, category):\n",
    "        try:\n",
    "            table_name = 'fact_team_' + category\n",
    "            print(f\"üíæ Creating {table_name}...\")\n",
    "            \n",
    "            # Loading\n",
    "            print(f\"   üîÉ Loading {len(df)} rows...\")\n",
    "            \n",
    "            df.to_sql(\n",
    "                table_name, \n",
    "                engine, \n",
    "                if_exists='replace',\n",
    "                index=False, \n",
    "                chunksize=5000\n",
    "            )\n",
    "            \n",
    "            print(f\"   ‚úÖ Successfully added {len(df)} new rows of data.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå ETL Failed during extraction or loading: {e}\")\n",
    "\n",
    "    # Declare the years\n",
    "    current_year  = date.today().year\n",
    "    ten_years_ago = current_year - 10\n",
    "\n",
    "    # Import the team data for the last 10 years\n",
    "    fact_team_batting  = pyb.team_batting(ten_years_ago, current_year,  ind= 1, qual= 0)\n",
    "    fact_team_pitching = pyb.team_pitching(ten_years_ago, current_year,  ind= 1, qual= 0)\n",
    "    fact_team_fielding = pyb.team_fielding(ten_years_ago, current_year,  ind= 1, qual= 0)\n",
    "\n",
    "    # Apply the function\n",
    "    load_fact_team_tables(engine, fact_team_batting,  'batting')\n",
    "    load_fact_team_tables(engine, fact_team_pitching, 'pitching')\n",
    "    load_fact_team_tables(engine, fact_team_fielding, 'fielding')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9f0b3a",
   "metadata": {},
   "source": [
    "### Create fact_player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3719bb5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "      ‚¨áÔ∏è  IMPORTING BASEBALL STATS      \n",
      "             Please wait...             \n",
      "========================================\n",
      "\n",
      "üíæ Creating fact_player_batting...\n",
      "   üîÉ Loading 8673 rows...\n",
      "   ‚úÖ Successfully added 8673 new rows of data.\n",
      "üíæ Creating fact_player_pitching...\n",
      "   üîÉ Loading 5106 rows...\n",
      "   ‚úÖ Successfully added 5106 new rows of data.\n",
      "üíæ Creating fact_player_fielding...\n",
      "   üîÉ Loading 13553 rows...\n",
      "   ‚úÖ Successfully added 13553 new rows of data.\n",
      "üíæ Creating fact_player_running...\n",
      "   üîÉ Loading 3830 rows...\n",
      "   ‚úÖ Successfully added 3830 new rows of data.\n"
     ]
    }
   ],
   "source": [
    "def create_fact_player_tables(engine: Engine):    \n",
    "    def load_fact_player_tables(engine: Engine, df, category):\n",
    "        try:\n",
    "            table_name = 'fact_player_' + category\n",
    "            print(f\"üíæ Creating {table_name}...\")\n",
    "            \n",
    "            # Loading\n",
    "            print(f\"   üîÉ Loading {len(df)} rows...\")\n",
    "            \n",
    "            df.to_sql(\n",
    "                table_name, \n",
    "                engine, \n",
    "                if_exists='replace',\n",
    "                index=False, \n",
    "                chunksize=5000\n",
    "            )\n",
    "            \n",
    "            print(f\"   ‚úÖ Successfully added {len(df)} new rows of data.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå ETL Failed during extraction or loading: {e}\")\n",
    "\n",
    "    # Declare the years\n",
    "    current_year   = date.today().year\n",
    "    five_years_ago = current_year - 5\n",
    "\n",
    "    # Import the team data for the last 10 years\n",
    "    # print(\"\\n\" + \"=\"*40)\n",
    "    # print(f\"{'‚¨áÔ∏è  Importing player stats':^40}\")\n",
    "    # print(f\"{'Please wait...':^40}\")\n",
    "    # print(\"=\"*40 + \"\\n\")\n",
    "    print(\"‚¨áÔ∏è  Importing player stats... please wait\")\n",
    "    \n",
    "    fact_player_batting  = pyb.batting_stats(five_years_ago, current_year,  ind= 1, qual= 0)\n",
    "    fact_player_pitching = pyb.pitching_stats(five_years_ago, current_year,  ind= 1, qual= 0)\n",
    "    fact_player_fielding = pyb.fielding_stats(five_years_ago, current_year,  ind= 1, qual= 0)\n",
    "    \n",
    "    # Speed tables are by year - they do not include range\n",
    "    # Setup year range\n",
    "    #current_year = datetime.now().year\n",
    "    years = range(current_year - 9, current_year + 1) # Last 10 years including current\n",
    "\n",
    "    all_dfs = []\n",
    "\n",
    "    for year in years:\n",
    "        #print(f\"Fetching sprint speed for {year}...\")\n",
    "        try:\n",
    "            # Fetch data\n",
    "            df = pyb.statcast_sprint_speed(year, 50)\n",
    "            \n",
    "            # Adding the years\n",
    "            df['Season'] = year\n",
    "            \n",
    "            all_dfs.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Could not fetch data for {year}: {e}\")\n",
    "\n",
    "    # Combine everything into one fact table\n",
    "    fact_player_running = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "    # Apply the function\n",
    "    load_fact_player_tables(engine, fact_player_batting,  'batting')\n",
    "    load_fact_player_tables(engine, fact_player_pitching, 'pitching')\n",
    "    load_fact_player_tables(engine, fact_player_fielding, 'fielding')\n",
    "    load_fact_player_tables(engine, fact_player_running, 'running')\n",
    "    \n",
    "create_fact_player_tables(engine)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735c63be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Historical player stats - It has data from 1871 but it doesn't have last year (2025)\n",
    "player_batting_historical     = pylahman.Batting()\n",
    "player_pitching_historical    = pylahman.Pitching()\n",
    "player_fielding_historical    = pylahman.Fielding()\n",
    "player_appearances_historical = pylahman.Appearances()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216c652b",
   "metadata": {},
   "source": [
    "### Get scores last n days *NOT IN USE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ef12a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for all games played from 2025-12-17 to 2025-12-17...\n",
      "This is a large query, it may take a moment to complete\n",
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No games found between 2025-12-17 and 2025-12-17.\n",
      "Searching for all games played from 2025-12-11 to 2025-12-17...\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No games found between 2025-12-11 and 2025-12-17.\n",
      "Searching for all games played from 2025-12-03 to 2025-12-17...\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No games found between 2025-12-03 and 2025-12-17.\n",
      "Searching for all games played from 2025-11-18 to 2025-12-17...\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No games found between 2025-11-18 and 2025-12-17.\n",
      "Searching for all games played from 2025-10-19 to 2025-12-17...\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28/28 [00:03<00:00,  7.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully pulled 2970 pitch events.\n",
      "Searching for all games played from 2025-09-19 to 2025-12-17...\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "c:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\pybaseball\\statcast.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_data = pd.concat(dataframe_list, axis=0).convert_dtypes(convert_string=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 58/58 [00:04<00:00, 14.14it/s]\n",
      "c:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\pybaseball\\statcast.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_data = pd.concat(dataframe_list, axis=0).convert_dtypes(convert_string=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully pulled 53951 pitch events.\n"
     ]
    }
   ],
   "source": [
    "# def get_game_results_last_n_days(n_days=90):\n",
    "#     \"\"\"\n",
    "#     Pulls raw pitch-by-pitch data for all games played in the last 'n_days' \n",
    "#     and then extracts the final score for each game.\n",
    "#     \"\"\"\n",
    "#     today = date.today()\n",
    "    \n",
    "#     # 1. Calculate the start and end dates for the 90-day range\n",
    "#     end_date = today - timedelta(days=1)  # Search up to yesterday\n",
    "#     start_date = today - timedelta(days=n_days)\n",
    "    \n",
    "#     start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "#     end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "#     print(f\"Searching for all games played from {start_date_str} to {end_date_str}...\")\n",
    "\n",
    "#     try:\n",
    "#         # 2. Pull all pitch-by-pitch data in that range\n",
    "#         all_data_in_range = pyb.statcast(start_dt=start_date_str, end_dt=end_date_str)\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         print(f\"Error retrieving Statcast data: {e}\")\n",
    "#         return pd.DataFrame()\n",
    "\n",
    "#     if all_data_in_range.empty:\n",
    "#         print(f\"No games found between {start_date_str} and {end_date_str}.\")\n",
    "#         return pd.DataFrame()\n",
    "\n",
    "#     print(f\"Successfully pulled {len(all_data_in_range)} pitch events.\")\n",
    "\n",
    "#     # 3. Sort the data chronologically by game_pk, inning, etc.\n",
    "#     data_sorted = all_data_in_range.sort_values(\n",
    "#         by=['game_pk', 'inning', 'inning_topbot', 'at_bat_number', 'pitch_number'],\n",
    "#         ascending=True\n",
    "#     )\n",
    "\n",
    "#     # 4. Group by game_pk and take the last row (which contains the final score)\n",
    "#     final_events = data_sorted.groupby('game_pk').tail(1).reset_index(drop=True)\n",
    "    \n",
    "#     # 5. Extract and rename the relevant columns for the final scoreboard\n",
    "#     scoreboard = final_events[[\n",
    "#         'game_date', \n",
    "#         'home_team', \n",
    "#         'away_team', \n",
    "#         'home_score', \n",
    "#         'away_score'\n",
    "#     ]].copy()\n",
    "    \n",
    "#     scoreboard.rename(columns={\n",
    "#         'home_score': 'Home_Final_Score',\n",
    "#         'away_score': 'Away_Final_Score',\n",
    "#         'game_date': 'Date'\n",
    "#     }, inplace=True)\n",
    "    \n",
    "#     # 6. Determine the Winner\n",
    "#     scoreboard['Winner'] = scoreboard.apply(\n",
    "#         lambda row: row['home_team'] if row['Home_Final_Score'] > row['Away_Final_Score'] else row['away_team'],\n",
    "#         axis=1\n",
    "#     )\n",
    "#     scoreboard['Result'] = (\n",
    "#         scoreboard['Winner'] + ' wins ' + \n",
    "#         scoreboard['Home_Final_Score'].astype(str) + '-' + \n",
    "#         scoreboard['Away_Final_Score'].astype(str)\n",
    "#     )\n",
    "    \n",
    "#     return scoreboard[['Date', 'away_team', 'home_team', 'Away_Final_Score', 'Home_Final_Score', 'Winner', 'Result']]\n",
    "\n",
    "# # --- EXECUTION ---\n",
    "# results_yesterday_df    = get_game_results_last_n_days(n_days= 1)\n",
    "# results_last_7_days_df  = get_game_results_last_n_days(n_days= 7)\n",
    "# results_last_15_days_df = get_game_results_last_n_days(n_days= 15)\n",
    "# results_last_30_days_df = get_game_results_last_n_days(n_days= 30)\n",
    "# results_last_60_days_df = get_game_results_last_n_days(n_days= 60)\n",
    "# results_last_90_days_df = get_game_results_last_n_days(n_days= 90)\n",
    "\n",
    "\n",
    "# # if not results_last_90_days_df.empty:\n",
    "# #     print(f\"\\n--- Game Results from the Last 90 Days ({len(results_last_90_days_df)} Games Found) ---\")\n",
    "# #     print(results_last_90_days_df.tail(10)) # Print the last 10 games found\n",
    "# # else:\n",
    "# #     print(\"\\nNo games were found in the last 90 days.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba17fde4",
   "metadata": {},
   "source": [
    "### Create fact_statcast_pitches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab62df2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for all games played from 2025-09-19 to 2025-12-17...\n",
      "This is a large query, it may take a moment to complete\n",
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 58/58 [00:04<00:00, 13.99it/s]\n",
      "c:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\pybaseball\\statcast.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_data = pd.concat(dataframe_list, axis=0).convert_dtypes(convert_string=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully pulled 53951 pitch events.\n"
     ]
    }
   ],
   "source": [
    "def create_fact_statcast_events_pitch_by_pitch(engine: Engine, n_days= 90):\n",
    "    \"\"\"\n",
    "    Pulls raw pitch-by-pitch data for all games played in the last 'n_days' \n",
    "    and then extracts the final score for each game.\n",
    "    \"\"\"\n",
    "    def load_fact_statcast_events(engine: Engine, df):\n",
    "        try:\n",
    "            table_name = 'fact_statcast_pitches'\n",
    "            print(f\"üíæ Creating {table_name}...\")\n",
    "            \n",
    "            # Loading\n",
    "            print(f\"   üîÉ Loading {len(df)} rows...\")\n",
    "            \n",
    "            df.to_sql(\n",
    "                table_name, \n",
    "                engine, \n",
    "                if_exists='replace',\n",
    "                index=False, \n",
    "                chunksize=5000\n",
    "            )\n",
    "            \n",
    "            print(f\"   ‚úÖ Successfully added {len(df)} new rows of data.\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå ETL Failed during extraction or loading: {e}\")\n",
    "    \n",
    "    # Get today's date\n",
    "    today = date.today()\n",
    "\n",
    "    # Calculate the start and end dates for the n-day range\n",
    "    end_date = today - timedelta(days= 1)  # Search up to yesterday\n",
    "    start_date = today - timedelta(days= n_days)\n",
    "\n",
    "    start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "    end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    print(f\"Searching for all games played from {start_date_str} to {end_date_str}...\")\n",
    "\n",
    "    try:\n",
    "        # Pull all pitch-by-pitch data in that range\n",
    "        fact_statcast_pitches_last_n_days = pyb.statcast(start_dt= start_date_str, end_dt= end_date_str)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving Statcast data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    if fact_statcast_pitches_last_n_days.empty:\n",
    "        print(f\"No games found between {start_date_str} and {end_date_str}.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f\"Successfully pulled {len(fact_statcast_pitches_last_n_days)} pitch events for the last {n_days} days.\")\n",
    "\n",
    "    # def filter_days(df, days):\n",
    "    #     cutoff = today - timedelta(days=days)\n",
    "    #     # Convert 'Date' column to datetime objects if they aren't already\n",
    "    #     df['game_date'] = pd.to_datetime(df['game_date']).dt.date\n",
    "    #     return df[df['game_date'] >= cutoff]\n",
    "\n",
    "    # # Sub-df from the main one\n",
    "    # results_1_day_df   = filter_days(fact_statcast_pitches_last_90_days, 1)\n",
    "    # results_7_days_df  = filter_days(fact_statcast_pitches_last_90_days, 7)\n",
    "    # results_30_days_df = filter_days(fact_statcast_pitches_last_90_days, 30)\n",
    "\n",
    "    # Apply the function\n",
    "    load_fact_statcast_events(engine, fact_statcast_pitches_last_n_days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a30db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the max date in the fact_statcast_pitches\n",
    "def get_latest_date_from_db():\n",
    "    query = text(\"SELECT MAX(game_date) FROM fact_statcast_pitches\")\n",
    "    \n",
    "    with engine.connect() as conn:\n",
    "        result = conn.execute(query).scalar()\n",
    "        \n",
    "    return result\n",
    "\n",
    "# Execute and calculate fetch window\n",
    "last_date = get_latest_date_from_db()\n",
    "\n",
    "if last_date:\n",
    "    # I want to start fetching from the day AFTER the last recorded date\n",
    "    fetch_start = (last_date + timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    # Fetch up to yesterday\n",
    "    fetch_end = (date.today() - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    \n",
    "    if fetch_start <= fetch_end:\n",
    "        print(f\"üîÑ Last data was {last_date}. Fetching from {fetch_start} to {fetch_end}...\")\n",
    "        new_data = pyb.statcast(start_dt=fetch_start, end_dt=fetch_end)\n",
    "        new_data.to_sql('fact_statcast_pitches', engine, if_exists='append', index=False)\n",
    "    else:\n",
    "        print(\"‚úÖ Database is already up to date.\")\n",
    "else:\n",
    "    print(\"Empty table. You need to run an initial seed fetch.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "434f7f00",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d72a7b",
   "metadata": {},
   "source": [
    "### Splits by team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d7c36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def teams_split(split_type, clean_mode):\n",
    "    # Load the options\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")  # Optional: Run in headless mode\n",
    "    options.binary_location = \"C:\\\\Program Files\\\\BraveSoftware\\\\Brave-Browser\\\\Application\\\\brave.exe\"\n",
    "\n",
    "    # Define year\n",
    "    year = datetime.now().year\n",
    "    \n",
    "    # Set up the WebDriver\n",
    "    driver = webdriver.Chrome(options= options)  \n",
    "\n",
    "    if split_type == 'LHP' or split_type == 'RHP': # for LHP and RHP pitchers\n",
    "        driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=plato%7Cvs%20{split_type}%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    elif split_type == '7' or split_type == '14' or split_type == '28': # for the last 7, 14 and 28 days\n",
    "        driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=total%7CLast%20{split_type}%20days%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    elif split_type == 'RH' or split_type == 'LH': # for RH and LH Starters\n",
    "        driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=plato%7Cvs%20{split_type}%20Starter%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    elif split_type == 'Home' or split_type == 'Away': # for home and away games\n",
    "        driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=hmvis%7C{split_type}%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    elif split_type == 'first_batter_game':\n",
    "        driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=leado%7C1st%20Batter%20G%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    elif split_type == 'vs_power_pitcher':\n",
    "        driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=power%7Cvs.%20Power%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    elif split_type == 'vs_weak_pitcher':\n",
    "        driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=power%7Cvs.%20Finesse%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    # For each team:\n",
    "    elif split_type == 'ANA' or split_type == 'ARI' or split_type == 'ATL' or split_type == 'BAL' or split_type == 'BOS' \\\n",
    "        or split_type == 'CHC' or split_type == 'CHW' or split_type == 'CIN' or split_type == 'CLE' or split_type == 'COL' \\\n",
    "        or split_type == 'DET' or split_type == 'HOU' or split_type == 'KCR' or split_type == 'LAD' or split_type == 'FLA' \\\n",
    "        or split_type == 'MIL' or split_type == 'MIN' or split_type == 'NYM' or split_type == 'NYY' or split_type == 'OAK' \\\n",
    "        or split_type == 'PHI' or split_type == 'PIT' or split_type == 'SDP' or split_type == 'SEA' or split_type == 'SFG' \\\n",
    "        or split_type == 'STL' or split_type == 'TBD' or split_type == 'TEX' or split_type == 'TOR' or split_type == 'WSN':\n",
    "            driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=oppon%7C{split_type}%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    elif split_type == 'vs_less_than_500_WP':\n",
    "        driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=oppon%7CWP%20%3C%20.500%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    elif split_type == 'vs_greater_or_equal_than_500_WP':\n",
    "        driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=oppon%7CWP%20%3E%3D%20.500%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    \n",
    "    \n",
    "    # Name of the table\n",
    "    datatable_id = 'split1'\n",
    "\n",
    "    # Explicitly wait for the table element to load\n",
    "    datatable_xpath = f\"//table[@id='{datatable_id}']\"  # Update XPATH as needed\n",
    "    try:\n",
    "        WebDriverWait(driver, 60).until(\n",
    "            EC.presence_of_element_located((By.XPATH, datatable_xpath))\n",
    "        )\n",
    "        print(f\"{datatable_id} ({split_type}) table loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Table {datatable_id} did not load. Details: {e}\")\n",
    "        driver.quit()\n",
    "\n",
    "    # Wait for the load of the page\n",
    "    time.sleep(10)\n",
    "\n",
    "    # Locate the table\n",
    "    table_element = driver.find_element(By.XPATH, datatable_xpath)\n",
    "    text_content = table_element.text\n",
    "\n",
    "    # Process the table content\n",
    "    rows = text_content.split(\"\\n\")\n",
    "    table_data = [row.split(\"\\t\") for row in rows]\n",
    "\n",
    "    # Convert to dataframe\n",
    "    df = pd.DataFrame(table_data)\n",
    "    \n",
    "    # Close the WebDriver\n",
    "    driver.quit()    \n",
    "    \n",
    "    if clean_mode == 1:\n",
    "        # Remove 'Roe' exactly (case-sensitive)\n",
    "        df[0] = df[0].str.replace('Roe', '', regex=False)\n",
    "\n",
    "        # Remove last row\n",
    "        df = df.iloc[:-1]\n",
    "\n",
    "        # Split column from right using spaces\n",
    "        df = df[0].str.split(\" \", n= 30, expand=True)\n",
    "\n",
    "        # Set first row as header\n",
    "        df.columns = df.iloc[0]  # Assign first row as column names\n",
    "        df = df[1:].reset_index(drop=True)  # Remove first row and reset index\n",
    "\n",
    "        # Remove the last column\n",
    "        df = df.iloc[:, :-1]\n",
    "\n",
    "        # Rename last 3 columns\n",
    "        new_column_names = [\"BAbip\", \"tOPS+\", \"sOPS+\"]  # New names for last 3 columns\n",
    "        df.columns.values[-3:] = new_column_names  # Assign new names\n",
    "\n",
    "        # Remove the first column\n",
    "        df = df.iloc[:, 1:]\n",
    "    else:\n",
    "        # Remove 'Roe' and GS exactly (case-sensitive)\n",
    "        df[0] = df[0].str.replace('Roe', '', regex=False)\n",
    "        df[0] = df[0].str.replace('GS', '', regex=False)\n",
    "\n",
    "        # Remove last row\n",
    "        df = df.iloc[:-1]\n",
    "\n",
    "        # Remove rows where column 'A' contains 'Rk', but keep the first row\n",
    "        df = df[~((df.index > 0) & (df[0].str.contains('Rk', na=False)))]\n",
    "\n",
    "        # Split column from right using spaces\n",
    "        df = df[0].str.split(\" \", n= 30, expand=True)\n",
    "\n",
    "        # Set first row as header\n",
    "        df.columns = df.iloc[0]  # Assign first row as column names\n",
    "        df = df[1:].reset_index(drop=True)  # Remove first row and reset index\n",
    "\n",
    "        # Remove the first column\n",
    "        df = df.iloc[:, 1:]\n",
    "\n",
    "        # Remove the last 2 columns\n",
    "        df = df.iloc[:, :-2]\n",
    "\n",
    "        # New column names\n",
    "        new_column_names = ['Team', 'G', 'PA', 'AB', 'R', 'H', '2B', '3B', 'HR', 'RBI', 'SB',\n",
    "                            'CS', 'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS', 'TB', 'GDP', 'HBP', 'SH',\n",
    "                            'SF', 'IBB', 'ROE', 'BAbip', 'tOPS+', 'sOPS+']\n",
    "\n",
    "        # Rename all columns\n",
    "        df.columns = new_column_names\n",
    "\n",
    "    return df\n",
    "\n",
    "# Call the function to get the teams split data\n",
    "team_vs_lhp             = teams_split(split_type= 'LHP',  clean_mode= 0) # GS empty\n",
    "team_vs_rhp             = teams_split(split_type= 'RHP',  clean_mode= 0) # GS empty\n",
    "team_vs_lh_starters     = teams_split(split_type= 'LH',   clean_mode= 1)\n",
    "team_vs_rh_starters     = teams_split(split_type= 'RH',   clean_mode= 1)\n",
    "team_last_seven_days    = teams_split(split_type= '7',    clean_mode= 1)\n",
    "team_last_fourteen_days = teams_split(split_type= '14',   clean_mode= 1)\n",
    "team_last_28_days       = teams_split(split_type= '28',   clean_mode= 1)\n",
    "team_home_games         = teams_split(split_type= 'Home', clean_mode= 1)\n",
    "team_away_games         = teams_split(split_type= 'Away', clean_mode= 1)\n",
    "team_first_batter_game  = teams_split(split_type= 'first_batter_game', clean_mode= 0) # GS empty\n",
    "team_vs_power_pitcher   = teams_split(split_type= 'vs_power_pitcher',  clean_mode= 0) # GS empty\n",
    "team_vs_weak_pitcher    = teams_split(split_type= 'vs_weak_pitcher',   clean_mode= 0) # GS empty\n",
    "team_vs_power_team      = teams_split(split_type= 'vs_greater_or_equal_than_500_WP', clean_mode= 1)\n",
    "team_vs_weak_team       = teams_split(split_type= 'vs_less_than_500_WP',             clean_mode= 1)\n",
    "\n",
    "# # Direct matchups\n",
    "team_laa = teams_split(split_type= 'ANA', clean_mode= 1)\n",
    "team_ari = teams_split(split_type= 'ARI', clean_mode= 1)\n",
    "team_atl = teams_split(split_type= 'ATL', clean_mode= 1)\n",
    "team_bal = teams_split(split_type= 'BAL', clean_mode= 1)\n",
    "team_bos = teams_split(split_type= 'BOS', clean_mode= 1)\n",
    "team_chc = teams_split(split_type= 'CHC', clean_mode= 1)\n",
    "team_chw = teams_split(split_type= 'CHW', clean_mode= 1)\n",
    "team_cin = teams_split(split_type= 'CIN', clean_mode= 1)\n",
    "team_cle = teams_split(split_type= 'CLE', clean_mode= 1)\n",
    "team_col = teams_split(split_type= 'COL', clean_mode= 1)\n",
    "team_det = teams_split(split_type= 'DET', clean_mode= 1)\n",
    "team_hou = teams_split(split_type= 'HOU', clean_mode= 1)\n",
    "team_kcr = teams_split(split_type= 'KCR', clean_mode= 1)\n",
    "team_lad = teams_split(split_type= 'LAD', clean_mode= 1)\n",
    "team_mia = teams_split(split_type= 'FLA', clean_mode= 1) \n",
    "team_mil = teams_split(split_type= 'MIL', clean_mode= 1)\n",
    "team_min = teams_split(split_type= 'MIN', clean_mode= 1)\n",
    "team_nym = teams_split(split_type= 'NYM', clean_mode= 1)\n",
    "team_nyy = teams_split(split_type= 'NYY', clean_mode= 1)\n",
    "team_oak = teams_split(split_type= 'OAK', clean_mode= 1)\n",
    "team_phi = teams_split(split_type= 'PHI', clean_mode= 1)\n",
    "team_pit = teams_split(split_type= 'PIT', clean_mode= 1)\n",
    "team_sdp = teams_split(split_type= 'SDP', clean_mode= 1)\n",
    "team_sea = teams_split(split_type= 'SEA', clean_mode= 1)\n",
    "team_sfg = teams_split(split_type= 'SFG', clean_mode= 1)\n",
    "team_stl = teams_split(split_type= 'STL', clean_mode= 1)\n",
    "team_tbr = teams_split(split_type= 'TBD', clean_mode= 1)\n",
    "team_tex = teams_split(split_type= 'TEX', clean_mode= 1)\n",
    "team_tor = teams_split(split_type= 'TOR', clean_mode= 1)\n",
    "team_wsn = teams_split(split_type= 'WSN', clean_mode= 1)\n",
    "\n",
    "# Dictionary of dataframes for the teams\n",
    "dic_team = {\n",
    "    'LAA': team_laa,\n",
    "    'AZ':  team_ari,\n",
    "    'ATL': team_atl,\n",
    "    'BAL': team_bal,\n",
    "    'BOS': team_bos,\n",
    "    'CHC': team_chc,\n",
    "    'CHW': team_chw,\n",
    "    'CIN': team_cin,\n",
    "    'CLE': team_cle,\n",
    "    'COL': team_col,\n",
    "    'DET': team_det,\n",
    "    'HOU': team_hou,\n",
    "    'KC':  team_kcr,\n",
    "    'LAD': team_lad,\n",
    "    'MIA': team_mia,\n",
    "    'MIL': team_mil,\n",
    "    'MIN': team_min,\n",
    "    'NYM': team_nym,\n",
    "    'NYY': team_nyy,\n",
    "    'ATH': team_oak,\n",
    "    'PHI': team_phi,\n",
    "    'PIT': team_pit,\n",
    "    'SD':  team_sdp,\n",
    "    'SEA': team_sea,\n",
    "    'SF':  team_sfg,\n",
    "    'STL': team_stl,\n",
    "    'TB':  team_tbr,\n",
    "    'TEX': team_tex,\n",
    "    'TOR': team_tor,\n",
    "    'WSH': team_wsn   \n",
    "    }\n",
    "\n",
    "# Add an ID column with the dictionary key as the identifier\n",
    "for key, df in dic_team.items():\n",
    "    df['ID'] = key  # Assign the dictionary key as the ID\n",
    "\n",
    "# Concatenate all dataFrames in the dictionary\n",
    "direct_matches = pd.concat(dic_team.values(), ignore_index=True)  # Resets index\n",
    "\n",
    "dic_splits = {\n",
    "    'team_vs_lhp'        :team_vs_lhp,        \n",
    "    'team_vs_rhp'        :team_vs_rhp,\n",
    "    'team_vs_lh_starters':team_vs_lh_starters,\n",
    "    'team_vs_rh_starters':team_vs_rh_starters,\n",
    "    'team_last_seven_days':team_last_seven_days,\n",
    "    'team_last_fourteen_days':team_last_fourteen_days,\n",
    "    'team_last_28_days':team_last_28_days,\n",
    "    'team_home_games':team_home_games,\n",
    "    'team_away_games':team_away_games,\n",
    "    'team_first_batter_game':team_first_batter_game,\n",
    "    'team_vs_power_pitcher':team_vs_power_pitcher,\n",
    "    'team_vs_weak_pitcher':team_vs_weak_pitcher,\n",
    "    'team_vs_power_team':team_vs_power_team,\n",
    "    'team_vs_weak_team':team_vs_weak_team      \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d645a94",
   "metadata": {},
   "source": [
    "### Create batting_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "537925e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Scrape Job with Driver Reuse and Retry Logic...\n",
      "------------------------------\n",
      "[BAL - vs_LHP]: Table loaded successfully.\n",
      "SUCCESS: Appended 30 rows. Master DF size: 30\n",
      "[BAL - vs_RHP]: Table loaded successfully.\n",
      "SUCCESS: Appended 34 rows. Master DF size: 64\n",
      "[BAL - last_7_days]: Table loaded successfully.\n",
      "SUCCESS: Appended 15 rows. Master DF size: 79\n",
      "[BAL - last_14_days]: Table loaded successfully.\n",
      "SUCCESS: Appended 16 rows. Master DF size: 95\n",
      "[BAL - last_28_days]: Table loaded successfully.\n",
      "SUCCESS: Appended 18 rows. Master DF size: 113\n",
      "[BAL - home_games]: Table loaded successfully.\n",
      "SUCCESS: Appended 38 rows. Master DF size: 151\n",
      "[BAL - away_games]: Table loaded successfully.\n",
      "SUCCESS: Appended 37 rows. Master DF size: 188\n",
      "[BAL - vs_RH_Starters]: Table loaded successfully.\n",
      "SUCCESS: Appended 38 rows. Master DF size: 226\n",
      "[BAL - vs_LH_Starters]: Table loaded successfully.\n",
      "SUCCESS: Appended 38 rows. Master DF size: 264\n",
      "[BAL - 1st_Half]: Table loaded successfully.\n",
      "SUCCESS: Appended 34 rows. Master DF size: 298\n",
      "[BAL - 2nd_Half]: Table loaded successfully.\n",
      "SUCCESS: Appended 31 rows. Master DF size: 329\n",
      "[BAL - April_March]: Table loaded successfully.\n",
      "SUCCESS: Appended 17 rows. Master DF size: 346\n",
      "[BAL - June_Splits]: Table loaded successfully.\n",
      "SUCCESS: Appended 25 rows. Master DF size: 371\n",
      "[BAL - July_Splits]: Table loaded successfully.\n",
      "SUCCESS: Appended 18 rows. Master DF size: 389\n",
      "[BAL - August_Splits]: Table loaded successfully.\n",
      "SUCCESS: Appended 23 rows. Master DF size: 412\n",
      "[BAL - Sept_Oct_Splits]: Table loaded successfully.\n",
      "SUCCESS: Appended 18 rows. Master DF size: 430\n",
      "[BAL - C_Position]: Table loaded successfully.\n",
      "SUCCESS: Appended 7 rows. Master DF size: 437\n",
      "[BAL - 1B_Position]: Table loaded successfully.\n",
      "SUCCESS: Appended 6 rows. Master DF size: 443\n",
      "[BAL - 2B_Position]: Table loaded successfully.\n",
      "SUCCESS: Appended 6 rows. Master DF size: 449\n",
      "[BAL - 3B_Position]: Table loaded successfully.\n",
      "SUCCESS: Appended 7 rows. Master DF size: 456\n",
      "[BAL - SS_Position]: Table loaded successfully.\n",
      "SUCCESS: Appended 4 rows. Master DF size: 460\n",
      "[BAL - LF_Position]: Table loaded successfully.\n",
      "SUCCESS: Appended 10 rows. Master DF size: 470\n",
      "[BAL - CF_Position]: Table loaded successfully.\n",
      "SUCCESS: Appended 9 rows. Master DF size: 479\n",
      "[BAL - RF_Position]: Table loaded successfully.\n",
      "SUCCESS: Appended 12 rows. Master DF size: 491\n",
      "[BAL - DH_Position]: Table loaded successfully.\n",
      "SUCCESS: Appended 21 rows. Master DF size: 512\n",
      "[BAL - PH_Position]: Table loaded successfully.\n",
      "SUCCESS: Appended 28 rows. Master DF size: 540\n",
      "[BAL - First_Batter_Game]: Table loaded successfully.\n",
      "SUCCESS: Appended 10 rows. Master DF size: 550\n",
      "[BAL - First_Batter_Inning]: Table loaded successfully.\n",
      "SUCCESS: Appended 32 rows. Master DF size: 582\n",
      "[BAL - Batting_1st]: Table loaded successfully.\n",
      "SUCCESS: Appended 13 rows. Master DF size: 595\n",
      "[BAL - Batting_2nd]: Table loaded successfully.\n",
      "SUCCESS: Appended 20 rows. Master DF size: 615\n",
      "[BAL - Batting_3rd]: Table loaded successfully.\n",
      "SUCCESS: Appended 12 rows. Master DF size: 627\n",
      "[BAL - Batting_4th]: Table loaded successfully.\n",
      "SUCCESS: Appended 20 rows. Master DF size: 647\n",
      "[BAL - Batting_5th]: Table loaded successfully.\n",
      "SUCCESS: Appended 25 rows. Master DF size: 672\n",
      "[BAL - Batting_6th]: Table loaded successfully.\n",
      "SUCCESS: Appended 25 rows. Master DF size: 697\n",
      "[BAL - Batting_7th]: Table loaded successfully.\n",
      "SUCCESS: Appended 25 rows. Master DF size: 722\n",
      "[BAL - Batting_8th]: Table loaded successfully.\n",
      "SUCCESS: Appended 27 rows. Master DF size: 749\n",
      "[BAL - Batting_9th]: Table loaded successfully.\n",
      "SUCCESS: Appended 38 rows. Master DF size: 787\n",
      "[BAL - in_the_lineup_1-3rd]: Table loaded successfully.\n",
      "SUCCESS: Appended 30 rows. Master DF size: 817\n",
      "[BAL - in_the_lineup_4-6th]: Table loaded successfully.\n",
      "SUCCESS: Appended 31 rows. Master DF size: 848\n",
      "[BAL - in_the_lineup_7-9th]: Table loaded successfully.\n",
      "SUCCESS: Appended 34 rows. Master DF size: 882\n",
      "[BAL - vs_SP]: Table loaded successfully.\n",
      "SUCCESS: Appended 32 rows. Master DF size: 914\n",
      "[BAL - vs_RP]: Table loaded successfully.\n",
      "SUCCESS: Appended 34 rows. Master DF size: 948\n",
      "[BAL - vs_Power_Pitchers]: Table loaded successfully.\n",
      "SUCCESS: Appended 31 rows. Master DF size: 979\n",
      "[BAL - vs_Finesse_Pitchers]: Table loaded successfully.\n",
      "SUCCESS: Appended 34 rows. Master DF size: 1013\n",
      "[BAL - batting_vs_ANA]: Table loaded successfully.\n",
      "SUCCESS: Appended 18 rows. Master DF size: 1031\n",
      "[BAL - batting_vs_ARI]: Table loaded successfully.\n",
      "SUCCESS: Appended 13 rows. Master DF size: 1044\n",
      "[BAL - batting_vs_ATL]: Table loaded successfully.\n",
      "SUCCESS: Appended 12 rows. Master DF size: 1056\n",
      "[BAL - batting_vs_BAL]: Table loaded successfully.\n",
      "RETRYING: Attempt 1/3 for BAL - batting_vs_BAL...\n",
      "[BAL - batting_vs_BAL]: Table loaded successfully.\n",
      "RETRYING: Attempt 2/3 for BAL - batting_vs_BAL...\n",
      "[BAL - batting_vs_BAL]: Table loaded successfully.\n",
      "RETRYING: Attempt 3/3 for BAL - batting_vs_BAL...\n",
      "Skipping BAL - batting_vs_BAL after 3 failed attempts.\n",
      "[BAL - batting_vs_BOS]: Table loaded successfully.\n",
      "SUCCESS: Appended 25 rows. Master DF size: 1081\n",
      "[BAL - batting_vs_CHC]: Table loaded successfully.\n",
      "SUCCESS: Appended 15 rows. Master DF size: 1096\n",
      "[BAL - batting_vs_CHW]: Table loaded successfully.\n",
      "SUCCESS: Appended 22 rows. Master DF size: 1118\n",
      "[BAL - batting_vs_CIN]: Table loaded successfully.\n",
      "SUCCESS: Appended 13 rows. Master DF size: 1131\n",
      "[BAL - batting_vs_CLE]: Table loaded successfully.\n",
      "SUCCESS: Appended 18 rows. Master DF size: 1149\n",
      "[BAL - batting_vs_COL]: Table loaded successfully.\n",
      "SUCCESS: Appended 13 rows. Master DF size: 1162\n",
      "[BAL - batting_vs_DET]: Table loaded successfully.\n",
      "SUCCESS: Appended 15 rows. Master DF size: 1177\n",
      "[BAL - batting_vs_HOU]: Table loaded successfully.\n",
      "SUCCESS: Appended 16 rows. Master DF size: 1193\n",
      "[BAL - batting_vs_KCR]: Table loaded successfully.\n",
      "SUCCESS: Appended 18 rows. Master DF size: 1211\n",
      "[BAL - batting_vs_LAD]: Table loaded successfully.\n",
      "SUCCESS: Appended 14 rows. Master DF size: 1225\n",
      "[BAL - batting_vs_FLA]: Table loaded successfully.\n",
      "SUCCESS: Appended 14 rows. Master DF size: 1239\n",
      "[BAL - batting_vs_MIL]: Table loaded successfully.\n",
      "SUCCESS: Appended 13 rows. Master DF size: 1252\n",
      "[BAL - batting_vs_MIN]: Table loaded successfully.\n",
      "SUCCESS: Appended 15 rows. Master DF size: 1267\n",
      "[BAL - batting_vs_NYM]: Table loaded successfully.\n",
      "SUCCESS: Appended 13 rows. Master DF size: 1280\n",
      "[BAL - batting_vs_NYY]: Table loaded successfully.\n",
      "SUCCESS: Appended 23 rows. Master DF size: 1303\n",
      "[BAL - batting_vs_OAK]: Table loaded successfully.\n",
      "SUCCESS: Appended 21 rows. Master DF size: 1324\n",
      "[BAL - batting_vs_PHI]: Table loaded successfully.\n",
      "SUCCESS: Appended 13 rows. Master DF size: 1337\n",
      "[BAL - batting_vs_PIT]: Table loaded successfully.\n",
      "SUCCESS: Appended 15 rows. Master DF size: 1352\n",
      "[BAL - batting_vs_SDP]: Table loaded successfully.\n",
      "SUCCESS: Appended 13 rows. Master DF size: 1365\n",
      "[BAL - batting_vs_SEA]: Table loaded successfully.\n",
      "SUCCESS: Appended 20 rows. Master DF size: 1385\n",
      "[BAL - batting_vs_SFG]: Table loaded successfully.\n",
      "SUCCESS: Appended 12 rows. Master DF size: 1397\n",
      "[BAL - batting_vs_STL]: Table loaded successfully.\n",
      "SUCCESS: Appended 13 rows. Master DF size: 1410\n",
      "[BAL - batting_vs_TBD]: Table loaded successfully.\n",
      "SUCCESS: Appended 22 rows. Master DF size: 1432\n",
      "[BAL - batting_vs_TEX]: Table loaded successfully.\n",
      "SUCCESS: Appended 21 rows. Master DF size: 1453\n",
      "[BAL - batting_vs_TOR]: Table loaded successfully.\n",
      "SUCCESS: Appended 22 rows. Master DF size: 1475\n",
      "[BAL - batting_vs_WSN]: Table loaded successfully.\n",
      "SUCCESS: Appended 18 rows. Master DF size: 1493\n",
      "[BAL - batting_Day_Games]: Table loaded successfully.\n",
      "SUCCESS: Appended 40 rows. Master DF size: 1533\n",
      "[BAL - batting_Night_Games]: Table loaded successfully.\n",
      "SUCCESS: Appended 37 rows. Master DF size: 1570\n",
      "[BAL - batting_Grass_Field_Games]: Table loaded successfully.\n",
      "SUCCESS: Appended 41 rows. Master DF size: 1611\n",
      "[BAL - batting_Artificial_Turf_Games]: Table loaded successfully.\n",
      "SUCCESS: Appended 30 rows. Master DF size: 1641\n",
      "------------------------------\n",
      "All tasks finished. Quitting driver.\n",
      "Scraping Complete.\n",
      "Final DataFrame Shape: (1641, 33)\n"
     ]
    }
   ],
   "source": [
    "YEAR = 2025\n",
    "DATATABLE_ID = 'team_split1' \n",
    "MAX_RETRIES = 3 \n",
    "\n",
    "# 2. Define the lists for iteration\n",
    "team_abbreviations = ['BAL']\n",
    "split_parameters = [\n",
    "    {'type': 'LHP',            'desc': 'vs_LHP'},\n",
    "    {'type': 'RHP',            'desc': 'vs_RHP'},\n",
    "    {'type': '7',              'desc': 'last_7_days'},\n",
    "    {'type': '14',             'desc': 'last_14_days'},\n",
    "    {'type': '28',             'desc': 'last_28_days'},\n",
    "    {'type': 'Home',           'desc': 'home_games'},\n",
    "    {'type': 'Away',           'desc': 'away_games'},\n",
    "    {'type': 'RH',             'desc': 'vs_RH_Starters'},\n",
    "    {'type': 'LH',             'desc': 'vs_LH_Starters'},\n",
    "    {'type': '1st',            'desc': '1st_Half'},\n",
    "    {'type': '2nd',            'desc': '2nd_Half'},\n",
    "    {'type': 'April%2FMarch',  'desc': 'April_March'},\n",
    "    {'type': 'June',           'desc': 'June_Splits'},\n",
    "    {'type': 'July',           'desc': 'July_Splits'},\n",
    "    {'type': 'August',         'desc': 'August_Splits'},\n",
    "    {'type': 'Sept%2FOct',     'desc': 'Sept_Oct_Splits'},\n",
    "    {'type': 'C',              'desc':'C_Position'},\n",
    "    {'type': '1B',             'desc': '1B_Position'},\n",
    "    {'type': '2B',             'desc': '2B_Position'},\n",
    "    {'type': '3B',             'desc': '3B_Position'},\n",
    "    {'type': 'SS',             'desc': 'SS_Position'},\n",
    "    {'type': 'LF',             'desc': 'LF_Position'},\n",
    "    {'type': 'CF',             'desc': 'CF_Position'},\n",
    "    {'type': 'RF',             'desc': 'RF_Position'},\n",
    "    {'type': 'DH',             'desc': 'DH_Position'},\n",
    "    {'type': 'PH',             'desc': 'PH_Position'},\n",
    "    {'type': '1st%20Batter',   'desc': 'First_Batter_Game'},\n",
    "    {'type': 'Leadoff%20Inn.', 'desc': 'First_Batter_Inning'},\n",
    "    {'type': 'Batting%201st',  'desc': 'Batting_1st'},\n",
    "    {'type': 'Batting%202nd',  'desc': 'Batting_2nd'},\n",
    "    {'type': 'Batting%203rd',  'desc': 'Batting_3rd'},\n",
    "    {'type': 'Batting%204th',  'desc': 'Batting_4th'},\n",
    "    {'type': 'Batting%205th',  'desc': 'Batting_5th'},\n",
    "    {'type': 'Batting%206th',  'desc': 'Batting_6th'},\n",
    "    {'type': 'Batting%207th',  'desc': 'Batting_7th'},\n",
    "    {'type': 'Batting%208th',  'desc': 'Batting_8th'},\n",
    "    {'type': 'Batting%209th',  'desc': 'Batting_9th'},\n",
    "    {'type': '1-3',            'desc': 'in_the_lineup_1-3rd'},\n",
    "    {'type': '4-6',            'desc': 'in_the_lineup_4-6th'},\n",
    "    {'type': '7-9',            'desc': 'in_the_lineup_7-9th'},\n",
    "    {'type': 'SP',             'desc': 'vs_SP'},\n",
    "    {'type': 'RP',             'desc': 'vs_RP'},\n",
    "    {'type': 'Power',          'desc': 'vs_Power_Pitchers'},\n",
    "    {'type': 'Finesse',        'desc': 'vs_Finesse_Pitchers'},\n",
    "    {'type': 'ANA',            'desc': 'batting_vs_ANA'},\n",
    "    {'type': 'ARI',            'desc': 'batting_vs_ARI'},\n",
    "    {'type': 'ATL',            'desc': 'batting_vs_ATL'},\n",
    "    {'type': 'BAL',            'desc': 'batting_vs_BAL'},\n",
    "    {'type': 'BOS',            'desc': 'batting_vs_BOS'},\n",
    "    {'type': 'CHC',            'desc': 'batting_vs_CHC'},\n",
    "    {'type': 'CHW',            'desc': 'batting_vs_CHW'},\n",
    "    {'type': 'CIN',            'desc': 'batting_vs_CIN'},\n",
    "    {'type': 'CLE',            'desc': 'batting_vs_CLE'},\n",
    "    {'type': 'COL',            'desc': 'batting_vs_COL'},\n",
    "    {'type': 'DET',            'desc': 'batting_vs_DET'},\n",
    "    {'type': 'HOU',            'desc': 'batting_vs_HOU'},\n",
    "    {'type': 'KCR',            'desc': 'batting_vs_KCR'},\n",
    "    {'type': 'LAD',            'desc': 'batting_vs_LAD'},\n",
    "    {'type': 'FLA',            'desc': 'batting_vs_FLA'},\n",
    "    {'type': 'MIL',            'desc': 'batting_vs_MIL'},\n",
    "    {'type': 'MIN',            'desc': 'batting_vs_MIN'},\n",
    "    {'type': 'NYM',            'desc': 'batting_vs_NYM'},\n",
    "    {'type': 'NYY',            'desc': 'batting_vs_NYY'},\n",
    "    {'type': 'OAK',            'desc': 'batting_vs_OAK'},\n",
    "    {'type': 'PHI',            'desc': 'batting_vs_PHI'},\n",
    "    {'type': 'PIT',            'desc': 'batting_vs_PIT'},\n",
    "    {'type': 'SDP',            'desc': 'batting_vs_SDP'},\n",
    "    {'type': 'SEA',            'desc': 'batting_vs_SEA'},\n",
    "    {'type': 'SFG',            'desc': 'batting_vs_SFG'},\n",
    "    {'type': 'STL',            'desc': 'batting_vs_STL'},\n",
    "    {'type': 'TBD',            'desc': 'batting_vs_TBD'},\n",
    "    {'type': 'TEX',            'desc': 'batting_vs_TEX'},\n",
    "    {'type': 'TOR',            'desc': 'batting_vs_TOR'},\n",
    "    {'type': 'WSN',            'desc': 'batting_vs_WSN'},\n",
    "    {'type': 'Day',            'desc': 'batting_Day_Games'},\n",
    "    {'type': 'Night',          'desc': 'batting_Night_Games'},\n",
    "    {'type': 'Grass',          'desc': 'batting_Grass_Field_Games'},\n",
    "    {'type': 'Artif.%20Turf',  'desc': 'batting_Artificial_Turf_Games'}\n",
    "]\n",
    "\n",
    "# Helper function to initialize driver\n",
    "def initialize_driver():\n",
    "    \"\"\"Initializes and returns a new Selenium WebDriver instance.\"\"\"\n",
    "    options = Options()\n",
    "    #options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\") \n",
    "    options.add_argument(\"--headless=new\")\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\") # Use a recent, common User-Agent\n",
    "    # NOTE: Keep the path correct my Brave installation\n",
    "    options.binary_location = \"C:\\\\Program Files\\\\BraveSoftware\\\\Brave-Browser\\\\Application\\\\brave.exe\" \n",
    "    \n",
    "    # Attempt to start the driver with a timeout\n",
    "    try:\n",
    "        driver = webdriver.Chrome(options=options) \n",
    "        driver.set_page_load_timeout(60)\n",
    "        return driver\n",
    "    except Exception as e:\n",
    "        print(f\"FATAL: Could not initialize Chrome driver. Check Brave path and driver version. Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "#  batter_split function\n",
    "def batter_split(driver, split_type, team_abv, year, datatable_id, description):\n",
    "    \n",
    "    # --- URL CONSTRUCTION --- \n",
    "    if split_type == 'LHP' or split_type == 'RHP': # for LHP and RHP pitchers\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=plato%7Cvs%20{split_type}%7C{team_abv}%7C{year}%7Cbat%7CAB%7C\"\n",
    "    elif split_type == '7' or split_type == '14' or split_type == '28': # for the last 7, 14 and 28 days\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=total%7CLast%20{split_type}%20days%7C{team_abv}%7C{year}%7Cbat%7CAB%7C\"\n",
    "    elif split_type == 'RH' or split_type == 'LH': # for RH and LH Starters\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=plato%7Cvs%20{split_type}%20Starter%7C{team_abv}%7C{year}%7Cbat%7CAB%7C\"\n",
    "    elif split_type == 'Home' or split_type == 'Away': # for home and away games\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=hmvis%7C{split_type}%7C{team_abv}%7C{year}%7Cbat%7CAB%7C\"\n",
    "    elif split_type == '1st' or split_type == '2nd': # for 1st and 2nd half of the season\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=half%7C{split_type}%20Half%7C{team_abv}%7C{year}%7Cbat%7CAB%7C\"\n",
    "    elif split_type == 'April%2FMarch' or split_type == 'May' or split_type == 'June' \\\n",
    "        or split_type == 'July' or split_type == 'August' or split_type == 'Sept%2FOct': # for each month\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=month%7C{split_type}%7C{team_abv}%7C{year}%7Cbat%7CAB%7C\"\n",
    "    elif split_type == 'C' or split_type == '1B' or split_type == '2B' or split_type == '3B' \\\n",
    "        or split_type == 'SS' or split_type == 'LF' or split_type == 'CF' or split_type == 'RF' \\\n",
    "        or split_type == 'DH' or split_type == 'PH': # for each position\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=defp%7Cas%20{split_type}%7C{team_abv}%7C{year}%7Cbat%7CAB%7C\"\n",
    "    elif split_type == '1st%20Batter': # first batter of the game\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=leado%7C{split_type}%20G%7C{team_abv}%7C{year}%7Cbat%7CAB%7C\"\n",
    "    elif split_type == 'Leadoff%20Inn.': # first batter of the inning\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=leado%7C{split_type}%7C{team_abv}%7C{year}%7Cbat%7CAB%7C\"\n",
    "    elif split_type == 'Batting%201st' or split_type == 'Batting%202nd' or split_type == 'Batting%203rd' \\\n",
    "        or split_type == 'Batting%204th' or split_type == 'Batting%205th' or split_type == 'Batting%206th' \\\n",
    "        or split_type == 'Batting%207th' or split_type == 'Batting%208th' or split_type == 'Batting%209th': # for each spot in the lineup\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=lineu%7C{split_type}%7C{team_abv}%7C{year}%7Cbat%7CAB%7C\"\n",
    "    elif split_type == '1-3' or split_type == '4-6' or split_type == '7-9': # for each third of the lineup\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=innng%7CInnings%20{split_type}%7C{team_abv}%7C{year}%7Cbat%7CAB%7C\"\n",
    "    elif split_type == 'SP' or split_type == 'RP': # vs SP or RP\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=times%7Cvs.%20{split_type}%7C{team_abv}%7C{year}%7Cbat%7CAB%7C\"\n",
    "    elif split_type == 'Power' or split_type == 'avg.P%2FF' or split_type == 'Finesse':\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=power%7Cvs.%20{split_type}%7C{team_abv}%7C{year}%7Cbat%7CAB%7C\" \n",
    "    elif split_type == 'ANA' or split_type == 'ARI' or split_type == 'ATL' or split_type == 'BAL' or split_type == 'BOS' \\\n",
    "        or split_type == 'CHC' or split_type == 'CHW' or split_type == 'CIN' or split_type == 'CLE' or split_type == 'COL' \\\n",
    "        or split_type == 'DET' or split_type == 'HOU' or split_type == 'KCR' or split_type == 'LAD' or split_type == 'FLA' \\\n",
    "        or split_type == 'MIL' or split_type == 'MIN' or split_type == 'NYM' or split_type == 'NYY' or split_type == 'OAK' \\\n",
    "        or split_type == 'PHI' or split_type == 'PIT' or split_type == 'SDP' or split_type == 'SEA' or split_type == 'SFG' \\\n",
    "        or split_type == 'STL' or split_type == 'TBD' or split_type == 'TEX' or split_type == 'TOR' or split_type == 'WSN':\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=oppon%7C{split_type}%7C{team_abv}%7C{year}%7Cbat%7CAB%7C\"\n",
    "    elif split_type == 'Day' or split_type == 'Night' or split_type == 'Grass' or split_type == 'Artif.%20Turf':\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=stad%7C{split_type}%7C{team_abv}%7C{year}%7Cbat%7CAB%7C\"\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: Split type '{split_type}' not supported yet.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "    except TimeoutException:\n",
    "        print(f\"[{team_abv} - {description}]: Page load timed out (60s). Skipping or retrying...\")\n",
    "        return None # Let the main loop handle the retry/skip\n",
    "        \n",
    "    datatable_xpath = f\"//table[@id='{datatable_id}']\"\n",
    "    \n",
    "    # --- SCRAPING LOGIC --- \n",
    "    try:\n",
    "        # Wait up to 30 seconds for the table\n",
    "        WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.XPATH, datatable_xpath))\n",
    "        )\n",
    "        table_element = driver.find_element(By.XPATH, datatable_xpath)\n",
    "        print(f\"[{team_abv} - {description}]: Table loaded successfully.\")\n",
    "    except Exception:\n",
    "        # This catches both TimeoutException and NoSuchElementException\n",
    "        print(f\"[{team_abv} - {description}]: Table element not found after 30s. Check site content.\")\n",
    "        return None \n",
    "\n",
    "    # Extract the full HTML, wrap in StringIO, read with pandas\n",
    "    table_html = table_element.get_attribute('outerHTML')\n",
    "    html_string = StringIO(table_html)\n",
    "    \n",
    "    try:\n",
    "        tables = pd.read_html(html_string, flavor='lxml') \n",
    "    except Exception as e:\n",
    "        print(f\"[{team_abv} - {description}]: Error parsing HTML with pandas: {e}\")\n",
    "        return None\n",
    "\n",
    "    if not tables:\n",
    "        print(f\"[{team_abv} - {description}]: No tables found.\")\n",
    "        return None\n",
    "\n",
    "    # Create an explicit copy\n",
    "    df = tables[0].copy() \n",
    "    \n",
    "    # --- CLEANING LOGIC --- \n",
    "    df.columns = df.columns.str.strip()\n",
    "    df.columns = [re.sub(r'[^A-Za-z0-9_]+', '', col) for col in df.columns]\n",
    "\n",
    "    if 'Rk' in df.columns:\n",
    "        df = df[df['Rk'] != 'Rk']\n",
    "        \n",
    "    df = df.iloc[:-1] # Remove last row (Totals)\n",
    "    \n",
    "    df['description'] = description\n",
    "    df['team'] = team_abv\n",
    "    df['year'] = YEAR\n",
    "    \n",
    "    return df \n",
    "\n",
    "# Master loop with driver reuse and retry logic\n",
    "\n",
    "batting_splits = pd.DataFrame()\n",
    "driver = initialize_driver()\n",
    "\n",
    "if driver is None:\n",
    "    exit() # Stop if the driver failed to initialize\n",
    "\n",
    "print(\"Starting Scrape Job with Driver Reuse and Retry Logic...\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "try:\n",
    "    # Outer loop for teams\n",
    "    for team_abv in team_abbreviations:\n",
    "        # Inner loop for splits\n",
    "        for split in split_parameters:\n",
    "            \n",
    "            # Retry loop for failed connection/table load\n",
    "            for attempt in range(MAX_RETRIES):\n",
    "                try:\n",
    "                    # Check if the driver is still alive (by checking its current URL)\n",
    "                    driver.current_url \n",
    "                    \n",
    "                    new_df = batter_split(\n",
    "                        driver=driver,\n",
    "                        split_type=split['type'], \n",
    "                        team_abv=team_abv, \n",
    "                        year=YEAR, \n",
    "                        datatable_id=DATATABLE_ID, \n",
    "                        description=split['desc']\n",
    "                    )\n",
    "                    \n",
    "                    if new_df is not None and not new_df.empty:\n",
    "                        batting_splits = pd.concat([batting_splits, new_df], ignore_index=True)\n",
    "                        print(f\"SUCCESS: Appended {len(new_df)} rows. Master DF size: {len(batting_splits)}\")\n",
    "                        break # Break the retry loop on success\n",
    "                    \n",
    "                    # If new_df is None (due to TimeoutException/Table not found), retry\n",
    "                    print(f\"RETRYING: Attempt {attempt + 1}/{MAX_RETRIES} for {team_abv} - {split['desc']}...\")\n",
    "                    time.sleep(2) # Short wait before retry\n",
    "\n",
    "                except WebDriverException as e:\n",
    "                    # CRITICAL: Driver died (Connection refused/lost)\n",
    "                    print(f\"\\n[FATAL ERROR] Driver connection lost for {team_abv} - {split['desc']}. Restarting driver...\")\n",
    "                    \n",
    "                    # Clean up the old session\n",
    "                    try:\n",
    "                        driver.quit()\n",
    "                    except Exception:\n",
    "                        pass # Ignore errors on quitting a dead driver\n",
    "                    \n",
    "                    # Restart the driver\n",
    "                    driver = initialize_driver()\n",
    "                    if driver is None:\n",
    "                        # If restart fails, stop the whole script\n",
    "                        raise SystemExit(\"Driver restart failed. Terminating.\")\n",
    "                        \n",
    "                    time.sleep(5) # Longer wait after a fatal crash\n",
    "                    print(\"Driver successfully restarted. Retrying scrape.\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"[{team_abv} - {split['desc']}]: Unhandled error: {e}\")\n",
    "                    break # Break retry loop on unexpected failure\n",
    "\n",
    "            # Check if retry failed all attempts and the split was not appended\n",
    "            else: \n",
    "                print(f\"Skipping {team_abv} - {split['desc']} after {MAX_RETRIES} failed attempts.\")\n",
    "                \n",
    "finally:\n",
    "    # 3. CLEANUP: Quit the driver ONCE after all loops are finished\n",
    "    print(\"-\" * 30)\n",
    "    print(\"All tasks finished. Quitting driver.\")\n",
    "    if 'driver' in locals() and driver:\n",
    "        driver.quit() \n",
    "    \n",
    "print(\"Scraping Complete.\")\n",
    "print(f\"Final DataFrame Shape: {batting_splits.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0cd99b",
   "metadata": {},
   "source": [
    "### Pitching splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f0807c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "YEAR = 2025\n",
    "DATATABLE_ID = 'team_split1' \n",
    "MAX_RETRIES = 3 \n",
    "\n",
    "# 2. Define the lists for iteration\n",
    "team_abbreviations = ['BAL']\n",
    "split_parameters = [\n",
    "    {'type': 'LHB',                      'desc': 'vs_LHB'},\n",
    "    {'type': 'RHB',                      'desc': 'vs_RHB'},\n",
    "    {'type': '7',                        'desc': 'last_7_days'},\n",
    "    {'type': '14',                       'desc': 'last_14_days'},\n",
    "    {'type': '28',                       'desc': 'last_28_days'},\n",
    "    {'type': 'Home',                     'desc': 'home_games'},\n",
    "    {'type': 'Away',                     'desc': 'away_games'},\n",
    "    {'type': '1st',                      'desc': '1st_half'},\n",
    "    {'type': '2nd',                      'desc': '2nd_half'},\n",
    "    {'type': 'April%2FMarch',            'desc': 'april_march'},\n",
    "    {'type': 'June',                     'desc': 'june_splits'},\n",
    "    {'type': 'July',                     'desc': 'july_splits'},\n",
    "    {'type': 'August',                   'desc': 'august_splits'},\n",
    "    {'type': 'Sept%2FOct',               'desc': 'sept_oct_Splits'},\n",
    "    {'type': '1st%20Batter',             'desc': 'first_batter_game'},\n",
    "    {'type': 'Leadoff%20Inn.',           'desc': 'first_batter_inning'},\n",
    "    {'type': 'Batting%201st',            'desc': 'pitching_vs_1st'},\n",
    "    {'type': 'Batting%202nd',            'desc': 'pitching_vs_2nd'},\n",
    "    {'type': 'Batting%203rd',            'desc': 'pitching_vs_3rd'},\n",
    "    {'type': 'Batting%204th',            'desc': 'pitching_vs_4th'},\n",
    "    {'type': 'Batting%205th',            'desc': 'pitching_vs_5th'},\n",
    "    {'type': 'Batting%206th',            'desc': 'pitching_vs_6th'},\n",
    "    {'type': 'Batting%207th',            'desc': 'pitching_vs_7th'},\n",
    "    {'type': 'Batting%208th',            'desc': 'pitching_vs_8th'},\n",
    "    {'type': 'Batting%209th',            'desc': 'pitching_vs_9th'},\n",
    "    {'type': 'Starter',                  'desc': 'as_starter'},\n",
    "    {'type': 'Reliever',                 'desc': 'as_reliever'},\n",
    "    {'type': '0-2%20Runs',               'desc': 'run_support_0_2'},\n",
    "    {'type': '3-5%20Runs',               'desc': 'run_support_3_5'},\n",
    "    {'type': '6%2B%20Runs',              'desc': 'run_support_6_plus'},\n",
    "    {'type': 'Swung%20at%201st%20Pitch', 'desc': 'outcome_of_at_bat_when_swung_at_first_pitch'},\n",
    "    {'type': 'Took%201st%20Pitch',       'desc': 'outcome_of_at_bat_when_took_first_pitch'},\n",
    "    {'type': '0',                        'desc': '0_outs_in_the_inning'},\n",
    "    {'type': '1',                        'desc': '1_outs_in_the_inning'},\n",
    "    {'type': '2',                        'desc': '2_outs_in_the_inning'},\n",
    "    {'type': 'innng%7C1st',             'desc': 'pitching_in_1st_inning'},\n",
    "    {'type': 'innng%7C2nd',             'desc': 'pitching_in_2nd_inning'},\n",
    "    {'type': 'innng%7C3rd',             'desc': 'pitching_in_3rd_inning'},\n",
    "    {'type': 'innng%7C4th',             'desc': 'pitching_in_4th_inning'},\n",
    "    {'type': 'innng%7C5th',             'desc': 'pitching_in_5th_inning'},\n",
    "    {'type': 'innng%7C6th',             'desc': 'pitching_in_6th_inning'},\n",
    "    {'type': 'innng%7C7th',             'desc': 'pitching_in_7th_inning'},\n",
    "    {'type': 'innng%7C8th',             'desc': 'pitching_in_8th_inning'},\n",
    "    {'type': 'innng%7C9th',             'desc': 'pitching_in_9th_inning'},\n",
    "    {'type': 'ANA',                      'desc': 'pitching_vs_ANA'},\n",
    "    {'type': 'ARI',                      'desc': 'pitching_vs_ARI'},\n",
    "    {'type': 'ATL',                      'desc': 'pitching_vs_ATL'},\n",
    "    {'type': 'BAL',                      'desc': 'pitching_vs_BAL'},\n",
    "    {'type': 'BOS',                      'desc': 'pitching_vs_BOS'},\n",
    "    {'type': 'CHC',                      'desc': 'pitching_vs_CHC'},\n",
    "    {'type': 'CHW',                      'desc': 'pitching_vs_CHW'},\n",
    "    {'type': 'CIN',                      'desc': 'pitching_vs_CIN'},\n",
    "    {'type': 'CLE',                      'desc': 'pitching_vs_CLE'},\n",
    "    {'type': 'COL',                      'desc': 'pitching_vs_COL'},\n",
    "    {'type': 'DET',                      'desc': 'pitching_vs_DET'},\n",
    "    {'type': 'HOU',                      'desc': 'pitching_vs_HOU'},\n",
    "    {'type': 'KCR',                      'desc': 'pitching_vs_KCR'},\n",
    "    {'type': 'LAD',                      'desc': 'pitching_vs_LAD'},\n",
    "    {'type': 'FLA',                      'desc': 'pitching_vs_FLA'},\n",
    "    {'type': 'MIL',                      'desc': 'pitching_vs_MIL'},\n",
    "    {'type': 'MIN',                      'desc': 'pitching_vs_MIN'},\n",
    "    {'type': 'NYM',                      'desc': 'pitching_vs_NYM'},\n",
    "    {'type': 'NYY',                      'desc': 'pitching_vs_NYY'},\n",
    "    {'type': 'OAK',                      'desc': 'pitching_vs_OAK'},\n",
    "    {'type': 'PHI',                      'desc': 'pitching_vs_PHI'},\n",
    "    {'type': 'PIT',                      'desc': 'pitching_vs_PIT'},\n",
    "    {'type': 'SDP',                      'desc': 'pitching_vs_SDP'},\n",
    "    {'type': 'SEA',                      'desc': 'pitching_vs_SEA'},\n",
    "    {'type': 'SFG',                      'desc': 'pitching_vs_SFG'},\n",
    "    {'type': 'STL',                      'desc': 'pitching_vs_STL'},\n",
    "    {'type': 'TBD',                      'desc': 'pitching_vs_TBD'},\n",
    "    {'type': 'TEX',                      'desc': 'pitching_vs_TEX'},\n",
    "    {'type': 'TOR',                      'desc': 'pitching_vs_TOR'},\n",
    "    {'type': 'WSN',                      'desc': 'pitching_vs_WSN'},\n",
    "    {'type': 'Day',                      'desc': 'pitching_Day_Games'},\n",
    "    {'type': 'Night',                    'desc': 'pitching_Night_Games'},\n",
    "    {'type': 'Grass',                    'desc': 'pitching_Grass_Field_Games'},\n",
    "    {'type': 'Artif.%20Turf',            'desc': 'pitching_Artificial_Turf_Games'}\n",
    "]\n",
    "\n",
    "# Helper function to initialize driver\n",
    "def initialize_driver():\n",
    "    \"\"\"Initializes and returns a new Selenium WebDriver instance.\"\"\"\n",
    "    options = Options()\n",
    "    #options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\") \n",
    "    options.add_argument(\"--headless=new\")\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\") # Use a recent, common User-Agent\n",
    "    # NOTE: Keep the path correct my Brave installation\n",
    "    options.binary_location = \"C:\\\\Program Files\\\\BraveSoftware\\\\Brave-Browser\\\\Application\\\\brave.exe\" \n",
    "    \n",
    "    # Attempt to start the driver with a timeout\n",
    "    try:\n",
    "        driver = webdriver.Chrome(options=options) \n",
    "        driver.set_page_load_timeout(60)\n",
    "        return driver\n",
    "    except Exception as e:\n",
    "        print(f\"FATAL: Could not initialize Chrome driver. Check Brave path and driver version. Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "#  pitcher_split function\n",
    "def pitcher_split(driver, split_type, team_abv, year, datatable_id, description):\n",
    "\n",
    "    # --- URL CONSTRUCTION --- \n",
    "    if split_type == 'LHB' or split_type == 'RHB': # matchups vs LHB and RHB hitters\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=plato%7Cvs%20{split_type}%7C{team_abv}%7C{year}%7Cpitch%7CAB%7C\"\n",
    "    elif split_type == '7' or split_type == '14' or split_type == '28': # for the last 7, 14 and 28 days\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=total%7CLast%20{split_type}%20days%7C{team_abv}%7C{year}%7Cpitch%7CAB%7C\"\n",
    "    elif split_type == 'Home' or split_type == 'Away': # for home and away games\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=hmvis%7C{split_type}%7C{team_abv}%7C{year}%7Cpitch%7CAB%7C\"\n",
    "    elif split_type == '1st' or split_type == '2nd': # for 1st and 2nd half of the season\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=half%7C{split_type}%20Half%7C{team_abv}%7C{year}%7Cpitch%7CAB%7C\"\n",
    "    elif split_type == 'April%2FMarch' or split_type == 'May' or split_type == 'June' \\\n",
    "        or split_type == 'July' or split_type == 'August' or split_type == 'Sept%2FOct': # for each month\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=month%7C{split_type}%7C{team_abv}%7C{year}%7Cpitch%7CAB%7C\"\n",
    "    elif split_type == '1st%20Batter': # first batter of the game\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=leado%7C{split_type}%20G%7C{team_abv}%7C{year}%7Cpitch%7CAB%7C\"\n",
    "    elif split_type == 'Leadoff%20Inn.': # first batter of the inning\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=leado%7C{split_type}%7C{team_abv}%7C{year}%7Cpitch%7CAB%7C\"\n",
    "    elif split_type == 'Batting%201st' or split_type == 'Batting%202nd' or split_type == 'Batting%203rd' \\\n",
    "        or split_type == 'Batting%204th' or split_type == 'Batting%205th' or split_type == 'Batting%206th' \\\n",
    "        or split_type == 'Batting%207th' or split_type == 'Batting%208th' or split_type == 'Batting%209th': \n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=lineu%7C{split_type}%7C{team_abv}%7C{year}%7Cpitch%7CAB%7C\"\n",
    "    elif split_type == 'Starter' or split_type == 'Reliever':\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=sprel%7Cas%20{split_type}%7CT{team_abv}%7C{year}%7Cpitch%7CAB%7C\"\n",
    "    elif split_type == '0-2%20Runs' or split_type == '3-5%20Runs' or split_type == '6%2B%20Runs':\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=rs%7C{split_type}%20Scored%7C{team_abv}%7C{year}%7Cpitch%7CAB%7C\"\n",
    "    elif split_type == 'Swung%20at%201st%20Pitch' or split_type == 'Took%201st%20Pitch':\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=tkswg%7C{split_type}%7C{team_abv}%7C{year}%7Cpitch%7CAB%7C\"\n",
    "    elif split_type == '0' or split_type == '1' or split_type == '2':\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=outs%7C{split_type}%20outs%7C{team_abv}%7C{year}%7Cpitch%7CAB%7C\"\n",
    "    elif split_type == 'innng%7C1st' or split_type == 'innng%7C2nd' or split_type == 'innng%7C3rd' \\\n",
    "        or split_type == 'innng%7C4th' or split_type == 'innng%7C5th' or split_type == 'innng%7C6th' \\\n",
    "        or split_type == 'innng%7C7th' or split_type == 'innng%7C8th' or split_type == 'innng%7C9th':\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params={split_type}%20inning%7C{team_abv}%7C{year}%7Cpitch%7CAB%7C\"\n",
    "    elif split_type == 'ANA' or split_type == 'ARI' or split_type == 'ATL' or split_type == 'BAL' or split_type == 'BOS' \\\n",
    "        or split_type == 'CHC' or split_type == 'CHW' or split_type == 'CIN' or split_type == 'CLE' or split_type == 'COL' \\\n",
    "        or split_type == 'DET' or split_type == 'HOU' or split_type == 'KCR' or split_type == 'LAD' or split_type == 'FLA' \\\n",
    "        or split_type == 'MIL' or split_type == 'MIN' or split_type == 'NYM' or split_type == 'NYY' or split_type == 'OAK' \\\n",
    "        or split_type == 'PHI' or split_type == 'PIT' or split_type == 'SDP' or split_type == 'SEA' or split_type == 'SFG' \\\n",
    "        or split_type == 'STL' or split_type == 'TBD' or split_type == 'TEX' or split_type == 'TOR' or split_type == 'WSN':\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=oppon%7C{split_type}%7C{team_abv}%7C{year}%7Cpitch%7CAB%7C\"\n",
    "    elif split_type == 'Day' or split_type == 'Night' or split_type == 'Grass' or split_type == 'Artif.%20Turf':\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=stad%7C{split_type}%7C{team_abv}%7C{year}%7Cpitch%7CAB%7C\"\n",
    "    else:\n",
    "        print(f\"Error: Split type '{split_type}' not supported yet.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "    except TimeoutException:\n",
    "        print(f\"[{team_abv} - {description}]: Page load timed out (60s). Skipping or retrying...\")\n",
    "        return None # Let the main loop handle the retry/skip\n",
    "        \n",
    "    datatable_xpath = f\"//table[@id='{datatable_id}']\"\n",
    "    \n",
    "    # --- SCRAPING LOGIC --- \n",
    "    try:\n",
    "        # Wait up to 30 seconds for the table\n",
    "        WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.XPATH, datatable_xpath))\n",
    "        )\n",
    "        table_element = driver.find_element(By.XPATH, datatable_xpath)\n",
    "        print(f\"[{team_abv} - {description}]: Table loaded successfully.\")\n",
    "    except Exception:\n",
    "        # This catches both TimeoutException and NoSuchElementException\n",
    "        print(f\"[{team_abv} - {description}]: Table element not found after 30s. Check site content.\")\n",
    "        return None \n",
    "\n",
    "    # Extract the full HTML, wrap in StringIO, read with pandas\n",
    "    table_html = table_element.get_attribute('outerHTML')\n",
    "    html_string = StringIO(table_html)\n",
    "    \n",
    "    try:\n",
    "        tables = pd.read_html(html_string, flavor='lxml') \n",
    "    except Exception as e:\n",
    "        print(f\"[{team_abv} - {description}]: Error parsing HTML with pandas: {e}\")\n",
    "        return None\n",
    "\n",
    "    if not tables:\n",
    "        print(f\"[{team_abv} - {description}]: No tables found.\")\n",
    "        return None\n",
    "\n",
    "    # Create an explicit copy\n",
    "    df = tables[0].copy() \n",
    "    \n",
    "    # --- CLEANING LOGIC --- \n",
    "    df.columns = df.columns.str.strip()\n",
    "    df.columns = [re.sub(r'[^A-Za-z0-9_]+', '', col) for col in df.columns]\n",
    "\n",
    "    if 'Rk' in df.columns:\n",
    "        df = df[df['Rk'] != 'Rk']\n",
    "        \n",
    "    df = df.iloc[:-1] # Remove last row (Totals)\n",
    "    \n",
    "    df['description'] = description\n",
    "    df['team'] = team_abv\n",
    "    df['year'] = YEAR\n",
    "    \n",
    "    return df \n",
    "\n",
    "# Master loop with driver reuse and retry logic\n",
    "\n",
    "pitching_splits = pd.DataFrame()\n",
    "driver = initialize_driver()\n",
    "\n",
    "if driver is None:\n",
    "    exit() # Stop if the driver failed to initialize\n",
    "\n",
    "print(\"Starting Scrape Job with Driver Reuse and Retry Logic...\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "try:\n",
    "    # Outer loop for teams\n",
    "    for team_abv in team_abbreviations:\n",
    "        # Inner loop for splits\n",
    "        for split in split_parameters:\n",
    "            \n",
    "            # Retry loop for failed connection/table load\n",
    "            for attempt in range(MAX_RETRIES):\n",
    "                try:\n",
    "                    # Check if the driver is still alive (by checking its current URL)\n",
    "                    driver.current_url \n",
    "                    \n",
    "                    new_df = pitcher_split(\n",
    "                        driver=driver,\n",
    "                        split_type=split['type'], \n",
    "                        team_abv=team_abv, \n",
    "                        year=YEAR, \n",
    "                        datatable_id=DATATABLE_ID, \n",
    "                        description=split['desc']\n",
    "                    )\n",
    "                    \n",
    "                    if new_df is not None and not new_df.empty:\n",
    "                        pitching_splits = pd.concat([pitching_splits, new_df], ignore_index=True)\n",
    "                        print(f\"SUCCESS: Appended {len(new_df)} rows. Master DF size: {len(pitching_splits)}\")\n",
    "                        break # Break the retry loop on success\n",
    "                    \n",
    "                    # If new_df is None (due to TimeoutException/Table not found), retry\n",
    "                    print(f\"RETRYING: Attempt {attempt + 1}/{MAX_RETRIES} for {team_abv} - {split['desc']}...\")\n",
    "                    time.sleep(2) # Short wait before retry\n",
    "\n",
    "                except WebDriverException as e:\n",
    "                    # CRITICAL: Driver died (Connection refused/lost)\n",
    "                    print(f\"\\n[FATAL ERROR] Driver connection lost for {team_abv} - {split['desc']}. Restarting driver...\")\n",
    "                    \n",
    "                    # Clean up the old session\n",
    "                    try:\n",
    "                        driver.quit()\n",
    "                    except Exception:\n",
    "                        pass # Ignore errors on quitting a dead driver\n",
    "                    \n",
    "                    # Restart the driver\n",
    "                    driver = initialize_driver()\n",
    "                    if driver is None:\n",
    "                        # If restart fails, stop the whole script\n",
    "                        raise SystemExit(\"Driver restart failed. Terminating.\")\n",
    "                        \n",
    "                    time.sleep(5) # Longer wait after a fatal crash\n",
    "                    print(\"Driver successfully restarted. Retrying scrape.\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"[{team_abv} - {split['desc']}]: Unhandled error: {e}\")\n",
    "                    break # Break retry loop on unexpected failure\n",
    "\n",
    "            # Check if retry failed all attempts and the split was not appended\n",
    "            else: \n",
    "                print(f\"Skipping {team_abv} - {split['desc']} after {MAX_RETRIES} failed attempts.\")\n",
    "                \n",
    "finally:\n",
    "    # 3. CLEANUP: Quit the driver ONCE after all loops are finished\n",
    "    print(\"-\" * 30)\n",
    "    print(\"All tasks finished. Quitting driver.\")\n",
    "    if 'driver' in locals() and driver:\n",
    "        driver.quit() \n",
    "    \n",
    "print(\"Scraping Complete.\")\n",
    "print(f\"Final DataFrame Shape: {pitching_splits.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79ce458d",
   "metadata": {},
   "source": [
    "### Pitching splits - Game Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d309e78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CONFIGURATION ---\n",
    "YEAR = 2025\n",
    "DATATABLE_ID = 'team_split1' \n",
    "MAX_RETRIES = 3 \n",
    "\n",
    "# 2. Define the lists for iteration\n",
    "team_abbreviations = ['BAL']\n",
    "split_parameters = [\n",
    "    {'type': '7',                        'desc': 'last_7_days'},\n",
    "    {'type': '14',                       'desc': 'last_14_days'},\n",
    "    {'type': '28',                       'desc': 'last_28_days'},\n",
    "    {'type': 'Home',                     'desc': 'home_games'},\n",
    "    {'type': 'Away',                     'desc': 'away_games'},\n",
    "    {'type': '1st',                      'desc': '1st_half'},\n",
    "    {'type': '2nd',                      'desc': '2nd_half'},\n",
    "    {'type': 'April%2FMarch',            'desc': 'april_march'},\n",
    "    {'type': 'June',                     'desc': 'june_splits'},\n",
    "    {'type': 'July',                     'desc': 'july_splits'},\n",
    "    {'type': 'August',                   'desc': 'august_splits'},\n",
    "    {'type': 'Sept%2FOct',               'desc': 'sept_oct_Splits'},\n",
    "    {'type': 'Starter',                  'desc': 'as_starter'},\n",
    "    {'type': 'Reliever',                 'desc': 'as_reliever'},\n",
    "    {'type': '0-2%20Runs',               'desc': 'run_support_0_2'},\n",
    "    {'type': '3-5%20Runs',               'desc': 'run_support_3_5'},\n",
    "    {'type': '6%2B%20Runs',              'desc': 'run_support_6_plus'},\n",
    "    {'type': 'ANA',                      'desc': 'pitching_vs_ANA'},\n",
    "    {'type': 'ARI',                      'desc': 'pitching_vs_ARI'},\n",
    "    {'type': 'ATL',                      'desc': 'pitching_vs_ATL'},\n",
    "    {'type': 'BAL',                      'desc': 'pitching_vs_BAL'},\n",
    "    {'type': 'BOS',                      'desc': 'pitching_vs_BOS'},\n",
    "    {'type': 'CHC',                      'desc': 'pitching_vs_CHC'},\n",
    "    {'type': 'CHW',                      'desc': 'pitching_vs_CHW'},\n",
    "    {'type': 'CIN',                      'desc': 'pitching_vs_CIN'},\n",
    "    {'type': 'CLE',                      'desc': 'pitching_vs_CLE'},\n",
    "    {'type': 'COL',                      'desc': 'pitching_vs_COL'},\n",
    "    {'type': 'DET',                      'desc': 'pitching_vs_DET'},\n",
    "    {'type': 'HOU',                      'desc': 'pitching_vs_HOU'},\n",
    "    {'type': 'KCR',                      'desc': 'pitching_vs_KCR'},\n",
    "    {'type': 'LAD',                      'desc': 'pitching_vs_LAD'},\n",
    "    {'type': 'FLA',                      'desc': 'pitching_vs_FLA'},\n",
    "    {'type': 'MIL',                      'desc': 'pitching_vs_MIL'},\n",
    "    {'type': 'MIN',                      'desc': 'pitching_vs_MIN'},\n",
    "    {'type': 'NYM',                      'desc': 'pitching_vs_NYM'},\n",
    "    {'type': 'NYY',                      'desc': 'pitching_vs_NYY'},\n",
    "    {'type': 'OAK',                      'desc': 'pitching_vs_OAK'},\n",
    "    {'type': 'PHI',                      'desc': 'pitching_vs_PHI'},\n",
    "    {'type': 'PIT',                      'desc': 'pitching_vs_PIT'},\n",
    "    {'type': 'SDP',                      'desc': 'pitching_vs_SDP'},\n",
    "    {'type': 'SEA',                      'desc': 'pitching_vs_SEA'},\n",
    "    {'type': 'SFG',                      'desc': 'pitching_vs_SFG'},\n",
    "    {'type': 'STL',                      'desc': 'pitching_vs_STL'},\n",
    "    {'type': 'TBD',                      'desc': 'pitching_vs_TBD'},\n",
    "    {'type': 'TEX',                      'desc': 'pitching_vs_TEX'},\n",
    "    {'type': 'TOR',                      'desc': 'pitching_vs_TOR'},\n",
    "    {'type': 'WSN',                      'desc': 'pitching_vs_WSN'},\n",
    "    {'type': 'Day',                      'desc': 'pitching_Day_Games'},\n",
    "    {'type': 'Night',                    'desc': 'pitching_Night_Games'},\n",
    "    {'type': 'Grass',                    'desc': 'pitching_Grass_Field_Games'},\n",
    "    {'type': 'Artif.%20Turf',            'desc': 'pitching_Artificial_Turf_Games'}\n",
    "]\n",
    "\n",
    "# Helper function to initialize driver\n",
    "def initialize_driver():\n",
    "    \"\"\"Initializes and returns a new Selenium WebDriver instance.\"\"\"\n",
    "    options = Options()\n",
    "    #options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--disable-gpu\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\") \n",
    "    options.add_argument(\"--headless=new\")\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36\") # Use a recent, common User-Agent\n",
    "    # NOTE: Keep the path correct my Brave installation\n",
    "    options.binary_location = \"C:\\\\Program Files\\\\BraveSoftware\\\\Brave-Browser\\\\Application\\\\brave.exe\" \n",
    "    \n",
    "    # Attempt to start the driver with a timeout\n",
    "    try:\n",
    "        driver = webdriver.Chrome(options=options) \n",
    "        driver.set_page_load_timeout(60)\n",
    "        return driver\n",
    "    except Exception as e:\n",
    "        print(f\"FATAL: Could not initialize Chrome driver. Check Brave path and driver version. Error: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "#  pitcher_split function\n",
    "def pitcher_split_game_level(driver, split_type, team_abv, year, datatable_id, description):\n",
    "\n",
    "    # --- URL CONSTRUCTION --- \n",
    "    if split_type == 'LHB' or split_type == 'RHB': # matchups vs LHB and RHB hitters\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=plato%7Cvs%20{split_type}%7C{team_abv}%7C{year}%7Cpitch%7CIP%7C\"\n",
    "    elif split_type == '7' or split_type == '14' or split_type == '28': # for the last 7, 14 and 28 days\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=total%7CLast%20{split_type}%20days%7C{team_abv}%7C{year}%7Cpitch%7CIP%7C\"\n",
    "    elif split_type == 'Home' or split_type == 'Away': # for home and away games\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=hmvis%7C{split_type}%7C{team_abv}%7C{year}%7Cpitch%7CIP%7C\"\n",
    "    elif split_type == '1st' or split_type == '2nd': # for 1st and 2nd half of the season\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=half%7C{split_type}%20Half%7C{team_abv}%7C{year}%7Cpitch%7CIP%7C\"\n",
    "    elif split_type == 'April%2FMarch' or split_type == 'May' or split_type == 'June' \\\n",
    "        or split_type == 'July' or split_type == 'August' or split_type == 'Sept%2FOct': # for each month\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=month%7C{split_type}%7C{team_abv}%7C{year}%7Cpitch%7CIP%7C\"\n",
    "    elif split_type == '1st%20Batter': # first batter of the game\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=leado%7C{split_type}%20G%7C{team_abv}%7C{year}%7Cpitch%7CIP%7C\"\n",
    "    elif split_type == 'Leadoff%20Inn.': # first batter of the inning\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=leado%7C{split_type}%7C{team_abv}%7C{year}%7Cpitch%7CIP%7C\"\n",
    "    elif split_type == 'Batting%201st' or split_type == 'Batting%202nd' or split_type == 'Batting%203rd' \\\n",
    "        or split_type == 'Batting%204th' or split_type == 'Batting%205th' or split_type == 'Batting%206th' \\\n",
    "        or split_type == 'Batting%207th' or split_type == 'Batting%208th' or split_type == 'Batting%209th': \n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=lineu%7C{split_type}%7C{team_abv}%7C{year}%7Cpitch%7CIP%7C\"\n",
    "    elif split_type == 'Starter' or split_type == 'Reliever':\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=sprel%7Cas%20{split_type}%7CT{team_abv}%7C{year}%7Cpitch%7CIP%7C\"\n",
    "    elif split_type == '0-2%20Runs' or split_type == '3-5%20Runs' or split_type == '6%2B%20Runs':\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=rs%7C{split_type}%20Scored%7C{team_abv}%7C{year}%7Cpitch%7CIP%7C\"\n",
    "    elif split_type == 'Swung%20at%201st%20Pitch' or split_type == 'Took%201st%20Pitch':\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=tkswg%7C{split_type}%7C{team_abv}%7C{year}%7Cpitch%7CIP%7C\"\n",
    "    elif split_type == '0' or split_type == '1' or split_type == '2':\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=outs%7C{split_type}%20outs%7C{team_abv}%7C{year}%7Cpitch%7CIP%7C\"\n",
    "    elif split_type == 'innng%7C1st' or split_type == 'innng%7C2nd' or split_type == 'innng%7C3rd' \\\n",
    "        or split_type == 'innng%7C4th' or split_type == 'innng%7C5th' or split_type == 'innng%7C6th' \\\n",
    "        or split_type == 'innng%7C7th' or split_type == 'innng%7C8th' or split_type == 'innng%7C9th':\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params={split_type}%20inning%7C{team_abv}%7C{year}%7Cpitch%7CIP%7C\"\n",
    "    elif split_type == 'ANA' or split_type == 'ARI' or split_type == 'ATL' or split_type == 'BAL' or split_type == 'BOS' \\\n",
    "        or split_type == 'CHC' or split_type == 'CHW' or split_type == 'CIN' or split_type == 'CLE' or split_type == 'COL' \\\n",
    "        or split_type == 'DET' or split_type == 'HOU' or split_type == 'KCR' or split_type == 'LAD' or split_type == 'FLA' \\\n",
    "        or split_type == 'MIL' or split_type == 'MIN' or split_type == 'NYM' or split_type == 'NYY' or split_type == 'OAK' \\\n",
    "        or split_type == 'PHI' or split_type == 'PIT' or split_type == 'SDP' or split_type == 'SEA' or split_type == 'SFG' \\\n",
    "        or split_type == 'STL' or split_type == 'TBD' or split_type == 'TEX' or split_type == 'TOR' or split_type == 'WSN':\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=oppon%7C{split_type}%7C{team_abv}%7C{year}%7Cpitch%7CIP%7C\"\n",
    "    elif split_type == 'Day' or split_type == 'Night' or split_type == 'Grass' or split_type == 'Artif.%20Turf':\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=stad%7C{split_type}%7C{team_abv}%7C{year}%7Cpitch%7CIP%7C\"\n",
    "    else:\n",
    "        print(f\"Error: Split type '{split_type}' not supported yet.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    try:\n",
    "        driver.get(url)\n",
    "    except TimeoutException:\n",
    "        print(f\"[{team_abv} - {description}]: Page load timed out (60s). Skipping or retrying...\")\n",
    "        return None # Let the main loop handle the retry/skip\n",
    "        \n",
    "    datatable_xpath = f\"//table[@id='{datatable_id}']\"\n",
    "    \n",
    "    # --- SCRAPING LOGIC --- \n",
    "    try:\n",
    "        # Wait up to 30 seconds for the table\n",
    "        WebDriverWait(driver, 30).until(\n",
    "            EC.presence_of_element_located((By.XPATH, datatable_xpath))\n",
    "        )\n",
    "        table_element = driver.find_element(By.XPATH, datatable_xpath)\n",
    "        print(f\"[{team_abv} - {description}]: Table loaded successfully.\")\n",
    "    except Exception:\n",
    "        # This catches both TimeoutException and NoSuchElementException\n",
    "        print(f\"[{team_abv} - {description}]: Table element not found after 30s. Check site content.\")\n",
    "        return None \n",
    "\n",
    "    # Extract the full HTML, wrap in StringIO, read with pandas\n",
    "    table_html = table_element.get_attribute('outerHTML')\n",
    "    html_string = StringIO(table_html)\n",
    "    \n",
    "    try:\n",
    "        tables = pd.read_html(html_string, flavor='lxml') \n",
    "    except Exception as e:\n",
    "        print(f\"[{team_abv} - {description}]: Error parsing HTML with pandas: {e}\")\n",
    "        return None\n",
    "\n",
    "    if not tables:\n",
    "        print(f\"[{team_abv} - {description}]: No tables found.\")\n",
    "        return None\n",
    "\n",
    "    # Create an explicit copy\n",
    "    df = tables[0].copy() \n",
    "    \n",
    "    # --- CLEANING LOGIC --- \n",
    "    df.columns = df.columns.str.strip()\n",
    "    df.columns = [re.sub(r'[^A-Za-z0-9_]+', '', col) for col in df.columns]\n",
    "\n",
    "    if 'Rk' in df.columns:\n",
    "        df = df[df['Rk'] != 'Rk']\n",
    "        \n",
    "    df = df.iloc[:-1] # Remove last row (Totals)\n",
    "    \n",
    "    df['description'] = description\n",
    "    df['team'] = team_abv\n",
    "    df['year'] = YEAR\n",
    "    \n",
    "    return df \n",
    "\n",
    "# Master loop with driver reuse and retry logic\n",
    "\n",
    "pitching_splits_game_level = pd.DataFrame()\n",
    "driver = initialize_driver()\n",
    "\n",
    "if driver is None:\n",
    "    exit() # Stop if the driver failed to initialize\n",
    "\n",
    "print(\"Starting Scrape Job with Driver Reuse and Retry Logic...\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "try:\n",
    "    # Outer loop for teams\n",
    "    for team_abv in team_abbreviations:\n",
    "        # Inner loop for splits\n",
    "        for split in split_parameters:\n",
    "            \n",
    "            # Retry loop for failed connection/table load\n",
    "            for attempt in range(MAX_RETRIES):\n",
    "                try:\n",
    "                    # Check if the driver is still alive (by checking its current URL)\n",
    "                    driver.current_url \n",
    "                    \n",
    "                    new_df = pitcher_split_game_level(\n",
    "                        driver=driver,\n",
    "                        split_type=split['type'], \n",
    "                        team_abv=team_abv, \n",
    "                        year=YEAR, \n",
    "                        datatable_id=DATATABLE_ID, \n",
    "                        description=split['desc']\n",
    "                    )\n",
    "                    \n",
    "                    if new_df is not None and not new_df.empty:\n",
    "                        pitching_splits_game_level = pd.concat([pitching_splits_game_level, new_df], ignore_index=True)\n",
    "                        print(f\"SUCCESS: Appended {len(new_df)} rows. Master DF size: {len(pitching_splits_game_level)}\")\n",
    "                        break # Break the retry loop on success\n",
    "                    \n",
    "                    # If new_df is None (due to TimeoutException/Table not found), retry\n",
    "                    print(f\"RETRYING: Attempt {attempt + 1}/{MAX_RETRIES} for {team_abv} - {split['desc']}...\")\n",
    "                    time.sleep(2) # Short wait before retry\n",
    "\n",
    "                except WebDriverException as e:\n",
    "                    # CRITICAL: Driver died (Connection refused/lost)\n",
    "                    print(f\"\\n[FATAL ERROR] Driver connection lost for {team_abv} - {split['desc']}. Restarting driver...\")\n",
    "                    \n",
    "                    # Clean up the old session\n",
    "                    try:\n",
    "                        driver.quit()\n",
    "                    except Exception:\n",
    "                        pass # Ignore errors on quitting a dead driver\n",
    "                    \n",
    "                    # Restart the driver\n",
    "                    driver = initialize_driver()\n",
    "                    if driver is None:\n",
    "                        # If restart fails, stop the whole script\n",
    "                        raise SystemExit(\"Driver restart failed. Terminating.\")\n",
    "                        \n",
    "                    time.sleep(5) # Longer wait after a fatal crash\n",
    "                    print(\"Driver successfully restarted. Retrying scrape.\")\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"[{team_abv} - {split['desc']}]: Unhandled error: {e}\")\n",
    "                    break # Break retry loop on unexpected failure\n",
    "\n",
    "            # Check if retry failed all attempts and the split was not appended\n",
    "            else: \n",
    "                print(f\"Skipping {team_abv} - {split['desc']} after {MAX_RETRIES} failed attempts.\")\n",
    "                \n",
    "finally:\n",
    "    # 3. CLEANUP: Quit the driver ONCE after all loops are finished\n",
    "    print(\"-\" * 30)\n",
    "    print(\"All tasks finished. Quitting driver.\")\n",
    "    if 'driver' in locals() and driver:\n",
    "        driver.quit() \n",
    "    \n",
    "print(\"Scraping Complete.\")\n",
    "print(f\"Final DataFrame Shape: {pitching_splits_game_level.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3405a5f6",
   "metadata": {},
   "source": [
    "### Update the table statcast_pitches in PostgreSQL\n",
    "#### This table shows the events pitch-by-pitch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23114b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "pybaseball.cache.enable() # Enable caching for reliability\n",
    "\n",
    "def update_statcast_data(engine: Engine):\n",
    "    \"\"\"\n",
    "    Pulls Statcast data starting from the day AFTER the last record in the database\n",
    "    to ensure only new events are downloaded and appended.\n",
    "    \"\"\"\n",
    "    \n",
    "    today = date.today()\n",
    "    \n",
    "    # --- STEP 1: FIND LAST DATE IN DB ---\n",
    "    try:\n",
    "        # Query the database to find the latest game_date currently stored\n",
    "        with engine.connect() as connection:\n",
    "            result = connection.execute(\n",
    "                text(\"SELECT MAX(game_date) FROM statcast_pitches;\")\n",
    "            ).scalar()\n",
    "        \n",
    "        # If the table is empty, start from 400 days ago (initial load range)\n",
    "        if result is None:\n",
    "            print(\"Database is empty. Starting full initial load (400 days)...\")\n",
    "            last_date = today - timedelta(days=400)\n",
    "        else:\n",
    "            # Start the new pull from the day AFTER the last record\n",
    "            last_date = result.date()\n",
    "            print(f\"Latest game_date found in DB: {last_date.strftime('%Y-%m-%d')}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR querying database for last date: {e}. Defaulting to last 5 days.\")\n",
    "        last_date = today - timedelta(days=5)\n",
    "\n",
    "    \n",
    "    # --- STEP 2: DEFINE NEW EXTRACTION RANGE ---\n",
    "    start_date = last_date + timedelta(days=1)\n",
    "    end_date = today - timedelta(days=1) # Pull up to yesterday, as today's games aren't finished\n",
    "\n",
    "    start_dt_str = start_date.strftime('%Y-%m-%d')\n",
    "    end_dt_str = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    if start_date >= end_date:\n",
    "        print(f\"Data is up to date as of {end_dt_str}. No new extraction needed.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Starting DAILY Statcast ETL: Pulling data from {start_dt_str} to {end_dt_str}\")\n",
    "    \n",
    "    # --- STEP 3: EXTRACTION ---\n",
    "    try:\n",
    "        df = pyb.statcast(start_dt=start_dt_str, end_dt=end_dt_str)\n",
    "        \n",
    "        if df is None or df.empty:\n",
    "            print(\"No new Statcast data retrieved for this date range. Exiting.\")\n",
    "            return\n",
    "\n",
    "        #  --- STEP 4: TRANSFORMATION ---        \n",
    "        # Handle data types before loading (optional, but good practice)\n",
    "        df['game_date'] = pd.to_datetime(df['game_date'])\n",
    "        \n",
    "        # # --- STEP 5: LOADING ---\n",
    "        print(f\"Loading {len(df)} new rows into 'statcast_pitches'...\")\n",
    "\n",
    "        df.to_sql(\n",
    "            'statcast_pitches', \n",
    "            engine, \n",
    "            if_exists='replace', # CRITICAL: Append new data to the existing table\n",
    "            index=False, \n",
    "            chunksize=5000\n",
    "        )\n",
    "        \n",
    "        print(f\"‚úÖ Successfully appended {len(df)} new rows of Statcast data.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Statcast ETL Failed during extraction or loading: {e}\")\n",
    "        \n",
    "\n",
    "# Execute the daily update\n",
    "update_statcast_data(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf9ac5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_statcast_data(start_date, end_date):\n",
    "    \"\"\"Pulls granular, pitch-by-pitch data for a specified date range.\"\"\"\n",
    "    print(f\"-> Pulling Statcast data from {start_date} to {end_date}...\")\n",
    "    \n",
    "    # pybaseball statcast function is designed to handle this extraction\n",
    "    raw_statcast_df = pyb.statcast(start_dt=start_date, end_dt=end_date)\n",
    "    \n",
    "    if raw_statcast_df is None or raw_statcast_df.empty:\n",
    "        print(\"Warning: No Statcast data returned for this date range.\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    return raw_statcast_df\n",
    "\n",
    "\n",
    "# Example\n",
    "test_start_date = '2025-10-28'\n",
    "test_end_date = '2025-10-30' \n",
    "\n",
    "daily_data = extract_statcast_data(test_start_date, test_end_date)\n",
    "print(f\"Successfully extracted {len(daily_data)} individual pitches/events.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893b85e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# game_pk: Integer. Game id provided by MLB Advanced Media.\n",
    "# get statcast data for game_pk \n",
    "game_log = pyb.statcast_single_game(813024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46519a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c4972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# game_boxscore = statsapi.boxscore_data(gamePk, timecode=None)\n",
    "\n",
    "for team in statsapi.lookup_team('dodgers'):\n",
    "    print(team)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb511b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = statsapi.meta('gameTypes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6749b680",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = statsapi.get('team', {'teamId':143})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504f23de",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_game = statsapi.last_game(119)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b679c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "players_lahman = pylahman.People()\n",
    "player_chadwick = pyb.chadwick_register()\n",
    "\n",
    "# Join lahman and chadwick on key identifiers and bring all the columns from lahman\n",
    "# Ignore if key_bbref is empty in chadwick\n",
    "players_chadwick_clean = player_chadwick[player_chadwick['key_retro'].notna()]\n",
    "players_lahman_clean   = players_lahman[players_lahman['retroID'].notna()]\n",
    "\n",
    "players_df = pd.merge(\n",
    "    players_chadwick_clean,\n",
    "    players_lahman_clean,\n",
    "    left_on=['key_retro'],\n",
    "    right_on=['retroID'],\n",
    "    how='left',\n",
    ")\n",
    "\n",
    "# Remove unnecesary columns and drop them from the dataframe\n",
    "cols_to_remove = ['retroID', 'bbrefID', 'mlb_played_first', 'mlb_played_last']\n",
    "players_df = players_df.drop(columns= cols_to_remove)\n",
    "\n",
    "# Rename the fields\n",
    "rename_map = {\n",
    "    # IDs\n",
    "    \"key_mlbam\":     \"key_mlbam\",\n",
    "    \"key_retro\":     \"key_retro\",\n",
    "    \"key_bbref\":     \"key_bbref\",\n",
    "    \"key_fangraphs\": \"key_fangraphs\",\n",
    "    \"ID\":            \"id_lahman\",\n",
    "    \"playerID\":      \"player_id_lahman\",\n",
    "\n",
    "    # Names\n",
    "    \"name_last\":     \"last_name_chadwick\",\n",
    "    \"name_first\":    \"first_name_chadwick\",\n",
    "    \"nameLast\":      \"last_name_lahman\",\n",
    "    \"nameFirst\":     \"first_name_lahman\",\n",
    "    \"nameGiven\":     \"first_and_second_name_lahman\",\n",
    "\n",
    "    # Debut/Final game\n",
    "    \"debut\":         \"debut\",\n",
    "    \"finalGame\":     \"final_game\",\n",
    "\n",
    "    # Info\n",
    "    \"weight\":        \"weight\",\n",
    "    \"height\":        \"height\",\n",
    "    \"bats\":          \"bats\",\n",
    "    \"throws\":        \"throws\",\n",
    "\n",
    "    # Birth/Death\n",
    "    \"birthYear\":     \"birth_year\",\n",
    "    \"birthMonth\":    \"birth_month\",\n",
    "    \"birthDay\":      \"birth_day\",\n",
    "    \"birthCity\":     \"birth_city\",\n",
    "    \"birthCountry\":  \"birth_country\",\n",
    "    \"birthState\":    \"birth_state\",\n",
    "    \"deathYear\":     \"death_year\",\n",
    "    \"deathMonth\":    \"death_month\",\n",
    "    \"deathDay\":      \"death_day\",\n",
    "    \"deathCountry\":  \"death_country\",\n",
    "    \"deathState\":    \"death_state\",\n",
    "    \"deathCity\":     \"death_city\",\n",
    "}\n",
    "\n",
    "# Apply the rename\n",
    "players_df = players_df.rename(columns= rename_map)\n",
    "\n",
    "# Order the new columns\n",
    "ordered_cols = [\n",
    "    \"key_mlbam\",\n",
    "    \"key_retro\",\n",
    "    \"key_bbref\",\n",
    "    \"key_fangraphs\",\n",
    "    \"id_lahman\",\n",
    "    \"player_id_lahman\",\n",
    "    \"last_name_chadwick\",\n",
    "    \"first_name_chadwick\",\n",
    "    \"last_name_lahman\",\n",
    "    \"first_name_lahman\",\n",
    "    \"first_and_second_name_lahman\",\n",
    "    \"debut\",\n",
    "    \"final_game\",\n",
    "    \"weight\",\n",
    "    \"height\",\n",
    "    \"bats\",\n",
    "    \"throws\",\n",
    "    \"birth_year\",\n",
    "    \"birth_month\",\n",
    "    \"birth_day\",\n",
    "    \"birth_city\",\n",
    "    \"birth_country\",\n",
    "    \"birth_state\",\n",
    "    \"death_year\",\n",
    "    \"death_month\",\n",
    "    \"death_day\",\n",
    "    \"death_country\",\n",
    "    \"death_state\",\n",
    "    \"death_city\"\n",
    "]\n",
    "\n",
    "# Apply the order\n",
    "players_df = players_df[ordered_cols]\n",
    "\n",
    "# This selects only columns with numbers and fills their nulls with -1\n",
    "numeric_cols = players_df.select_dtypes(include=['number']).columns\n",
    "players_df[numeric_cols] = players_df[numeric_cols].fillna(-1)\n",
    "\n",
    "# Replace nulls in the text columns\n",
    "text_cols = [\n",
    "    \"key_retro\",\n",
    "    \"key_bbref\",\n",
    "    \"player_id_lahman\",\n",
    "    \"last_name_chadwick\",\n",
    "    \"first_name_chadwick\",\n",
    "    \"last_name_lahman\",\n",
    "    \"first_name_lahman\",\n",
    "    \"first_and_second_name_lahman\",\n",
    "    \"bats\",\n",
    "    \"throws\",\n",
    "    \"birth_city\",\n",
    "    \"birth_country\",\n",
    "    \"birth_state\",\n",
    "    \"death_country\",\n",
    "    \"death_state\",\n",
    "    \"death_city\"\n",
    "]\n",
    "\n",
    "# Convert to a standard object type first and then fill the nulls with N/A\n",
    "for col in text_cols:\n",
    "    players_df[col] = players_df[col].astype(object).fillna('N/A')\n",
    "    \n",
    "\n",
    "# List the date columns\n",
    "date_cols = [\n",
    "    \"debut\",\n",
    "    \"final_game\"\n",
    "]\n",
    "# Fill null dates with January 1st, 1700\n",
    "for col in date_cols:\n",
    "    players_df[col] = players_df[col].fillna(pd.Timestamp('1700-01-01'))\n",
    "\n",
    "# Check for nulls in my table - there shouldn't be any\n",
    "if (players_df.isnull().sum() == 0).all():\n",
    "    print(\"‚úÖ No nulls found.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è WARNING - There are nulls in some columns in the dataframe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50721a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Identify all text columns\n",
    "text_cols = team_franchises.select_dtypes(include=['object', 'string']).columns\n",
    "\n",
    "# 2. Convert to object FIRST, then fill\n",
    "for col in text_cols:\n",
    "    # Converting to object allows 'N/A' to be treated as a normal string\n",
    "    team_franchises[col] = team_franchises[col].astype(object).fillna('N/A')\n",
    "    \n",
    "    # Just in case some were literal 'nan' strings:\n",
    "    team_franchises[col] = team_franchises[col].replace(['nan', 'None', '<NA>'], 'N/A')\n",
    "\n",
    "# 3. Final Verification with Emojis\n",
    "null_count = team_franchises[text_cols].isnull().sum().sum()\n",
    "if null_count == 0:\n",
    "    print(\"‚úÖ All string columns are clean. No nulls found!\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Warning: {null_count} nulls still remain in text columns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7c7edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_info = pylahman.Teams()\n",
    "\n",
    "# Identify all text columns\n",
    "text_cols = team_info.select_dtypes(include=['object', 'string']).columns\n",
    "\n",
    "# Convert to object first, then fill with N/A\n",
    "for col in text_cols:\n",
    "    # Converting to object allows 'N/A' to be treated as a normal string\n",
    "    team_info[col] = team_info[col].astype(object).fillna('N/A')\n",
    "    \n",
    "    # Just in case some were literal 'nan' strings:\n",
    "    team_info[col] = team_info[col].replace(['nan', 'None', '<NA>'], 'N/A')\n",
    "\n",
    "# This selects only columns with numbers and fills their nulls with -1\n",
    "numeric_cols = team_info.select_dtypes(include=['number']).columns\n",
    "team_info[numeric_cols] = team_info[numeric_cols].fillna(-1)\n",
    "\n",
    "# Final verification\n",
    "null_count_text    = team_info[text_cols].isnull().sum().sum()\n",
    "null_count_numeric = team_info[numeric_cols].isnull().sum().sum()\n",
    "total_nulls        = null_count_text + null_count_numeric\n",
    "\n",
    "if total_nulls == 0:\n",
    "    print(\"‚úÖ All columns are clean. No nulls found!\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è Warning: {total_nulls} nulls still remain some columns.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cff595",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94bebb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ dim_pitcher_archetypes updated! Primary Key was preserved.\n"
     ]
    }
   ],
   "source": [
    "#def update_dim_pitcher_archetypes(engine: Engine):\n",
    "\"\"\"\n",
    "Groups pitchers into 8 archetypes and updates the database.\n",
    "Now includes an 'updated_at' column to track the last run date.\n",
    "\"\"\"\n",
    "\n",
    "# 1. Pull unique pitcher stats\n",
    "query = \"\"\"\n",
    "SELECT \n",
    "    pitcher,\n",
    "    AVG(release_speed) as avg_velo, \n",
    "    AVG(release_spin_rate) as avg_spin, -- The spin rate of a pitch measured in revolutions per minute (rpm) at the moment of release\n",
    "    AVG(pfx_x) as avg_horiz_mvmt, -- Horizontal movement in feet from the catcher's perspective\n",
    "    AVG(pfx_z) as avg_vert_mvmt -- Vertical movement from the catcher's perpsective.\n",
    "FROM fact_statcast_pitches\n",
    "WHERE release_speed IS NOT NULL \n",
    "    AND release_spin_rate IS NOT NULL\n",
    "    AND pfx_x IS NOT NULL \n",
    "    AND pfx_z IS NOT NULL\n",
    "GROUP BY pitcher\n",
    "HAVING COUNT(*) > 100 \n",
    "\"\"\"\n",
    "pitcher_stats = pd.read_sql(query, engine)\n",
    "\n",
    "# 2. Scale the data\n",
    "scaler = StandardScaler()\n",
    "features = ['avg_velo', 'avg_spin', 'avg_horiz_mvmt', 'avg_vert_mvmt']\n",
    "scaled_data = scaler.fit_transform(pitcher_stats[features])\n",
    "\n",
    "# 3. Create 8 Archetypes\n",
    "kmeans = KMeans(n_clusters=8, random_state=42, n_init=10)\n",
    "pitcher_stats['archetype_id'] = kmeans.fit_predict(scaled_data)\n",
    "\n",
    "# 4. Map IDs and Add Timestamp\n",
    "archetype_map = {\n",
    "    0: \"Power Flamethrower\",\n",
    "    1: \"Sinker / Tail Specialist\",\n",
    "    2: \"Breaking Ball Specialist\",\n",
    "    3: \"Standard Control Righty\",\n",
    "    4: \"Position Player / Eephus\",\n",
    "    5: \"Deceptive Angle Specialist\",\n",
    "    6: \"Low-Spin / Heavy Sinker\",\n",
    "    7: \"Power Slider / Sweeper\"\n",
    "}\n",
    "pitcher_stats['archetype_name'] = pitcher_stats['archetype_id'].map(archetype_map)\n",
    "\n",
    "# Add the current timestamp to every row\n",
    "pitcher_stats['updated_at'] = datetime.now()\n",
    "\n",
    "# 5. Database Update (Truncate and Append)\n",
    "with engine.connect() as conn:\n",
    "    try:\n",
    "        conn.execute(text(\"TRUNCATE TABLE dim_pitcher_archetypes;\"))\n",
    "        conn.commit()\n",
    "        print(\"Refreshing existing dim_pitcher_archetypes table...\")\n",
    "    except Exception:\n",
    "        print(\"Table 'dim_pitcher_archetypes' not found. Creating it for the first time...\")\n",
    "        conn.rollback()\n",
    "\n",
    "# Upload data including the new column\n",
    "pitcher_stats[['pitcher', 'archetype_id', 'archetype_name', 'updated_at']].to_sql(\n",
    "    'dim_pitcher_archetypes', \n",
    "    engine, \n",
    "    if_exists='append', \n",
    "    index=False\n",
    ")\n",
    "\n",
    "# 6. Ensure the Primary Key is set\n",
    "pk_check = \"\"\"\n",
    "SELECT count(*) \n",
    "FROM information_schema.table_constraints \n",
    "WHERE table_name='dim_pitcher_archetypes' AND constraint_type='PRIMARY KEY';\n",
    "\"\"\"\n",
    "with engine.connect() as conn:\n",
    "    has_pk = conn.execute(text(pk_check)).scalar()\n",
    "    if has_pk == 0:\n",
    "        conn.execute(text(\"ALTER TABLE dim_pitcher_archetypes ADD PRIMARY KEY (pitcher);\"))\n",
    "        conn.commit()\n",
    "        print(\"‚úÖ Primary Key (pitcher) established.\")\n",
    "\n",
    "print(f\"‚úÖ Successfully categorized {len(pitcher_stats)} pitchers.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PY_312_DEVELOPMENT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
