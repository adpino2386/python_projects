{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "37b6a471",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import pybaseball as pyb\n",
    "import pybaseball.cache # Ensure caching is imported\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import datetime\n",
    "import time\n",
    "from datetime import date, timedelta\n",
    "from sqlalchemy.engine import Engine\n",
    "from sqlalchemy import text\n",
    "\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from rapidfuzz import process\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6f549c45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection established.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Build the PostgreSQL connection string\n",
    "DB_URL = f\"postgresql://{os.environ['DB_USER']}:{os.environ['DB_PASS']}@{os.environ['DB_HOST']}:5432/{os.environ['DB_NAME']}\"\n",
    "\n",
    "# Create the engine object for connecting\n",
    "engine = create_engine(DB_URL)\n",
    "\n",
    "print(\"Database connection established.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b060cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a sample function; the final ETL will be more complex.\n",
    "def extract_batting_data(year=2025):\n",
    "    # fgs is FanGraphs Season Stats\n",
    "    df = pyb.batting_stats(year)\n",
    "    # Rename columns to match your SQL schema (e.g., 'BB' for Walks, 'K' for Strikeouts)\n",
    "    df = df.rename(columns={'ID': 'player_id', 'Tm': 'team_id'})\n",
    "    return df\n",
    "\n",
    "current_year_batting = extract_batting_data(2025)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced1e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_historical_batting(start_year=2024, end_year=2025):\n",
    "    \"\"\"Pulls batting stats for a range of years from FanGraphs and combines them.\"\"\"\n",
    "    \n",
    "    all_data_frames = []\n",
    "    \n",
    "    # Create the list of years to pull\n",
    "    years = range(start_year, end_year + 1)\n",
    "    \n",
    "    for year in years:\n",
    "        print(f\"-> Pulling FanGraphs data for {year}...\")\n",
    "        try:\n",
    "            # 1. Extraction: Pull data for a single year\n",
    "            df = pyb.batting_stats(year)\n",
    "            \n",
    "            # CRITICAL: Add a 'Season' column for historical tracking\n",
    "            df['Season'] = year \n",
    "            \n",
    "            # 2. Transformation (Initial Rename/Select)\n",
    "            # You must select and rename columns here to match your PostgreSQL schema\n",
    "            \n",
    "            # Example: Select and rename columns (Adjust this based on your exact schema!)\n",
    "            df = df.rename(columns={'Name': 'player_name', 'PlayerId': 'player_id', \n",
    "                                    'G': 'games_played', 'HR': 'home_runs', 'SO': 'strikeouts'})\n",
    "            \n",
    "            # 3. Append: Add the processed year's data to the list\n",
    "            all_data_frames.append(df)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: Failed to pull data for {year}: {e}\")\n",
    "            \n",
    "    # 4. Concatenate: Merge all DataFrames into one large DataFrame\n",
    "    if all_data_frames:\n",
    "        historical_df = pd.concat(all_data_frames, ignore_index=True)\n",
    "        print(f\"✅ Successfully combined data from {len(years)} seasons into {len(historical_df)} total rows.\")\n",
    "        return historical_df\n",
    "    \n",
    "    return pd.DataFrame() # Return empty if no data was pulled\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    full_batting_df = extract_historical_batting()\n",
    "    \n",
    "    # ... (Then proceed to your advanced metrics calculation and load_data function) ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43dc54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extract_statcast_data(start_date, end_date):\n",
    "    \"\"\"Pulls granular, pitch-by-pitch data for a specified date range.\"\"\"\n",
    "    print(f\"-> Pulling Statcast data from {start_date} to {end_date}...\")\n",
    "    \n",
    "    # pybaseball statcast function is designed to handle this extraction\n",
    "    raw_statcast_df = pyb.statcast(start_dt=start_date, end_dt=end_date)\n",
    "    \n",
    "    if raw_statcast_df is None or raw_statcast_df.empty:\n",
    "        print(\"Warning: No Statcast data returned for this date range.\")\n",
    "        return pd.DataFrame()\n",
    "        \n",
    "    return raw_statcast_df\n",
    "\n",
    "\n",
    "# Example\n",
    "test_start_date = '2025-10-28'\n",
    "test_end_date = '2025-10-30' \n",
    "\n",
    "daily_data = extract_statcast_data(test_start_date, test_end_date)\n",
    "print(f\"Successfully extracted {len(daily_data)} individual pitches/events.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79dbdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable pybaseball caching to speed up repeated queries\n",
    "pybaseball.cache.enable()\n",
    "\n",
    "# Set the connection engine using your environment variables (as previously defined)\n",
    "# engine = create_engine(DB_URL) \n",
    "\n",
    "def update_statcast_data(engine: Engine, days_to_keep: int = 400):\n",
    "    \"\"\"\n",
    "    Pulls recent Statcast data and keeps a rolling window of data \n",
    "    in the PostgreSQL statcast_pitches table.\n",
    "    \"\"\"\n",
    "    today = date.today()\n",
    "    \n",
    "    # We pull data from the end of last season (or roughly 400 days ago) \n",
    "    # up to yesterday to ensure we have a full window for rolling metrics.\n",
    "    start_date = today - timedelta(days=days_to_keep) \n",
    "    end_date = today - timedelta(days=1)\n",
    "    \n",
    "    start_dt_str = start_date.strftime('%Y-%m-%d')\n",
    "    end_dt_str = end_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    print(f\"Starting Statcast ETL: Pulling data from {start_dt_str} to {end_dt_str}\")\n",
    "    \n",
    "    try:\n",
    "        # Use the general statcast function for league-wide pitch data\n",
    "        # 'statcast' is an alias for the league-wide Statcast search\n",
    "        df = pyb.statcast(start_dt=start_dt_str, end_dt=end_dt_str)\n",
    "\n",
    "        if df.empty:\n",
    "            print(\"No new Statcast data retrieved. Exiting.\")\n",
    "            return\n",
    "\n",
    "        # 1. Cleaning/Selection (CRITICAL)\n",
    "        # Select ONLY the columns you need to prevent errors during loading.\n",
    "        # Statcast column names are long; we'll rename them to match the SQL table.\n",
    "        df_clean = df.rename(columns={\n",
    "            'game_date': 'game_date', \n",
    "            'game_pk': 'game_pk', \n",
    "            'inning': 'inning', \n",
    "            'batter': 'batter_id', \n",
    "            'pitcher': 'pitcher_id', \n",
    "            'stand': 'stand', \n",
    "            'p_throws': 'p_throws',\n",
    "            'events': 'events',\n",
    "            'description': 'description',\n",
    "            'launch_speed': 'launch_speed', \n",
    "            'launch_angle': 'launch_angle',\n",
    "            'bb_type': 'bb_type',\n",
    "            'pitch_type': 'pitch_type',\n",
    "            'release_speed': 'release_speed',\n",
    "            'spin_rate': 'spin_rate'\n",
    "        })\n",
    "\n",
    "        # Only keep the columns that exist in our SQL schema\n",
    "        columns_to_keep = [col for col in df_clean.columns if col in ['game_date', 'game_pk', 'inning', 'batter_id', 'pitcher_id', 'stand', 'p_throws', 'events', 'description', 'launch_speed', 'launch_angle', 'bb_type', 'pitch_type', 'release_speed', 'spin_rate']]\n",
    "        final_df = df_clean[columns_to_keep]\n",
    "\n",
    "        # # 2. Loading: Use 'replace' for the first run, then switch to 'append' \n",
    "        # # for a daily ETL to avoid re-downloading old data.\n",
    "        # # Since we are pulling a large historical range, we should replace the table.\n",
    "        final_df.to_sql('statcast_pitches', engine, if_exists='append', index=False, chunksize=5000)\n",
    "        \n",
    "        # print(f\"✅ Successfully loaded {len(final_df)} rows of Statcast data into 'statcast_pitches'.\")\n",
    "        return final_df\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Statcast ETL Failed: {e}\")\n",
    "\n",
    "# Example Run (assuming 'engine' is defined with your credentials)\n",
    "statcast_data_df = update_statcast_data(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a049992",
   "metadata": {},
   "source": [
    "### This will update the table statcast_pitches in PostgreSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d67664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database is empty. Starting full initial load (400 days)...\n",
      "Starting DAILY Statcast ETL: Pulling data from 2024-11-08 to 2025-12-11\n",
      "This is a large query, it may take a moment to complete\n",
      "Skipping offseason dates\n",
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 254/254 [00:14<00:00, 17.16it/s]\n",
      "c:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\pybaseball\\statcast.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_data = pd.concat(dataframe_list, axis=0).convert_dtypes(convert_string=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 770795 new rows into 'statcast_pitches'...\n",
      "✅ Successfully appended 770795 new rows of Statcast data.\n"
     ]
    }
   ],
   "source": [
    "pybaseball.cache.enable() # Enable caching for reliability\n",
    "\n",
    "def update_statcast_data(engine: Engine):\n",
    "    \"\"\"\n",
    "    Pulls Statcast data starting from the day AFTER the last record in the database\n",
    "    to ensure only new events are downloaded and appended.\n",
    "    \"\"\"\n",
    "    \n",
    "    today = date.today()\n",
    "    \n",
    "    # --- STEP 1: FIND LAST DATE IN DB ---\n",
    "    try:\n",
    "        # Query the database to find the latest game_date currently stored\n",
    "        with engine.connect() as connection:\n",
    "            result = connection.execute(\n",
    "                text(\"SELECT MAX(game_date) FROM statcast_pitches;\")\n",
    "            ).scalar()\n",
    "        \n",
    "        # If the table is empty, start from 400 days ago (initial load range)\n",
    "        if result is None:\n",
    "            print(\"Database is empty. Starting full initial load (400 days)...\")\n",
    "            last_date = today - timedelta(days=400)\n",
    "        else:\n",
    "            # Start the new pull from the day AFTER the last record\n",
    "            last_date = result.date()\n",
    "            print(f\"Latest game_date found in DB: {last_date.strftime('%Y-%m-%d')}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ ERROR querying database for last date: {e}. Defaulting to last 5 days.\")\n",
    "        last_date = today - timedelta(days=5)\n",
    "\n",
    "    \n",
    "    # --- STEP 2: DEFINE NEW EXTRACTION RANGE ---\n",
    "    start_date = last_date + timedelta(days=1)\n",
    "    end_date = today - timedelta(days=1) # Pull up to yesterday, as today's games aren't finished\n",
    "\n",
    "    start_dt_str = start_date.strftime('%Y-%m-%d')\n",
    "    end_dt_str = end_date.strftime('%Y-%m-%d')\n",
    "\n",
    "    if start_date >= end_date:\n",
    "        print(f\"Data is up to date as of {end_dt_str}. No new extraction needed.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Starting DAILY Statcast ETL: Pulling data from {start_dt_str} to {end_dt_str}\")\n",
    "    \n",
    "    # --- STEP 3: EXTRACTION ---\n",
    "    try:\n",
    "        df = pyb.statcast(start_dt=start_dt_str, end_dt=end_dt_str)\n",
    "        \n",
    "        if df is None or df.empty:\n",
    "            print(\"No new Statcast data retrieved for this date range. Exiting.\")\n",
    "            return\n",
    "\n",
    "        #  --- STEP 4: TRANSFORMATION ---        \n",
    "        # Handle data types before loading (optional, but good practice)\n",
    "        df['game_date'] = pd.to_datetime(df['game_date'])\n",
    "        \n",
    "        # # --- STEP 5: LOADING ---\n",
    "        print(f\"Loading {len(df)} new rows into 'statcast_pitches'...\")\n",
    "\n",
    "        df.to_sql(\n",
    "            'statcast_pitches', \n",
    "            engine, \n",
    "            if_exists='replace', # CRITICAL: Append new data to the existing table\n",
    "            index=False, \n",
    "            chunksize=5000\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ Successfully appended {len(df)} new rows of Statcast data.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Statcast ETL Failed during extraction or loading: {e}\")\n",
    "        \n",
    "\n",
    "# Execute the daily update\n",
    "update_statcast_data(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b036bfa2",
   "metadata": {},
   "source": [
    "### Update players table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f98b29d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 25901 new rows into 'players'...\n",
      "✅ Players successfully added 25901 new rows of players data.\n"
     ]
    }
   ],
   "source": [
    "def update_players(engine: Engine):   \n",
    "    try:\n",
    "        df = pyb.chadwick_register()\n",
    "        \n",
    "        # # --- STEP 5: LOADING ---\n",
    "        print(f\"Loading {len(df)} new rows into 'players'...\")\n",
    "        \n",
    "        df.to_sql(\n",
    "            'players', \n",
    "            engine, \n",
    "            if_exists='replace',\n",
    "            index=False, \n",
    "            chunksize=5000\n",
    "        )\n",
    "        \n",
    "        print(f\"✅ Players successfully added {len(df)} new rows of players data.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Statcast ETL Failed during extraction or loading: {e}\")\n",
    "        \n",
    "\n",
    "# Execute the players function\n",
    "update_players(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f6532c",
   "metadata": {},
   "source": [
    "### Get team stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8153a255",
   "metadata": {},
   "outputs": [],
   "source": [
    "team_batting  = pyb.team_batting(2025)\n",
    "team_pitching = pyb.team_pitching(2025)\n",
    "team_fielding = pyb.team_fielding(2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9f0b3a",
   "metadata": {},
   "source": [
    "### Get players stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36acbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batting_stats  = pyb.batting_stats(2025,  qual=0)\n",
    "pitching_stats = pyb.pitching_stats(2025, qual=0)\n",
    "fielding_stats = pyb.fielding_stats(2025, qual=0)\n",
    "running_stats  = pyb.statcast_sprint_speed(2025, 50) #players with at least 50 opportunities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216c652b",
   "metadata": {},
   "source": [
    "### Get scores last n days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b6ef12a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching for all games played from 2025-12-11 to 2025-12-11...\n",
      "This is a large query, it may take a moment to complete\n",
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No games found between 2025-12-11 and 2025-12-11.\n",
      "Searching for all games played from 2025-12-05 to 2025-12-11...\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No games found between 2025-12-05 and 2025-12-11.\n",
      "Searching for all games played from 2025-11-27 to 2025-12-11...\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No games found between 2025-11-27 and 2025-12-11.\n",
      "Searching for all games played from 2025-11-12 to 2025-12-11...\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00,  5.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No games found between 2025-11-12 and 2025-12-11.\n",
      "Searching for all games played from 2025-10-13 to 2025-12-11...\n",
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 34/34 [00:02<00:00, 13.37it/s]\n",
      "c:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\pybaseball\\statcast.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_data = pd.concat(dataframe_list, axis=0).convert_dtypes(convert_string=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully pulled 5290 pitch events.\n",
      "Searching for all games played from 2025-09-13 to 2025-12-11...\n",
      "This is a large query, it may take a moment to complete\n",
      "Skipping offseason dates\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:04<00:00, 15.87it/s]\n",
      "c:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\pybaseball\\statcast.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_data = pd.concat(dataframe_list, axis=0).convert_dtypes(convert_string=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully pulled 77978 pitch events.\n"
     ]
    }
   ],
   "source": [
    "import pybaseball as pyb\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def get_game_results_last_n_days(n_days=90):\n",
    "    \"\"\"\n",
    "    Pulls raw pitch-by-pitch data for all games played in the last 'n_days' \n",
    "    and then extracts the final score for each game.\n",
    "    \"\"\"\n",
    "    today = datetime.date.today()\n",
    "    \n",
    "    # 1. Calculate the start and end dates for the 90-day range\n",
    "    end_date = today - datetime.timedelta(days=1)  # Search up to yesterday\n",
    "    start_date = today - datetime.timedelta(days=n_days)\n",
    "    \n",
    "    start_date_str = start_date.strftime('%Y-%m-%d')\n",
    "    end_date_str = end_date.strftime('%Y-%m-%d')\n",
    "    \n",
    "    print(f\"Searching for all games played from {start_date_str} to {end_date_str}...\")\n",
    "\n",
    "    try:\n",
    "        # 2. Pull all pitch-by-pitch data in that range\n",
    "        all_data_in_range = pyb.statcast(start_dt=start_date_str, end_dt=end_date_str)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving Statcast data: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    if all_data_in_range.empty:\n",
    "        print(f\"No games found between {start_date_str} and {end_date_str}.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    print(f\"Successfully pulled {len(all_data_in_range)} pitch events.\")\n",
    "\n",
    "    # 3. Sort the data chronologically by game_pk, inning, etc.\n",
    "    data_sorted = all_data_in_range.sort_values(\n",
    "        by=['game_pk', 'inning', 'inning_topbot', 'at_bat_number', 'pitch_number'],\n",
    "        ascending=True\n",
    "    )\n",
    "\n",
    "    # 4. Group by game_pk and take the last row (which contains the final score)\n",
    "    final_events = data_sorted.groupby('game_pk').tail(1).reset_index(drop=True)\n",
    "    \n",
    "    # 5. Extract and rename the relevant columns for the final scoreboard\n",
    "    scoreboard = final_events[[\n",
    "        'game_date', \n",
    "        'home_team', \n",
    "        'away_team', \n",
    "        'home_score', \n",
    "        'away_score'\n",
    "    ]].copy()\n",
    "    \n",
    "    scoreboard.rename(columns={\n",
    "        'home_score': 'Home_Final_Score',\n",
    "        'away_score': 'Away_Final_Score',\n",
    "        'game_date': 'Date'\n",
    "    }, inplace=True)\n",
    "    \n",
    "    # 6. Determine the Winner\n",
    "    scoreboard['Winner'] = scoreboard.apply(\n",
    "        lambda row: row['home_team'] if row['Home_Final_Score'] > row['Away_Final_Score'] else row['away_team'],\n",
    "        axis=1\n",
    "    )\n",
    "    scoreboard['Result'] = (\n",
    "        scoreboard['Winner'] + ' wins ' + \n",
    "        scoreboard['Home_Final_Score'].astype(str) + '-' + \n",
    "        scoreboard['Away_Final_Score'].astype(str)\n",
    "    )\n",
    "    \n",
    "    return scoreboard[['Date', 'away_team', 'home_team', 'Away_Final_Score', 'Home_Final_Score', 'Winner', 'Result']]\n",
    "\n",
    "# --- EXECUTION ---\n",
    "results_yesterday_df    = get_game_results_last_n_days(n_days= 1)\n",
    "results_last_7_days_df  = get_game_results_last_n_days(n_days= 7)\n",
    "results_last_15_days_df = get_game_results_last_n_days(n_days= 15)\n",
    "results_last_30_days_df = get_game_results_last_n_days(n_days= 30)\n",
    "results_last_60_days_df = get_game_results_last_n_days(n_days= 60)\n",
    "results_last_90_days_df = get_game_results_last_n_days(n_days= 90)\n",
    "\n",
    "\n",
    "# if not results_last_90_days_df.empty:\n",
    "#     print(f\"\\n--- Game Results from the Last 90 Days ({len(results_last_90_days_df)} Games Found) ---\")\n",
    "#     print(results_last_90_days_df.tail(10)) # Print the last 10 games found\n",
    "# else:\n",
    "#     print(\"\\nNo games were found in the last 90 days.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1a4903",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00c2c1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a large query, it may take a moment to complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:02<00:00, 10.73it/s]\n",
      "c:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\pybaseball\\statcast.py:85: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  final_data = pd.concat(dataframe_list, axis=0).convert_dtypes(convert_string=False)\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "df = pyb.statcast(start_dt='2025-10-01', end_dt='2025-10-30')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "73d7c36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split1 (LHP) table loaded successfully.\n",
      "split1 (RHP) table loaded successfully.\n",
      "split1 (LH) table loaded successfully.\n",
      "split1 (RH) table loaded successfully.\n",
      "split1 (7) table loaded successfully.\n",
      "split1 (14) table loaded successfully.\n",
      "split1 (28) table loaded successfully.\n",
      "split1 (Home) table loaded successfully.\n",
      "split1 (Away) table loaded successfully.\n",
      "split1 (first_batter_game) table loaded successfully.\n",
      "split1 (vs_power_pitcher) table loaded successfully.\n",
      "split1 (vs_weak_pitcher) table loaded successfully.\n",
      "split1 (vs_greater_or_equal_than_500_WP) table loaded successfully.\n",
      "split1 (vs_less_than_500_WP) table loaded successfully.\n",
      "split1 (ANA) table loaded successfully.\n",
      "split1 (ARI) table loaded successfully.\n",
      "split1 (ATL) table loaded successfully.\n",
      "split1 (BAL) table loaded successfully.\n",
      "split1 (BOS) table loaded successfully.\n",
      "split1 (CHC) table loaded successfully.\n",
      "split1 (CHW) table loaded successfully.\n",
      "split1 (CIN) table loaded successfully.\n",
      "split1 (CLE) table loaded successfully.\n",
      "split1 (COL) table loaded successfully.\n",
      "split1 (DET) table loaded successfully.\n",
      "split1 (HOU) table loaded successfully.\n",
      "split1 (KCR) table loaded successfully.\n",
      "split1 (LAD) table loaded successfully.\n",
      "split1 (FLA) table loaded successfully.\n",
      "split1 (MIL) table loaded successfully.\n",
      "split1 (MIN) table loaded successfully.\n",
      "split1 (NYM) table loaded successfully.\n",
      "split1 (NYY) table loaded successfully.\n",
      "split1 (OAK) table loaded successfully.\n",
      "split1 (PHI) table loaded successfully.\n",
      "split1 (PIT) table loaded successfully.\n",
      "split1 (SDP) table loaded successfully.\n",
      "split1 (SEA) table loaded successfully.\n",
      "split1 (SFG) table loaded successfully.\n",
      "split1 (STL) table loaded successfully.\n",
      "split1 (TBD) table loaded successfully.\n",
      "split1 (TEX) table loaded successfully.\n",
      "split1 (TOR) table loaded successfully.\n",
      "split1 (WSN) table loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "def teams_split(split_type, clean_mode):\n",
    "    # Load the options\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")  # Optional: Run in headless mode\n",
    "    options.binary_location = \"C:\\\\Program Files\\\\BraveSoftware\\\\Brave-Browser\\\\Application\\\\brave.exe\"\n",
    "\n",
    "    # Define year\n",
    "    year = datetime.now().year\n",
    "    \n",
    "    # Set up the WebDriver\n",
    "    driver = webdriver.Chrome(options= options)  \n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    if split_type == 'LHP' or split_type == 'RHP': # for LHP and RHP pitchers\n",
    "        driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=plato%7Cvs%20{split_type}%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    elif split_type == '7' or split_type == '14' or split_type == '28': # for the last 7, 14 and 28 days\n",
    "        driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=total%7CLast%20{split_type}%20days%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    elif split_type == 'RH' or split_type == 'LH': # for RH and LH Starters\n",
    "        driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=plato%7Cvs%20{split_type}%20Starter%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    elif split_type == 'Home' or split_type == 'Away': # for home and away games\n",
    "        driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=hmvis%7C{split_type}%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    elif split_type == 'first_batter_game':\n",
    "        driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=leado%7C1st%20Batter%20G%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    elif split_type == 'vs_power_pitcher':\n",
    "        driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=power%7Cvs.%20Power%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    elif split_type == 'vs_weak_pitcher':\n",
    "        driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=power%7Cvs.%20Finesse%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    # For each team:\n",
    "    elif split_type == 'ANA' or split_type == 'ARI' or split_type == 'ATL' or split_type == 'BAL' or split_type == 'BOS' \\\n",
    "        or split_type == 'CHC' or split_type == 'CHW' or split_type == 'CIN' or split_type == 'CLE' or split_type == 'COL' \\\n",
    "        or split_type == 'DET' or split_type == 'HOU' or split_type == 'KCR' or split_type == 'LAD' or split_type == 'FLA' \\\n",
    "        or split_type == 'MIL' or split_type == 'MIN' or split_type == 'NYM' or split_type == 'NYY' or split_type == 'OAK' \\\n",
    "        or split_type == 'PHI' or split_type == 'PIT' or split_type == 'SDP' or split_type == 'SEA' or split_type == 'SFG' \\\n",
    "        or split_type == 'STL' or split_type == 'TBD' or split_type == 'TEX' or split_type == 'TOR' or split_type == 'WSN':\n",
    "            driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=oppon%7C{split_type}%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    elif split_type == 'vs_less_than_500_WP':\n",
    "        driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=oppon%7CWP%20%3C%20.500%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    elif split_type == 'vs_greater_or_equal_than_500_WP':\n",
    "        driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=oppon%7CWP%20%3E%3D%20.500%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    \n",
    "    \n",
    "    # Name of the table\n",
    "    datatable_id = 'split1'\n",
    "\n",
    "    # Explicitly wait for the table element to load\n",
    "    datatable_xpath = f\"//table[@id='{datatable_id}']\"  # Update XPATH as needed\n",
    "    try:\n",
    "        WebDriverWait(driver, 60).until(\n",
    "            EC.presence_of_element_located((By.XPATH, datatable_xpath))\n",
    "        )\n",
    "        print(f\"{datatable_id} ({split_type}) table loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Table {datatable_id} did not load. Details: {e}\")\n",
    "        driver.quit()\n",
    "\n",
    "    # Wait for the load of the page\n",
    "    time.sleep(10)\n",
    "\n",
    "    # Locate the table\n",
    "    table_element = driver.find_element(By.XPATH, datatable_xpath)\n",
    "    text_content = table_element.text\n",
    "\n",
    "    # Process the table content\n",
    "    rows = text_content.split(\"\\n\")\n",
    "    table_data = [row.split(\"\\t\") for row in rows]\n",
    "\n",
    "    # Convert to dataframe\n",
    "    df = pd.DataFrame(table_data)\n",
    "    \n",
    "    # Close the WebDriver\n",
    "    driver.quit()    \n",
    "    \n",
    "    if clean_mode == 1:\n",
    "        # Remove 'Roe' exactly (case-sensitive)\n",
    "        df[0] = df[0].str.replace('Roe', '', regex=False)\n",
    "\n",
    "        # Remove last row\n",
    "        df = df.iloc[:-1]\n",
    "\n",
    "        # Split column from right using spaces\n",
    "        df = df[0].str.split(\" \", n= 30, expand=True)\n",
    "\n",
    "        # Set first row as header\n",
    "        df.columns = df.iloc[0]  # Assign first row as column names\n",
    "        df = df[1:].reset_index(drop=True)  # Remove first row and reset index\n",
    "\n",
    "        # Remove the last column\n",
    "        df = df.iloc[:, :-1]\n",
    "\n",
    "        # Rename last 3 columns\n",
    "        new_column_names = [\"BAbip\", \"tOPS+\", \"sOPS+\"]  # New names for last 3 columns\n",
    "        df.columns.values[-3:] = new_column_names  # Assign new names\n",
    "\n",
    "        # Remove the first column\n",
    "        df = df.iloc[:, 1:]\n",
    "    else:\n",
    "        # Remove 'Roe' and GS exactly (case-sensitive)\n",
    "        df[0] = df[0].str.replace('Roe', '', regex=False)\n",
    "        df[0] = df[0].str.replace('GS', '', regex=False)\n",
    "\n",
    "        # Remove last row\n",
    "        df = df.iloc[:-1]\n",
    "\n",
    "        # Remove rows where column 'A' contains 'Rk', but keep the first row\n",
    "        df = df[~((df.index > 0) & (df[0].str.contains('Rk', na=False)))]\n",
    "\n",
    "        # Split column from right using spaces\n",
    "        df = df[0].str.split(\" \", n= 30, expand=True)\n",
    "\n",
    "        # Set first row as header\n",
    "        df.columns = df.iloc[0]  # Assign first row as column names\n",
    "        df = df[1:].reset_index(drop=True)  # Remove first row and reset index\n",
    "\n",
    "        # Remove the first column\n",
    "        df = df.iloc[:, 1:]\n",
    "\n",
    "        # Remove the last 2 columns\n",
    "        df = df.iloc[:, :-2]\n",
    "\n",
    "        # New column names\n",
    "        new_column_names = ['Team', 'G', 'PA', 'AB', 'R', 'H', '2B', '3B', 'HR', 'RBI', 'SB',\n",
    "                            'CS', 'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS', 'TB', 'GDP', 'HBP', 'SH',\n",
    "                            'SF', 'IBB', 'ROE', 'BAbip', 'tOPS+', 'sOPS+']\n",
    "\n",
    "        # Rename all columns\n",
    "        df.columns = new_column_names\n",
    "\n",
    "    return df\n",
    "\n",
    "# Call the function to get the teams split data\n",
    "team_vs_lhp             = teams_split(split_type= 'LHP',  clean_mode= 0) # GS empty\n",
    "team_vs_rhp             = teams_split(split_type= 'RHP',  clean_mode= 0) # GS empty\n",
    "team_vs_lh_starters     = teams_split(split_type= 'LH',   clean_mode= 1)\n",
    "team_vs_rh_starters     = teams_split(split_type= 'RH',   clean_mode= 1)\n",
    "team_last_seven_days    = teams_split(split_type= '7',    clean_mode= 1)\n",
    "team_last_fourteen_days = teams_split(split_type= '14',   clean_mode= 1)\n",
    "team_last_28_days       = teams_split(split_type= '28',   clean_mode= 1)\n",
    "team_home_games         = teams_split(split_type= 'Home', clean_mode= 1)\n",
    "team_away_games         = teams_split(split_type= 'Away', clean_mode= 1)\n",
    "team_first_batter_game  = teams_split(split_type= 'first_batter_game', clean_mode= 0) # GS empty\n",
    "team_vs_power_pitcher   = teams_split(split_type= 'vs_power_pitcher',  clean_mode= 0) # GS empty\n",
    "team_vs_weak_pitcher    = teams_split(split_type= 'vs_weak_pitcher',   clean_mode= 0) # GS empty\n",
    "team_vs_power_team      = teams_split(split_type= 'vs_greater_or_equal_than_500_WP', clean_mode= 1)\n",
    "team_vs_weak_team       = teams_split(split_type= 'vs_less_than_500_WP',             clean_mode= 1)\n",
    "\n",
    "# # Direct matchups\n",
    "team_laa = teams_split(split_type= 'ANA', clean_mode= 1)\n",
    "team_ari = teams_split(split_type= 'ARI', clean_mode= 1)\n",
    "team_atl = teams_split(split_type= 'ATL', clean_mode= 1)\n",
    "team_bal = teams_split(split_type= 'BAL', clean_mode= 1)\n",
    "team_bos = teams_split(split_type= 'BOS', clean_mode= 1)\n",
    "team_chc = teams_split(split_type= 'CHC', clean_mode= 1)\n",
    "team_chw = teams_split(split_type= 'CHW', clean_mode= 1)\n",
    "team_cin = teams_split(split_type= 'CIN', clean_mode= 1)\n",
    "team_cle = teams_split(split_type= 'CLE', clean_mode= 1)\n",
    "team_col = teams_split(split_type= 'COL', clean_mode= 1)\n",
    "team_det = teams_split(split_type= 'DET', clean_mode= 1)\n",
    "team_hou = teams_split(split_type= 'HOU', clean_mode= 1)\n",
    "team_kcr = teams_split(split_type= 'KCR', clean_mode= 1)\n",
    "team_lad = teams_split(split_type= 'LAD', clean_mode= 1)\n",
    "team_mia = teams_split(split_type= 'FLA', clean_mode= 1) \n",
    "team_mil = teams_split(split_type= 'MIL', clean_mode= 1)\n",
    "team_min = teams_split(split_type= 'MIN', clean_mode= 1)\n",
    "team_nym = teams_split(split_type= 'NYM', clean_mode= 1)\n",
    "team_nyy = teams_split(split_type= 'NYY', clean_mode= 1)\n",
    "team_oak = teams_split(split_type= 'OAK', clean_mode= 1)\n",
    "team_phi = teams_split(split_type= 'PHI', clean_mode= 1)\n",
    "team_pit = teams_split(split_type= 'PIT', clean_mode= 1)\n",
    "team_sdp = teams_split(split_type= 'SDP', clean_mode= 1)\n",
    "team_sea = teams_split(split_type= 'SEA', clean_mode= 1)\n",
    "team_sfg = teams_split(split_type= 'SFG', clean_mode= 1)\n",
    "team_stl = teams_split(split_type= 'STL', clean_mode= 1)\n",
    "team_tbr = teams_split(split_type= 'TBD', clean_mode= 1)\n",
    "team_tex = teams_split(split_type= 'TEX', clean_mode= 1)\n",
    "team_tor = teams_split(split_type= 'TOR', clean_mode= 1)\n",
    "team_wsn = teams_split(split_type= 'WSN', clean_mode= 1)\n",
    "\n",
    "# Dictionary of dataframes for the teams\n",
    "dic_team = {\n",
    "    'LAA': team_laa,\n",
    "    'AZ': team_ari,\n",
    "    'ATL': team_atl,\n",
    "    'BAL': team_bal,\n",
    "    'BOS': team_bos,\n",
    "    'CHC': team_chc,\n",
    "    'CHW': team_chw,\n",
    "    'CIN': team_cin,\n",
    "    'CLE': team_cle,\n",
    "    'COL': team_col,\n",
    "    'DET': team_det,\n",
    "    'HOU': team_hou,\n",
    "    'KC': team_kcr,\n",
    "    'LAD': team_lad,\n",
    "    'MIA': team_mia,\n",
    "    'MIL': team_mil,\n",
    "    'MIN': team_min,\n",
    "    'NYM': team_nym,\n",
    "    'NYY': team_nyy,\n",
    "    'ATH': team_oak,\n",
    "    'PHI': team_phi,\n",
    "    'PIT': team_pit,\n",
    "    'SD': team_sdp,\n",
    "    'SEA': team_sea,\n",
    "    'SF': team_sfg,\n",
    "    'STL': team_stl,\n",
    "    'TB': team_tbr,\n",
    "    'TEX': team_tex,\n",
    "    'TOR': team_tor,\n",
    "    'WSH': team_wsn   \n",
    "    }\n",
    "\n",
    "# Add an ID column with the dictionary key as the identifier\n",
    "for key, df in dic_team.items():\n",
    "    df['ID'] = key  # Assign the dictionary key as the ID\n",
    "\n",
    "# Concatenate all dataFrames in the dictionary\n",
    "direct_matches = pd.concat(dic_team.values(), ignore_index=True)  # Resets index\n",
    "\n",
    "dic_splits = {\n",
    "    'team_vs_lhp'        :team_vs_lhp,        \n",
    "    'team_vs_rhp'        :team_vs_rhp,\n",
    "    'team_vs_lh_starters':team_vs_lh_starters,\n",
    "    'team_vs_rh_starters':team_vs_rh_starters,\n",
    "    'team_last_seven_days':team_last_seven_days,\n",
    "    'team_last_fourteen_days':team_last_fourteen_days,\n",
    "    'team_last_28_days':team_last_28_days,\n",
    "    'team_home_games':team_home_games,\n",
    "    'team_away_games':team_away_games,\n",
    "    'team_first_batter_game':team_first_batter_game,\n",
    "    'team_vs_power_pitcher':team_vs_power_pitcher,\n",
    "    'team_vs_weak_pitcher':team_vs_weak_pitcher,\n",
    "    'team_vs_power_team':team_vs_power_team,\n",
    "    'team_vs_weak_team':team_vs_weak_team      \n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "68b2a5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "team_split1 table loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "options = Options()\n",
    "options.add_argument(\"--headless\")  # Optional: Run in headless mode\n",
    "options.binary_location = \"C:\\\\Program Files\\\\BraveSoftware\\\\Brave-Browser\\\\Application\\\\brave.exe\"\n",
    "\n",
    "# Define year\n",
    "year = datetime.now().year\n",
    "\n",
    "# Set up the WebDriver\n",
    "driver = webdriver.Chrome(options= options)  \n",
    "\n",
    "# for LHP and RHP pitchers\n",
    "driver.get(f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=plato%7Cvs%20LHP%7CNYY%7C2025%7Cbat%7CAB%7C\")\n",
    "\n",
    "# Name of the table\n",
    "datatable_id = 'team_split1'\n",
    "\n",
    "# Explicitly wait for the table element to load\n",
    "datatable_xpath = f\"//table[@id='{datatable_id}']\"  # Update XPATH as needed\n",
    "try:\n",
    "    WebDriverWait(driver, 60).until(\n",
    "        EC.presence_of_element_located((By.XPATH, datatable_xpath))\n",
    "    )\n",
    "    print(f\"{datatable_id} table loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error: Table {datatable_id} did not load. Details: {e}\")\n",
    "    driver.quit()\n",
    "\n",
    "# Wait for the load of the page\n",
    "time.sleep(10)\n",
    "\n",
    "# Locate the table\n",
    "table_element = driver.find_element(By.XPATH, datatable_xpath)\n",
    "text_content = table_element.text\n",
    "\n",
    "# Process the table content\n",
    "rows = text_content.split(\"\\n\")\n",
    "table_data = [row.split(\"\\t\") for row in rows]\n",
    "\n",
    "# Convert to dataframe\n",
    "df = pd.DataFrame(table_data)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "14359c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Table team_split1 did not load. Details: Message: \n",
      "Stacktrace:\n",
      "Symbols not available. Dumping unresolved backtrace:\n",
      "\t0x7ff706e18245\n",
      "\t0x7ff706e182a0\n",
      "\t0x7ff706bf165d\n",
      "\t0x7ff706c49a33\n",
      "\t0x7ff706c49d3c\n",
      "\t0x7ff706c9df67\n",
      "\t0x7ff706c9ac97\n",
      "\t0x7ff706c3ac29\n",
      "\t0x7ff706c3ba93\n",
      "\t0x7ff70712ffe0\n",
      "\t0x7ff70712a920\n",
      "\t0x7ff707149086\n",
      "\t0x7ff706e35744\n",
      "\t0x7ff706e3e6ec\n",
      "\t0x7ff706e21964\n",
      "\t0x7ff706e21b15\n",
      "\t0x7ff706e07842\n",
      "\t0x7ffe40abe8d7\n",
      "\t0x7ffe4112c53c\n",
      "\n"
     ]
    },
    {
     "ename": "MaxRetryError",
     "evalue": "HTTPConnectionPool(host='localhost', port=53784): Max retries exceeded with url: /session/99c49fdf6522acf5ac9e49be4c8825ee/element (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001879EDFB530>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionRefusedError\u001b[0m                    Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\urllib3\\connection.py:198\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 198\u001b[0m     sock \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m socket\u001b[38;5;241m.\u001b[39mgaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\urllib3\\util\\connection.py:85\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[0;32m     72\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[1;32m---> 73\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n",
      "\u001b[1;31mConnectionRefusedError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\urllib3\\connectionpool.py:793\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 793\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    794\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    795\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    796\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    797\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    798\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    799\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    800\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    801\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    802\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    803\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    804\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    806\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\urllib3\\connectionpool.py:496\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 496\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    503\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    504\u001b[0m \u001b[43m        \u001b[49m\u001b[43menforce_content_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menforce_content_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m \u001b[38;5;66;03m# We are swallowing BrokenPipeError (errno.EPIPE) since the server is\u001b[39;00m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;66;03m# legitimately able to close the connection after sending a valid response.\u001b[39;00m\n\u001b[0;32m    509\u001b[0m \u001b[38;5;66;03m# With this behaviour, the received response is still readable.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\urllib3\\connection.py:400\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, chunked, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mputheader(header, value)\n\u001b[1;32m--> 400\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    402\u001b[0m \u001b[38;5;66;03m# If we're given a body we start sending that in chunks.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python312\\Lib\\http\\client.py:1326\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1326\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Python312\\Lib\\http\\client.py:1085\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1084\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1085\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1087\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1088\u001b[0m \n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Program Files\\Python312\\Lib\\http\\client.py:1029\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1028\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m-> 1029\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\urllib3\\connection.py:238\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n\u001b[0;32m    240\u001b[0m         \u001b[38;5;66;03m# If we're tunneling it means we're connected to our proxy.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\urllib3\\connection.py:213\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 213\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[0;32m    214\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    215\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[0;32m    217\u001b[0m \u001b[38;5;66;03m# Audit hooks are only available in Python 3.8+\u001b[39;00m\n",
      "\u001b[1;31mNewConnectionError\u001b[0m: <urllib3.connection.HTTPConnection object at 0x000001879EDFB530>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[97], line 140\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# For each team, call the players_split function\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m team_abv \u001b[38;5;129;01min\u001b[39;00m team_abbreviations:\n\u001b[1;32m--> 140\u001b[0m     df_team_players_lhp \u001b[38;5;241m=\u001b[39m \u001b[43mplayers_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLHP\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteam_abv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mteam_abv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# GS empty\u001b[39;00m\n\u001b[0;32m    141\u001b[0m     df_team_players_rhp \u001b[38;5;241m=\u001b[39m players_split(split_type\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRHP\u001b[39m\u001b[38;5;124m'\u001b[39m, team_abv\u001b[38;5;241m=\u001b[39m team_abv, clean_mode\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# GS empty\u001b[39;00m\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;66;03m# You can store or process df_team_players_lhp and df_team_players_rhp as needed\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \n\u001b[0;32m    144\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;66;03m#     'team_vs_weak_team':team_vs_weak_team      \u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# }\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[97], line 60\u001b[0m, in \u001b[0;36mplayers_split\u001b[1;34m(split_type, team_abv, clean_mode)\u001b[0m\n\u001b[0;32m     57\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;66;03m# Locate the table\u001b[39;00m\n\u001b[1;32m---> 60\u001b[0m table_element \u001b[38;5;241m=\u001b[39m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatatable_xpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m text_content \u001b[38;5;241m=\u001b[39m table_element\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# Process the table content\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:741\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    738\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    739\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 741\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:345\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m params:\n\u001b[0;32m    343\u001b[0m         params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msessionId\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession_id\n\u001b[1;32m--> 345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommand_executor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver_command\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[0;32m    347\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merror_handler\u001b[38;5;241m.\u001b[39mcheck_response(response)\n",
      "File \u001b[1;32mc:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:302\u001b[0m, in \u001b[0;36mRemoteConnection.execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    300\u001b[0m trimmed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_trim_large_entries(params)\n\u001b[0;32m    301\u001b[0m LOGGER\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, command_info[\u001b[38;5;241m0\u001b[39m], url, \u001b[38;5;28mstr\u001b[39m(trimmed))\n\u001b[1;32m--> 302\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\selenium\\webdriver\\remote\\remote_connection.py:322\u001b[0m, in \u001b[0;36mRemoteConnection._request\u001b[1;34m(self, method, url, body)\u001b[0m\n\u001b[0;32m    319\u001b[0m     body \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkeep_alive:\n\u001b[1;32m--> 322\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    323\u001b[0m     statuscode \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mstatus\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\urllib3\\_request_methods.py:144\u001b[0m, in \u001b[0;36mRequestMethods.request\u001b[1;34m(self, method, url, body, fields, headers, json, **urlopen_kw)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_encode_url(\n\u001b[0;32m    137\u001b[0m         method,\n\u001b[0;32m    138\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    141\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39murlopen_kw,\n\u001b[0;32m    142\u001b[0m     )\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_encode_body\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfields\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43murlopen_kw\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\urllib3\\_request_methods.py:279\u001b[0m, in \u001b[0;36mRequestMethods.request_encode_body\u001b[1;34m(self, method, url, fields, headers, encode_multipart, multipart_boundary, **urlopen_kw)\u001b[0m\n\u001b[0;32m    275\u001b[0m     extra_kw[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mheaders\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m, content_type)\n\u001b[0;32m    277\u001b[0m extra_kw\u001b[38;5;241m.\u001b[39mupdate(urlopen_kw)\n\u001b[1;32m--> 279\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\urllib3\\poolmanager.py:444\u001b[0m, in \u001b[0;36mPoolManager.urlopen\u001b[1;34m(self, method, url, redirect, **kw)\u001b[0m\n\u001b[0;32m    442\u001b[0m     response \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39murlopen(method, url, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest_uri\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    446\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n\u001b[0;32m    447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m redirect_location:\n",
      "File \u001b[1;32mc:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\urllib3\\connectionpool.py:877\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    874\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    875\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    876\u001b[0m     )\n\u001b[1;32m--> 877\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    896\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32mc:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\urllib3\\connectionpool.py:877\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    874\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    875\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    876\u001b[0m     )\n\u001b[1;32m--> 877\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    896\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32mc:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\urllib3\\connectionpool.py:877\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    872\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn:\n\u001b[0;32m    873\u001b[0m     \u001b[38;5;66;03m# Try again\u001b[39;00m\n\u001b[0;32m    874\u001b[0m     log\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[0;32m    875\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRetrying (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) after connection broken by \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, retries, err, url\n\u001b[0;32m    876\u001b[0m     )\n\u001b[1;32m--> 877\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    883\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    884\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    885\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    886\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpool_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    887\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrelease_conn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrelease_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    888\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    889\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody_pos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody_pos\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    890\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    891\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    892\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    893\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    895\u001b[0m \u001b[38;5;66;03m# Handle redirect?\u001b[39;00m\n\u001b[0;32m    896\u001b[0m redirect_location \u001b[38;5;241m=\u001b[39m redirect \u001b[38;5;129;01mand\u001b[39;00m response\u001b[38;5;241m.\u001b[39mget_redirect_location()\n",
      "File \u001b[1;32mc:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\urllib3\\connectionpool.py:847\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    844\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(new_e, (\u001b[38;5;167;01mOSError\u001b[39;00m, HTTPException)):\n\u001b[0;32m    845\u001b[0m     new_e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, new_e)\n\u001b[1;32m--> 847\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    848\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m    849\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    850\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n\u001b[0;32m    852\u001b[0m \u001b[38;5;66;03m# Keep track of the error for the retry warning.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\adtpi\\python_environments\\PY_312_DEVELOPMENT\\Lib\\site-packages\\urllib3\\util\\retry.py:515\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[0;32m    514\u001b[0m     reason \u001b[38;5;241m=\u001b[39m error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[1;32m--> 515\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    517\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n\u001b[0;32m    519\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_retry\n",
      "\u001b[1;31mMaxRetryError\u001b[0m: HTTPConnectionPool(host='localhost', port=53784): Max retries exceeded with url: /session/99c49fdf6522acf5ac9e49be4c8825ee/element (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001879EDFB530>: Failed to establish a new connection: [WinError 10061] No connection could be made because the target machine actively refused it'))"
     ]
    }
   ],
   "source": [
    "def players_split(split_type, team_abv, clean_mode):\n",
    "    # Load the options\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")  # Optional: Run in headless mode\n",
    "    options.binary_location = \"C:\\\\Program Files\\\\BraveSoftware\\\\Brave-Browser\\\\Application\\\\brave.exe\"\n",
    "\n",
    "    # Define year\n",
    "    year = datetime.now().year\n",
    "    \n",
    "    # Set up the WebDriver\n",
    "    driver = webdriver.Chrome(options= options)  \n",
    "\n",
    "    if split_type == 'LHP' or split_type == 'RHP': # for LHP and RHP pitchers\n",
    "        driver.get(f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=plato%7Cvs%20{split_type}%7C{team_abv}%7C{year}%7Cbat%7CAB%7C\")\n",
    "        \n",
    "    # elif split_type == '7' or split_type == '14' or split_type == '28': # for the last 7, 14 and 28 days\n",
    "    #     driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=total%7CLast%20{split_type}%20days%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    # elif split_type == 'RH' or split_type == 'LH': # for RH and LH Starters\n",
    "    #     driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=plato%7Cvs%20{split_type}%20Starter%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    # elif split_type == 'Home' or split_type == 'Away': # for home and away games\n",
    "    #     driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=hmvis%7C{split_type}%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    # elif split_type == 'first_batter_game':\n",
    "    #     driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=leado%7C1st%20Batter%20G%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    # elif split_type == 'vs_power_pitcher':\n",
    "    #     driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=power%7Cvs.%20Power%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    # elif split_type == 'vs_weak_pitcher':\n",
    "    #     driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=power%7Cvs.%20Finesse%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    # # For each team:\n",
    "    # elif split_type == 'ANA' or split_type == 'ARI' or split_type == 'ATL' or split_type == 'BAL' or split_type == 'BOS' \\\n",
    "    #     or split_type == 'CHC' or split_type == 'CHW' or split_type == 'CIN' or split_type == 'CLE' or split_type == 'COL' \\\n",
    "    #     or split_type == 'DET' or split_type == 'HOU' or split_type == 'KCR' or split_type == 'LAD' or split_type == 'FLA' \\\n",
    "    #     or split_type == 'MIL' or split_type == 'MIN' or split_type == 'NYM' or split_type == 'NYY' or split_type == 'OAK' \\\n",
    "    #     or split_type == 'PHI' or split_type == 'PIT' or split_type == 'SDP' or split_type == 'SEA' or split_type == 'SFG' \\\n",
    "    #     or split_type == 'STL' or split_type == 'TBD' or split_type == 'TEX' or split_type == 'TOR' or split_type == 'WSN':\n",
    "    #         driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=oppon%7C{split_type}%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    # elif split_type == 'vs_less_than_500_WP':\n",
    "    #     driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=oppon%7CWP%20%3C%20.500%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    # elif split_type == 'vs_greater_or_equal_than_500_WP':\n",
    "    #     driver.get(f\"https://www.baseball-reference.com/tools/split_stats_lg.cgi?full=1&params=oppon%7CWP%20%3E%3D%20.500%7CML%7C{year}%7Cbat%7CAB%7C\")\n",
    "    \n",
    "    \n",
    "    # Name of the table\n",
    "    datatable_id = 'team_split1'\n",
    "\n",
    "    # Explicitly wait for the table element to load\n",
    "    datatable_xpath = f\"//table[@id='{datatable_id}']\"  # Update XPATH as needed\n",
    "    try:\n",
    "        WebDriverWait(driver, 60).until(\n",
    "            EC.presence_of_element_located((By.XPATH, datatable_xpath))\n",
    "        )\n",
    "        print(f\"{datatable_id} ({split_type}) table loaded successfully.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Table {datatable_id} did not load. Details: {e}\")\n",
    "        driver.quit()\n",
    "\n",
    "    # Wait for the load of the page\n",
    "    time.sleep(10)\n",
    "\n",
    "    # Locate the table\n",
    "    table_element = driver.find_element(By.XPATH, datatable_xpath)\n",
    "    text_content = table_element.text\n",
    "\n",
    "    # Process the table content\n",
    "    rows = text_content.split(\"\\n\")\n",
    "    table_data = [row.split(\"\\t\") for row in rows]\n",
    "\n",
    "    # Convert to dataframe\n",
    "    df = pd.DataFrame(table_data)\n",
    "    \n",
    "    # Close the WebDriver\n",
    "    driver.quit()    \n",
    "    \n",
    "    if clean_mode == 1:\n",
    "        # Remove 'Roe' exactly (case-sensitive)\n",
    "        df[0] = df[0].str.replace('Roe', '', regex=False)\n",
    "\n",
    "        # Remove last row\n",
    "        df = df.iloc[:-1]\n",
    "\n",
    "        # Split column from right using spaces\n",
    "        df = df[0].str.split(\" \", n= 30, expand=True)\n",
    "\n",
    "        # Set first row as header\n",
    "        df.columns = df.iloc[0]  # Assign first row as column names\n",
    "        df = df[1:].reset_index(drop=True)  # Remove first row and reset index\n",
    "\n",
    "        # Remove the last column\n",
    "        df = df.iloc[:, :-1]\n",
    "\n",
    "        # Rename last 3 columns\n",
    "        new_column_names = [\"BAbip\", \"tOPS+\", \"sOPS+\"]  # New names for last 3 columns\n",
    "        df.columns.values[-3:] = new_column_names  # Assign new names\n",
    "\n",
    "        # Remove the first column\n",
    "        df = df.iloc[:, 1:]\n",
    "    else:\n",
    "        # Remove 'Roe' and GS exactly (case-sensitive)\n",
    "        df[0] = df[0].str.replace('Roe', '', regex=False)\n",
    "        df[0] = df[0].str.replace('GS', '', regex=False)\n",
    "\n",
    "        # Remove last row\n",
    "        df = df.iloc[:-1]\n",
    "\n",
    "        # Remove rows where column 'A' contains 'Rk', but keep the first row\n",
    "        df = df[~((df.index > 0) & (df[0].str.contains('Rk', na=False)))]\n",
    "\n",
    "        # Split column from right using spaces\n",
    "        df = df[0].str.split(\" \", n= 30, expand=True)\n",
    "\n",
    "        # Set first row as header\n",
    "        df.columns = df.iloc[0]  # Assign first row as column names\n",
    "        df = df[1:].reset_index(drop=True)  # Remove first row and reset index\n",
    "\n",
    "        # Remove the first column\n",
    "        df = df.iloc[:, 1:]\n",
    "\n",
    "        # Remove the last 2 columns\n",
    "        df = df.iloc[:, :-2]\n",
    "\n",
    "        # New column names\n",
    "        new_column_names = ['Team', 'G', 'PA', 'AB', 'R', 'H', '2B', '3B', 'HR', 'RBI', 'SB',\n",
    "                            'CS', 'BB', 'SO', 'BA', 'OBP', 'SLG', 'OPS', 'TB', 'GDP', 'HBP', 'SH',\n",
    "                            'SF', 'IBB', 'ROE', 'BAbip', 'tOPS+', 'sOPS+']\n",
    "\n",
    "        # Rename all columns\n",
    "        df.columns = new_column_names\n",
    "\n",
    "    return df\n",
    "\n",
    "# Create a list with the team abbreviations\n",
    "team_abbreviations = ['NYA', 'BOS', 'TBA', 'TOR', 'BAL',\n",
    "                    'CHW', 'CLE', 'DET', 'KCA', 'MIN',\n",
    "                    'HOU', 'LAA', 'OAK', 'SEA', 'TEX',\n",
    "                    'ATL', 'MIA', 'NYN', 'PHI', 'WSN',\n",
    "                    'CIN', 'CHN', 'MIL', 'PIT', 'STL',\n",
    "                    'COL', 'LAD', 'SDP', 'SFG', 'ARI']\n",
    "\n",
    "# For each team, call the players_split function\n",
    "for team_abv in team_abbreviations:\n",
    "    df_team_players_lhp = players_split(split_type= 'LHP', team_abv= team_abv, clean_mode= 0) # GS empty\n",
    "    df_team_players_rhp = players_split(split_type= 'RHP', team_abv= team_abv, clean_mode= 0) # GS empty\n",
    "    # You can store or process df_team_players_lhp and df_team_players_rhp as needed\n",
    "\n",
    "\n",
    "\n",
    "# Call the function to get the teams split data\n",
    "#team_vs_lhp             = teams_split(split_type= 'LHP',  clean_mode= 0) # GS empty\n",
    "# team_vs_rhp             = teams_split(split_type= 'RHP',  clean_mode= 0) # GS empty\n",
    "# team_vs_lh_starters     = teams_split(split_type= 'LH',   clean_mode= 1)\n",
    "# team_vs_rh_starters     = teams_split(split_type= 'RH',   clean_mode= 1)\n",
    "# team_last_seven_days    = teams_split(split_type= '7',    clean_mode= 1)\n",
    "# team_last_fourteen_days = teams_split(split_type= '14',   clean_mode= 1)\n",
    "# team_last_28_days       = teams_split(split_type= '28',   clean_mode= 1)\n",
    "# team_home_games         = teams_split(split_type= 'Home', clean_mode= 1)\n",
    "# team_away_games         = teams_split(split_type= 'Away', clean_mode= 1)\n",
    "# team_first_batter_game  = teams_split(split_type= 'first_batter_game', clean_mode= 0) # GS empty\n",
    "# team_vs_power_pitcher   = teams_split(split_type= 'vs_power_pitcher',  clean_mode= 0) # GS empty\n",
    "# team_vs_weak_pitcher    = teams_split(split_type= 'vs_weak_pitcher',   clean_mode= 0) # GS empty\n",
    "# team_vs_power_team      = teams_split(split_type= 'vs_greater_or_equal_than_500_WP', clean_mode= 1)\n",
    "# team_vs_weak_team       = teams_split(split_type= 'vs_less_than_500_WP',             clean_mode= 1)\n",
    "\n",
    "# # # Direct matchups\n",
    "# team_laa = teams_split(split_type= 'ANA', clean_mode= 1)\n",
    "# team_ari = teams_split(split_type= 'ARI', clean_mode= 1)\n",
    "# team_atl = teams_split(split_type= 'ATL', clean_mode= 1)\n",
    "# team_bal = teams_split(split_type= 'BAL', clean_mode= 1)\n",
    "# team_bos = teams_split(split_type= 'BOS', clean_mode= 1)\n",
    "# team_chc = teams_split(split_type= 'CHC', clean_mode= 1)\n",
    "# team_chw = teams_split(split_type= 'CHW', clean_mode= 1)\n",
    "# team_cin = teams_split(split_type= 'CIN', clean_mode= 1)\n",
    "# team_cle = teams_split(split_type= 'CLE', clean_mode= 1)\n",
    "# team_col = teams_split(split_type= 'COL', clean_mode= 1)\n",
    "# team_det = teams_split(split_type= 'DET', clean_mode= 1)\n",
    "# team_hou = teams_split(split_type= 'HOU', clean_mode= 1)\n",
    "# team_kcr = teams_split(split_type= 'KCR', clean_mode= 1)\n",
    "# team_lad = teams_split(split_type= 'LAD', clean_mode= 1)\n",
    "# team_mia = teams_split(split_type= 'FLA', clean_mode= 1) \n",
    "# team_mil = teams_split(split_type= 'MIL', clean_mode= 1)\n",
    "# team_min = teams_split(split_type= 'MIN', clean_mode= 1)\n",
    "# team_nym = teams_split(split_type= 'NYM', clean_mode= 1)\n",
    "# team_nyy = teams_split(split_type= 'NYY', clean_mode= 1)\n",
    "# team_oak = teams_split(split_type= 'OAK', clean_mode= 1)\n",
    "# team_phi = teams_split(split_type= 'PHI', clean_mode= 1)\n",
    "# team_pit = teams_split(split_type= 'PIT', clean_mode= 1)\n",
    "# team_sdp = teams_split(split_type= 'SDP', clean_mode= 1)\n",
    "# team_sea = teams_split(split_type= 'SEA', clean_mode= 1)\n",
    "# team_sfg = teams_split(split_type= 'SFG', clean_mode= 1)\n",
    "# team_stl = teams_split(split_type= 'STL', clean_mode= 1)\n",
    "# team_tbr = teams_split(split_type= 'TBD', clean_mode= 1)\n",
    "# team_tex = teams_split(split_type= 'TEX', clean_mode= 1)\n",
    "# team_tor = teams_split(split_type= 'TOR', clean_mode= 1)\n",
    "# team_wsn = teams_split(split_type= 'WSN', clean_mode= 1)\n",
    "\n",
    "# # Dictionary of dataframes for the teams\n",
    "# dic_team = {\n",
    "#     'LAA': team_laa,\n",
    "#     'AZ': team_ari,\n",
    "#     'ATL': team_atl,\n",
    "#     'BAL': team_bal,\n",
    "#     'BOS': team_bos,\n",
    "#     'CHC': team_chc,\n",
    "#     'CHW': team_chw,\n",
    "#     'CIN': team_cin,\n",
    "#     'CLE': team_cle,\n",
    "#     'COL': team_col,\n",
    "#     'DET': team_det,\n",
    "#     'HOU': team_hou,\n",
    "#     'KC': team_kcr,\n",
    "#     'LAD': team_lad,\n",
    "#     'MIA': team_mia,\n",
    "#     'MIL': team_mil,\n",
    "#     'MIN': team_min,\n",
    "#     'NYM': team_nym,\n",
    "#     'NYY': team_nyy,\n",
    "#     'ATH': team_oak,\n",
    "#     'PHI': team_phi,\n",
    "#     'PIT': team_pit,\n",
    "#     'SD': team_sdp,\n",
    "#     'SEA': team_sea,\n",
    "#     'SF': team_sfg,\n",
    "#     'STL': team_stl,\n",
    "#     'TB': team_tbr,\n",
    "#     'TEX': team_tex,\n",
    "#     'TOR': team_tor,\n",
    "#     'WSH': team_wsn   \n",
    "#     }\n",
    "\n",
    "# # Add an ID column with the dictionary key as the identifier\n",
    "# for key, df in dic_team.items():\n",
    "#     df['ID'] = key  # Assign the dictionary key as the ID\n",
    "\n",
    "# # Concatenate all dataFrames in the dictionary\n",
    "# direct_matches = pd.concat(dic_team.values(), ignore_index=True)  # Resets index\n",
    "\n",
    "# dic_splits = {\n",
    "#     'team_vs_lhp'        :team_vs_lhp,        \n",
    "#     'team_vs_rhp'        :team_vs_rhp,\n",
    "#     'team_vs_lh_starters':team_vs_lh_starters,\n",
    "#     'team_vs_rh_starters':team_vs_rh_starters,\n",
    "#     'team_last_seven_days':team_last_seven_days,\n",
    "#     'team_last_fourteen_days':team_last_fourteen_days,\n",
    "#     'team_last_28_days':team_last_28_days,\n",
    "#     'team_home_games':team_home_games,\n",
    "#     'team_away_games':team_away_games,\n",
    "#     'team_first_batter_game':team_first_batter_game,\n",
    "#     'team_vs_power_pitcher':team_vs_power_pitcher,\n",
    "#     'team_vs_weak_pitcher':team_vs_weak_pitcher,\n",
    "#     'team_vs_power_team':team_vs_power_team,\n",
    "#     'team_vs_weak_team':team_vs_weak_team      \n",
    "# }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "b0229e23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL: https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=plato%7Cvs%20LHP%7CNYY%7C2025%7Cbat%7CAB%7C\n",
      "Table team_split1 (LHP vs NYY) loaded successfully.\n",
      "URL: https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=plato%7Cvs%20RHP%7CNYY%7C2025%7Cbat%7CAB%7C\n",
      "Table team_split1 (RHP vs NYY) loaded successfully.\n",
      "URL: https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=plato%7Cvs%20LHP%7CBOS%7C2025%7Cbat%7CAB%7C\n",
      "Table team_split1 (LHP vs BOS) loaded successfully.\n",
      "URL: https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=plato%7Cvs%20RHP%7CBOS%7C2025%7Cbat%7CAB%7C\n",
      "Table team_split1 (RHP vs BOS) loaded successfully.\n",
      "URL: https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=plato%7Cvs%20LHP%7CTBR%7C2025%7Cbat%7CAB%7C\n",
      "Table team_split1 (LHP vs TBR) loaded successfully.\n",
      "URL: https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=plato%7Cvs%20RHP%7CTBR%7C2025%7Cbat%7CAB%7C\n",
      "Table team_split1 (RHP vs TBR) loaded successfully.\n",
      "URL: https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=plato%7Cvs%20LHP%7CTOR%7C2025%7Cbat%7CAB%7C\n",
      "Table team_split1 (LHP vs TOR) loaded successfully.\n",
      "URL: https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=plato%7Cvs%20RHP%7CTOR%7C2025%7Cbat%7CAB%7C\n",
      "Table team_split1 (RHP vs TOR) loaded successfully.\n",
      "URL: https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=plato%7Cvs%20LHP%7CBAL%7C2025%7Cbat%7CAB%7C\n",
      "Table team_split1 (LHP vs BAL) loaded successfully.\n",
      "URL: https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=plato%7Cvs%20RHP%7CBAL%7C2025%7Cbat%7CAB%7C\n",
      "Table team_split1 (RHP vs BAL) loaded successfully.\n",
      "\n",
      "--- Final Concatenated Player Splits ---\n",
      "                                                   0 Split_Type Team\n",
      "0  Rk Name G GS PA AB R H 2B 3B HR RBI SB CS BB S...     vs_LHP  NYY\n",
      "1  1 Aaron Judge 77 161 123 48 42 7 0 16 30 3 2 3...     vs_LHP  NYY\n",
      "2  2 José Caballero 16 31 25 6 7 3 0 2 2 4 1 5 7 ...     vs_LHP  NYY\n",
      "3  3 Cody Bellinger 93 176 153 30 54 10 2 8 36 5 ...     vs_LHP  NYY\n",
      "4  4 Paul Goldschmidt 82 168 149 26 50 14 0 7 16 ...     vs_LHP  NYY\n",
      "5  5 Giancarlo Stanton 46 78 65 7 18 3 0 5 24 0 0...     vs_LHP  NYY\n",
      "6  6 Amed Rosario 15 29 29 1 9 3 0 1 5 0 0 0 6 .3...     vs_LHP  NYY\n",
      "7  7 Ben Rice 67 119 106 17 22 6 1 7 18 1 0 10 33...     vs_LHP  NYY\n",
      "8  8 Austin Wells 72 137 125 15 30 6 1 6 28 4 0 8...     vs_LHP  NYY\n",
      "9  9 Jorbit Vivas 5 6 5 3 1 1 0 0 0 0 0 1 0 .200 ...     vs_LHP  NYY\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def players_split(split_type, team_abv, clean_mode):\n",
    "    # --- 1. SETUP (Only here because the logic is complex) ---\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.binary_location = \"C:\\\\Program Files\\\\BraveSoftware\\\\Brave-Browser\\\\Application\\\\brave.exe\"\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    year = datetime.now().year\n",
    "    \n",
    "    # --- 2. URL CONSTRUCTION ---\n",
    "    if split_type == 'LHP' or split_type == 'RHP': \n",
    "        # Correct URL for PLAYER splits for a specific TEAM (using team_abv)\n",
    "        url = f\"https://www.baseball-reference.com/tools/split_stats_team.cgi?full=1&params=plato%7Cvs%20{split_type}%7C{team_abv}%7C{year}%7Cbat%7CAB%7C\"\n",
    "        datatable_id = 'team_split1' # <-- CORRECTED ID FOR PLAYER SPLITS\n",
    "    else:\n",
    "        # Handle other split types or raise an error\n",
    "        print(f\"Error: Split type '{split_type}' not supported yet.\")\n",
    "        driver.quit()\n",
    "        return pd.DataFrame() # Return empty DataFrame on failure\n",
    "\n",
    "    driver.get(url)\n",
    "    \n",
    "    # --- 3. WAIT AND EXTRACT ---\n",
    "    datatable_xpath = f\"//table[@id='{datatable_id}']\"\n",
    "    try:\n",
    "        WebDriverWait(driver, 60).until(\n",
    "            EC.presence_of_element_located((By.XPATH, datatable_xpath))\n",
    "        )\n",
    "        print(f\"URL: {url}\")\n",
    "        print(f\"Table {datatable_id} ({split_type} vs {team_abv}) loaded successfully.\")\n",
    "\n",
    "        table_element = driver.find_element(By.XPATH, datatable_xpath)\n",
    "        text_content = table_element.text\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: Table {datatable_id} did not load. Details: {e}\")\n",
    "        driver.quit()\n",
    "        return pd.DataFrame()\n",
    "    finally:\n",
    "        driver.quit() # Close the driver in a finally block to ensure it closes\n",
    "        \n",
    "    # --- 4. DATA PROCESSING (Keep this logic) ---\n",
    "    rows = text_content.split(\"\\n\")\n",
    "    table_data = [row.split(\"\\t\") for row in rows]\n",
    "    df = pd.DataFrame(table_data)\n",
    "    \n",
    "    # ... (Your cleanup logic for clean_mode 0 or 1 remains here) ...\n",
    "    # This is where the complex splitting, renaming, and removal happens.\n",
    "    \n",
    "    # Placeholder for the cleanup logic to make the function runnable\n",
    "    if df.empty: return pd.DataFrame() \n",
    "    # NOTE: You would re-insert your full cleanup logic here.\n",
    "\n",
    "    return df # Return the resulting DataFrame\n",
    "\n",
    "# --- EXECUTION ---\n",
    "team_abbreviations = ['NYY', 'BOS', 'TBR', 'TOR', 'BAL'] # Use a small list for testing\n",
    "all_player_splits = []\n",
    "\n",
    "for team_abv in team_abbreviations:\n",
    "    df_lhp = players_split(split_type='LHP', team_abv=team_abv, clean_mode=0)\n",
    "    if not df_lhp.empty:\n",
    "        df_lhp['Split_Type'] = 'vs_LHP'\n",
    "        df_lhp['Team'] = team_abv\n",
    "        all_player_splits.append(df_lhp)\n",
    "\n",
    "    df_rhp = players_split(split_type='RHP', team_abv=team_abv, clean_mode=0)\n",
    "    if not df_rhp.empty:\n",
    "        df_rhp['Split_Type'] = 'vs_RHP'\n",
    "        df_rhp['Team'] = team_abv\n",
    "        all_player_splits.append(df_rhp)\n",
    "\n",
    "final_df = pd.concat(all_player_splits, ignore_index=True)\n",
    "print(\"\\n--- Final Concatenated Player Splits ---\")\n",
    "print(final_df.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PY_312_DEVELOPMENT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
