{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1ecb1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import pybaseball as pyb\n",
    "import pybaseball.cache # Ensure caching is imported\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "from datetime import date, timedelta\n",
    "from sqlalchemy.engine import Engine\n",
    "from sqlalchemy import text\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import WebDriverException, TimeoutException\n",
    "from rapidfuzz import process\n",
    "import re\n",
    "import numpy as np\n",
    "from io import StringIO\n",
    "import pylahman\n",
    "import statsapi\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97742fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection established.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Build the PostgreSQL connection string\n",
    "DB_URL = f\"postgresql://{os.environ['DB_USER']}:{os.environ['DB_PASS']}@{os.environ['DB_HOST']}:5432/{os.environ['DB_NAME']}\"\n",
    "\n",
    "# Create the engine object for connecting\n",
    "engine = create_engine(DB_URL)\n",
    "\n",
    "print(\"Database connection established.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a602196",
   "metadata": {},
   "source": [
    "Test - Pitcher archetype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9460fff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ffour_usage  sinker_usage  ffour_vaa_pct  velo_gap_pct  \\\n",
      "style_cluster                                                           \n",
      "0                    22.12         26.20          45.16         36.51   \n",
      "1                    44.82          5.34          56.19         60.08   \n",
      "2                    18.56         34.52          39.94         49.79   \n",
      "3                    41.78         16.62          21.14         32.18   \n",
      "4                    52.95          0.00          53.41         50.33   \n",
      "5                    33.01         22.99          56.30         55.70   \n",
      "6                    45.38          7.52          59.26         47.03   \n",
      "\n",
      "               paint_pct  fb_velo  whiff_pct  suppression_pct  \n",
      "style_cluster                                                  \n",
      "0                  43.90    92.95      46.15            56.90  \n",
      "1                  40.32    94.03      59.43            45.26  \n",
      "2                  24.34    93.84      52.30            61.46  \n",
      "3                  61.30    92.16      33.50            48.66  \n",
      "4                  48.63    93.76      59.23            42.05  \n",
      "5                  56.06    93.84      46.01            53.85  \n",
      "6                  47.46    94.47      55.87            46.54  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def run_scouting_model(df):\n",
    "    \"\"\"\n",
    "    Synthesizes pitching identity (GMM) with performance outcomes (Whiff/Barrel),\n",
    "    Perceived Power (Extension), and Vertical Separation.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Identity Features (Physical & Tactical only)\n",
    "    identity_features = [\n",
    "        'ffour_usage', 'sinker_usage', 'bb_usage', 'offspeed_usage',\n",
    "        'ffour_vaa_pct', 'sinker_vaa_pct', 'bb_vaa_pct', 'offspeed_vaa_pct',\n",
    "        'velo_gap_pct', 'command_pct', 'paint_pct'\n",
    "    ]\n",
    "    \n",
    "    # 2. Effectiveness Scores\n",
    "    df['lethality_score'] = (\n",
    "        (df['whiff_pct'] * 0.75) + \n",
    "        (df['suppression_pct'] * 0.20) + \n",
    "        (df['velo_pct'] * 0.05)\n",
    "    ).round(1)\n",
    "\n",
    "    # 3. Clustering (Archetype Definition)\n",
    "    scaler = StandardScaler()\n",
    "    scaled_identity = scaler.fit_transform(df[identity_features].fillna(0))\n",
    "    \n",
    "    gmm = GaussianMixture(n_components=7, random_state=42)\n",
    "    df['style_cluster'] = gmm.fit_predict(scaled_identity)\n",
    "\n",
    "    # 4. Outlier Detection (Unicorns)\n",
    "    iso = IsolationForest(contamination=0.04, random_state=42)\n",
    "    df['is_unicorn'] = iso.fit_predict(scaled_identity)\n",
    "    \n",
    "    def profile_pitcher_clusters(df):\n",
    "        # Defining the tactical metrics we want to see\n",
    "        # profile_metrics = [\n",
    "        #     'style_cluster', 'fb_velo', 'ffour_usage', 'sinker_usage', \n",
    "        #     'offspeed_usage', 'whiff_pct', 'paint_pct', 'vaa_plus_pct'\n",
    "        # ]\n",
    "        \n",
    "        profile_metrics = [\n",
    "        'style_cluster', \n",
    "        # DNA\n",
    "        'ffour_usage', 'sinker_usage', 'ffour_vaa_pct', 'velo_gap_pct', 'paint_pct',\n",
    "        # RESULTS\n",
    "        'fb_velo', 'whiff_pct', 'suppression_pct']\n",
    "        \n",
    "        # Calculate the mean for each cluster\n",
    "        profile = df[profile_metrics].groupby('style_cluster').mean().round(2)\n",
    "        \n",
    "        # Sort by whiff_pct to see the \"Dominance Hierarchy\"\n",
    "        #return profile.sort_values(by='whiff_pct', ascending=False)\n",
    "        return df[profile_metrics].groupby('style_cluster').mean().round(2)\n",
    "    \n",
    "    # Usage:\n",
    "    pitcher_profile_table = profile_pitcher_clusters(df)\n",
    "    print(pitcher_profile_table)\n",
    "    \n",
    "    def calculate_pitcher_grade(row):\n",
    "        # 1. STUFF+ (Physicality)\n",
    "        # This is the \"Weapon\" - 60% of the overall grade\n",
    "        stuff_plus = row['stuff_plus_pct']\n",
    "        \n",
    "        # 2. LOCATION+ (Surgicality)\n",
    "        # This is the \"Aim\" - 40% of the overall grade\n",
    "        location_plus = row['location_plus_pct']\n",
    "        \n",
    "        # 3. PITCHING+ (The Master Score)\n",
    "        # Note: We weigh Stuff higher because it's harder to find/teach\n",
    "        base_score = (stuff_plus * 0.60) + (location_plus * 0.40)\n",
    "        \n",
    "        # 4. VOLUME/STARTER ADJUSTMENTS\n",
    "        if row['is_starter'] == 1:\n",
    "            base_score += 5  # The \"Skubal Boost\"\n",
    "        \n",
    "        if row['total_appearances'] < 5:\n",
    "            base_score -= 10 # The \"Sample Size Penalty\"\n",
    "\n",
    "        # 5. FINAL LETTER GRADE\n",
    "        if base_score >= 85: \n",
    "            grade = 'A+'\n",
    "        elif base_score >= 75: \n",
    "            grade = 'A'\n",
    "        elif base_score >= 60: \n",
    "            grade = 'B'\n",
    "        elif base_score >= 45: \n",
    "            grade = 'C'\n",
    "        else: \n",
    "            grade = 'F'\n",
    "            \n",
    "        return grade, stuff_plus, location_plus\n",
    "\n",
    "    #df['overall_grade'] = df.apply(calculate_pitcher_grade, axis=1)\n",
    "    df[['overall_grade', 'stuff_plus_final', 'location_plus_final']] = df.apply(\n",
    "        lambda x: pd.Series(calculate_pitcher_grade(x)), axis=1\n",
    "    )\n",
    "\n",
    "\n",
    "    def generate_scouting_report(row):\n",
    "        tags = []\n",
    "        # Start the summary with the Grade and Handedness\n",
    "        summary_header = f\"[{row['overall_grade']} GRADE] ({row['hand']})\"\n",
    "        \n",
    "        # 1. CORE IDENTITY TAGS (Physicality)\n",
    "        s_plus = row['stuff_plus_pct']\n",
    "        l_plus = row['location_plus_pct']\n",
    "        \n",
    "        if s_plus >= 90: tags.append(\"üí£ PURE FILTH\")\n",
    "        elif s_plus <= 20: tags.append(\"üìâ LACKS BITE\")\n",
    "\n",
    "        if l_plus >= 90: tags.append(\"üéØ SURGEON\")\n",
    "        elif l_plus <= 20: tags.append(\"üèπ WILD THING\")\n",
    "\n",
    "        # 2. MATCHUP TACTICS (New Logic)\n",
    "        # We use the columns we just built in SQL\n",
    "        profile = row['attack_profile']\n",
    "        role = row['matchup_role']\n",
    "        platoon = row['platoon_identity']\n",
    "        \n",
    "        # Build the Narrative Summary\n",
    "        analysis = f\"Identified as a {role}. \"\n",
    "        \n",
    "        if \"NORTH-SOUTH\" in profile:\n",
    "            analysis += \"Wins vertically with high-carry fastballs; elite matchup against low-ball hitters. \"\n",
    "        elif \"EAST-WEST\" in profile:\n",
    "            analysis += \"Heavy horizontal movement profile; ideal for inducing double plays. \"\n",
    "        \n",
    "        if platoon == \"MATCHUP PROOF\":\n",
    "            tags.append(\"üõ°Ô∏è PLATOON NEUTRAL\")\n",
    "            analysis += \"Maintains effectiveness regardless of batter handedness. \"\n",
    "        elif platoon == \"PLATOON SENSITIVE\":\n",
    "            tags.append(\"‚ö†Ô∏è SPLIT RISK\")\n",
    "            analysis += \"Performance drops significantly against opposite-handed hitters. \"\n",
    "\n",
    "        # 3. SPECIAL TRAITS\n",
    "        if row['tunnel_pct'] >= 90: tags.append(\"üß¨ TUNNELER\")\n",
    "        if row['is_unicorn'] == -1: tags.append(\"ü¶Ñ UNICORN\")\n",
    "        if row['breakout_potential'] != 'OPTIMIZED':\n",
    "            tags.append(\"üöÄ BREAKOUT\")\n",
    "            analysis += f\"Tactical Alert: {row['breakout_potential']}. \"\n",
    "\n",
    "        # Create the final string\n",
    "        tag_str = \" | \".join(list(set(tags)))\n",
    "        final_summary = f\"{summary_header} {tag_str} ‚Äî {analysis.strip()}\"\n",
    "        \n",
    "        return tag_str, final_summary\n",
    "\n",
    "    # Apply to your DataFrame\n",
    "    results = df.apply(generate_scouting_report, axis=1)\n",
    "    df['archetype_tags'], df['scouting_summary'] = zip(*results)\n",
    "\n",
    "    # Apply and split into two columns\n",
    "    results = df.apply(generate_scouting_report, axis=1)\n",
    "    df['archetype_tags'], df['scouting_summary'] = zip(*results)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def update_dim_pitcher_archetypes(engine):\n",
    "    \"\"\"\n",
    "    SQL to extract the necessary metrics for the Python model.\n",
    "    \"\"\"\n",
    "    query = text(\"\"\"\n",
    "    WITH attack_zone_stats AS (\n",
    "    SELECT \n",
    "        p.*,\n",
    "        -- Define Command/Paint Zones\n",
    "        CASE \n",
    "            WHEN ABS(p.plate_x) <= 0.67 AND p.plate_z BETWEEN (p.sz_bot + 0.33) AND (p.sz_top - 0.33) THEN 'heart'\n",
    "            WHEN ABS(p.plate_x) <= 1.1 AND p.plate_z BETWEEN (p.sz_bot - 0.33) AND (p.sz_top + 0.33) THEN 'shadow'\n",
    "            WHEN ABS(p.plate_x) <= 1.5 AND p.plate_z BETWEEN (p.sz_bot - 0.75) AND (p.sz_top + 0.75) THEN 'chase'\n",
    "            ELSE 'waste'\n",
    "        END as attack_zone,\n",
    "        CASE WHEN p.description IN ('swinging_strike', 'swinging_strike_blocked', 'missed_bunt') THEN 1 ELSE 0 END as is_whiff,\n",
    "        CASE WHEN p.description IN ('swinging_strike', 'swinging_strike_blocked', 'missed_bunt', 'foul', 'foul_tip', 'hit_into_play') THEN 1 ELSE 0 END as is_swing\n",
    "    FROM fact_statcast_pitches p\n",
    "    ),\n",
    "    vaa_base_calc AS (\n",
    "        SELECT \n",
    "            az.*,\n",
    "            CASE WHEN az.pitch_type IN ('FA', 'FF', 'FC') THEN \n",
    "                -ATAN((az.vz0 + (az.az * ((-az.vy0 - SQRT(az.vy0^2 - (2 * az.ay * (50 - (17/12))))) / az.ay))) / \n",
    "                (-SQRT(az.vy0^2 - (2 * az.ay * (50 - (17/12)))))) * (180/3.14159) \n",
    "            END as individual_ff_vaa\n",
    "        FROM attack_zone_stats az\n",
    "    ),\n",
    "    aggregated_stats AS (\n",
    "        SELECT \n",
    "            p.pitcher,\n",
    "            p.p_throws,\n",
    "            COUNT(*) as total_pitches,        \n",
    "            AVG(p.release_extension) as avg_extension,\n",
    "            COALESCE(ROUND(AVG(CASE WHEN p.pitch_type IN ('FA', 'FF', 'FT', 'FC', 'SI') THEN p.release_speed + ((p.release_extension - 6.2) * 2) END)::numeric, 1), 0) as perceived_fb_velo,\n",
    "            (AVG(CASE WHEN p.pitch_type IN ('FA', 'FF') THEN p.pfx_z * 12 END) - \n",
    "            AVG(CASE WHEN p.pitch_type IN ('CH', 'FS', 'SI') THEN p.pfx_z * 12 END)) as v_break_gap_raw,\n",
    "            \n",
    "            ROUND(100.0 * SUM(p.is_whiff) / NULLIF(SUM(p.is_swing), 0), 2) as whiff_rate_raw,\n",
    "            ROUND(100.0 * SUM(CASE WHEN p.launch_speed_angle = 6 THEN 1 ELSE 0 END) / \n",
    "                NULLIF(SUM(CASE WHEN p.type = 'X' THEN 1 ELSE 0 END), 0), 2) as barrel_rate_raw,        \n",
    "            \n",
    "            ROUND(100.0 * SUM(CASE WHEN p.attack_zone = 'shadow' THEN 1 ELSE 0 END) / COUNT(*), 1) as paint_raw,\n",
    "            ROUND(100.0 * SUM(CASE WHEN p.attack_zone IN ('shadow', 'chase') THEN 1 ELSE 0 END) / COUNT(*), 1) as command_raw,        \n",
    "            \n",
    "            AVG(CASE WHEN p.stand = 'L' THEN p.estimated_woba_using_speedangle END) as xwoba_vs_lhb,\n",
    "            AVG(CASE WHEN p.stand = 'R' THEN p.estimated_woba_using_speedangle END) as xwoba_vs_rhb,           \n",
    "            \n",
    "            COALESCE(ROUND(AVG(CASE WHEN p.pitch_type IN ('FA', 'FF', 'FT', 'FC', 'SI') THEN p.release_speed END)::numeric, 1), 0) as fb_velo,\n",
    "            COALESCE(ROUND(AVG(CASE WHEN p.pitch_type IN ('CH', 'FS', 'FO', 'SC', 'ST', 'SL', 'KC', 'GY', 'SV', 'CS', 'KN', 'EP') THEN p.release_speed END)::numeric, 1), 0) as offspeed_velo,                                                                                                                                                                    \n",
    "            \n",
    "            ROUND(100.0 * SUM(CASE WHEN p.pitch_type IN ('FA', 'FF', 'FC') THEN 1 ELSE 0 END) / COUNT(*), 1) as ffour_usage,\n",
    "            ROUND(100.0 * SUM(CASE WHEN p.pitch_type IN ('SI', 'FT') THEN 1 ELSE 0 END) / COUNT(*), 1) as sinker_usage,\n",
    "            ROUND(100.0 * SUM(CASE WHEN p.pitch_type IN ('CU', 'SL', 'KC', 'ST', 'SV', 'CS', 'KN') THEN 1 ELSE 0 END) / COUNT(*), 1) as bb_usage,\n",
    "            ROUND(100.0 * SUM(CASE WHEN p.pitch_type IN ('CH', 'FS', 'FO', 'SC', 'ST', 'SL', 'KC', 'GY', 'SV', 'CS', 'KN', 'EP') THEN 1 ELSE 0 END) / COUNT(*), 1) as offspeed_usage,        \n",
    "            \n",
    "            COALESCE(ROUND(AVG(CASE WHEN p.pitch_type IN ('FA', 'FF', 'FT', 'FC', 'SI') THEN p.release_speed END)::numeric - \n",
    "                        AVG(CASE WHEN p.pitch_type IN ('CH', 'FS', 'FO', 'SC', 'ST', 'SL', 'KC', 'GY', 'SV', 'CS', 'KN', 'EP') THEN p.release_speed END)::numeric, 1), 0) as velo_gap,        \n",
    "            COALESCE(ROUND(AVG(p.individual_ff_vaa)::numeric, 2), 0) as ffour_vaa,\n",
    "            COALESCE(ROUND(AVG(CASE WHEN p.pitch_type IN ('SI', 'FT') THEN -ATAN((p.vz0 + (p.az * ((-p.vy0 - SQRT(p.vy0^2 - (2 * p.ay * (50 - (17/12))))) / p.ay))) / (-SQRT(p.vy0^2 - (2 * p.ay * (50 - (17/12)))))) * (180/3.14159) END)::numeric, 2), 0) as sinker_vaa,\n",
    "            COALESCE(ROUND(AVG(CASE WHEN p.pitch_type IN ('CU', 'SL', 'KC', 'ST', 'SV', 'CS', 'KN') THEN -ATAN((p.vz0 + (p.az * ((-p.vy0 - SQRT(p.vy0^2 - (2 * p.ay * (50 - (17/12))))) / p.ay))) / (-SQRT(p.vy0^2 - (2 * p.ay * (50 - (17/12)))))) * (180/3.14159) END)::numeric, 2), 0) as bb_vaa,\n",
    "            COALESCE(ROUND(AVG(CASE WHEN p.pitch_type IN ('CH', 'FS', 'FO', 'SC', 'EP') THEN -ATAN((p.vz0 + (p.az * ((-p.vy0 - SQRT(p.vy0^2 - (2 * p.ay * (50 - (17/12))))) / p.ay))) / (-SQRT(p.vy0^2 - (2 * p.ay * (50 - (17/12)))))) * (180/3.14159) END)::numeric, 2), 0) as offspeed_vaa,\n",
    "\n",
    "            COUNT(DISTINCT game_pk) as total_appearances,\n",
    "            (COUNT(*) / COUNT(DISTINCT game_pk)) as avg_pitches_per_app,\n",
    "            CASE WHEN (COUNT(*) / COUNT(DISTINCT game_pk)) >= 40 AND COUNT(DISTINCT game_pk) >= 3 THEN 1 ELSE 0 END as is_starter,\n",
    "            \n",
    "            STDDEV(p.release_pos_x) as release_x_std,\n",
    "            STDDEV(p.release_pos_z) as release_z_std,\n",
    "            (STDDEV(p.release_pos_x) + STDDEV(p.release_pos_z)) as tunnel_raw,\n",
    "            AVG(p.individual_ff_vaa - ((-0.68 * p.plate_z) - 3.8)) as vaa_above_expected_raw,       \n",
    "            -- RAW STUFF+ (Process)\n",
    "            ( (AVG(p.release_speed) * 0.4) + (AVG(p.release_extension) * 0.2) + (AVG(ABS(p.pfx_x)) * 12 * 0.2) + (AVG(p.pfx_z) * 12 * 0.2) ) as stuff_raw,\n",
    "            -- RAW LOCATION+ (Process)\n",
    "            ( (SUM(CASE WHEN p.attack_zone = 'shadow' THEN 1 ELSE 0 END)::float / COUNT(*)) * 0.6 + (SUM(CASE WHEN p.attack_zone = 'heart' THEN 0 ELSE 1 END)::float / COUNT(*)) * 0.4 ) as location_raw\n",
    "\n",
    "        FROM vaa_base_calc p\n",
    "        GROUP BY p.pitcher, p.p_throws\n",
    "        HAVING COUNT(*) > 100 AND AVG(p.release_speed) > 84\n",
    "    ),\n",
    "    ranked_stats AS (\n",
    "        SELECT \n",
    "            ast.*,\n",
    "            ROUND((PERCENT_RANK() OVER (ORDER BY fb_velo))::numeric, 2) * 100 as velo_pct,\n",
    "            COALESCE(ROUND((PERCENT_RANK() OVER (PARTITION BY (offspeed_usage > 0) ORDER BY offspeed_velo))::numeric, 2) * 100, 0) as offspeed_velo_pct,\n",
    "            COALESCE(ROUND((PERCENT_RANK() OVER (PARTITION BY (offspeed_usage > 0) ORDER BY velo_gap))::numeric, 2) * 100, 0) as velo_gap_pct,                   \n",
    "            ROUND((PERCENT_RANK() OVER (ORDER BY whiff_rate_raw))::numeric, 2) * 100 as whiff_pct,\n",
    "            ROUND((PERCENT_RANK() OVER (ORDER BY barrel_rate_raw DESC))::numeric, 2) * 100 as suppression_pct,\n",
    "            ROUND((PERCENT_RANK() OVER (ORDER BY command_raw))::numeric, 2) * 100 as command_pct,\n",
    "            ROUND((PERCENT_RANK() OVER (ORDER BY paint_raw))::numeric, 2) * 100 as paint_pct,            \n",
    "            ROUND((PERCENT_RANK() OVER (ORDER BY perceived_fb_velo))::numeric, 2) * 100 as perceived_velo_pct,\n",
    "            COALESCE(ROUND((PERCENT_RANK() OVER (PARTITION BY (offspeed_usage > 0 OR sinker_usage > 0) ORDER BY v_break_gap_raw))::numeric, 2) * 100, 0) as movement_gap_pct,\n",
    "            ROUND((PERCENT_RANK() OVER (ORDER BY avg_extension))::numeric, 2) * 100 as extension_pct,           \n",
    "            COALESCE(ROUND((PERCENT_RANK() OVER (PARTITION BY (ffour_usage > 0) ORDER BY ffour_vaa))::numeric, 2) * 100, 0) as ffour_vaa_pct,\n",
    "            COALESCE(ROUND((PERCENT_RANK() OVER (PARTITION BY (sinker_usage > 0) ORDER BY sinker_vaa DESC))::numeric, 2) * 100, 0) as sinker_vaa_pct,\n",
    "            COALESCE(ROUND((PERCENT_RANK() OVER (PARTITION BY (bb_usage > 0) ORDER BY bb_vaa DESC))::numeric, 2) * 100, 0) as bb_vaa_pct,\n",
    "            COALESCE(ROUND((PERCENT_RANK() OVER (PARTITION BY (offspeed_usage > 0) ORDER BY offspeed_vaa DESC))::numeric, 2) * 100, 0) as offspeed_vaa_pct,\n",
    "            ROUND((100 - (ABS(COALESCE(xwoba_vs_lhb, 0.320) - COALESCE(xwoba_vs_rhb, 0.320)) * 100))::numeric, 2) as neutrality_pct,\n",
    "            ROUND((PERCENT_RANK() OVER (ORDER BY tunnel_raw DESC))::numeric, 2) * 100 as tunnel_pct,\n",
    "            ROUND((PERCENT_RANK() OVER (ORDER BY vaa_above_expected_raw))::numeric, 2) * 100 as vaa_plus_pct,\n",
    "            ROUND((PERCENT_RANK() OVER (ORDER BY stuff_raw))::numeric, 2) * 100 as stuff_plus_pct,\n",
    "            ROUND((PERCENT_RANK() OVER (ORDER BY location_raw))::numeric, 2) * 100 as location_plus_pct\n",
    "        FROM aggregated_stats ast\n",
    "    )\n",
    "    SELECT \n",
    "        CONCAT(pn.first_name_chadwick, ' ', pn.last_name_chadwick) as full_name,\n",
    "        rs.p_throws as hand,\n",
    "        rs.*,\n",
    "        -- MATCHUP COLUMN 1: ATTACK PROFILE (Rise vs Run)\n",
    "        CASE \n",
    "            WHEN vaa_plus_pct > 75 THEN 'NORTH-SOUTH (High Rise)'\n",
    "            WHEN sinker_usage > 25 THEN 'EAST-WEST (Sinker/Run)'\n",
    "            WHEN movement_gap_pct > 75 THEN 'DECEPTIVE (High Break)'\n",
    "            ELSE 'BALANCED'\n",
    "        END as attack_profile,\n",
    "        -- MATCHUP COLUMN 2: ROLE IDENTITY\n",
    "        CASE \n",
    "            WHEN rs.whiff_pct > 75 AND rs.location_plus_pct > 75 THEN 'DOMINANT ACE'\n",
    "            WHEN rs.whiff_pct > 75 AND rs.location_plus_pct < 40 THEN 'POWER ARMS (High Risk)'\n",
    "            WHEN rs.location_plus_pct > 75 AND rs.whiff_pct < 45 THEN 'PITCH TO CONTACT SURGEON'\n",
    "            ELSE 'ROTATION STABILIZER'\n",
    "        END as matchup_role,\n",
    "        -- MATCHUP COLUMN 3: PLATOON RESISTANCE\n",
    "        CASE \n",
    "            WHEN rs.neutrality_pct > 75 THEN 'MATCHUP PROOF'\n",
    "            WHEN rs.neutrality_pct < 35 THEN 'PLATOON SENSITIVE'\n",
    "            ELSE 'STANDARD SPLITS'\n",
    "        END as platoon_identity,\n",
    "        ROUND((perceived_velo_pct * 0.25 + ffour_vaa_pct * 0.25 + whiff_pct * 0.5), 0) as ffour_quality_score,\n",
    "        ROUND((movement_gap_pct * 0.25 + offspeed_vaa_pct * 0.25 + whiff_pct * 0.5), 0) as offspeed_quality_score,   \n",
    "        CASE \n",
    "            WHEN (ffour_vaa_pct > 80 AND ffour_usage < 20) THEN 'UNDERUSED ELITE FASTBALL'\n",
    "            WHEN (bb_vaa_pct > 80 AND bb_usage < 15) THEN 'UNDERUSED ELITE BREAKING'\n",
    "            WHEN (offspeed_vaa_pct > 80 AND offspeed_usage < 15) THEN 'UNDERUSED ELITE OFFSPD'\n",
    "            ELSE 'OPTIMIZED'\n",
    "        END as breakout_potential\n",
    "    FROM ranked_stats rs\n",
    "    JOIN dim_player pn ON rs.pitcher = pn.key_mlbam\n",
    "    ORDER BY stuff_plus_pct DESC;\n",
    "    \"\"\")\n",
    "    df = pd.read_sql(query, engine)\n",
    "\n",
    "    return run_scouting_model(df)\n",
    "\n",
    "# Execute\n",
    "pitcher_archetypes = update_dim_pitcher_archetypes(engine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0572e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               ffour_usage  sinker_usage  ffour_vaa_pct  velo_gap_pct  \\\n",
      "style_cluster                                                           \n",
      "0                    22.12         26.20          45.16         36.51   \n",
      "1                    44.82          5.34          56.19         60.08   \n",
      "2                    18.56         34.52          39.94         49.79   \n",
      "3                    41.78         16.62          21.14         32.18   \n",
      "4                    52.95          0.00          53.41         50.33   \n",
      "5                    33.01         22.99          56.30         55.70   \n",
      "6                    45.38          7.52          59.26         47.03   \n",
      "\n",
      "               paint_pct  fb_velo  whiff_pct  suppression_pct  \n",
      "style_cluster                                                  \n",
      "0                  43.90    92.95      46.15            56.90  \n",
      "1                  40.32    94.03      59.43            45.26  \n",
      "2                  24.34    93.84      52.30            61.46  \n",
      "3                  61.30    92.16      33.50            48.66  \n",
      "4                  48.63    93.76      59.23            42.05  \n",
      "5                  56.06    93.84      46.01            53.85  \n",
      "6                  47.46    94.47      55.87            46.54  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib # Recommended for saving the model later\n",
    "\n",
    "def run_scouting_model(df):\n",
    "    \"\"\"\n",
    "    Synthesizes pitching identity (GMM) with performance outcomes.\n",
    "    Integrates tactical labels derived from cluster profiling.\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Identity Features\n",
    "    identity_features = [\n",
    "        'ffour_usage', 'sinker_usage', 'bb_usage', 'offspeed_usage',\n",
    "        'ffour_vaa_pct', 'sinker_vaa_pct', 'bb_vaa_pct', 'offspeed_vaa_pct',\n",
    "        'velo_gap_pct', 'command_pct', 'paint_pct'\n",
    "    ]\n",
    "    \n",
    "    # 2. Effectiveness Scores\n",
    "    df['lethality_score'] = (\n",
    "        (df['whiff_pct'] * 0.75) + \n",
    "        (df['suppression_pct'] * 0.20) + \n",
    "        (df['velo_pct'] * 0.05)\n",
    "    ).round(1)\n",
    "\n",
    "    # 1. Load the \"Frozen\" Models\n",
    "    scaler = joblib.load('pitcher_scaler_v1.pkl')\n",
    "    gmm = joblib.load('pitcher_model_v1.pkl')\n",
    "    \n",
    "    # 3. Clustering (Archetype Definition)\n",
    "    #scaler = StandardScaler()\n",
    "    # Filling NaNs with 0 to ensure the scaler doesn't fail\n",
    "    # scaled_identity = scaler.fit_transform(df[identity_features].fillna(0))\n",
    "    \n",
    "    # 2. Use the frozen scaler (DO NOT use fit_transform)\n",
    "    # We use .transform() so we measure new data by OLD standards\n",
    "    scaled_identity = scaler.transform(df[identity_features].fillna(0))\n",
    "        \n",
    "    # gmm = GaussianMixture(n_components=7, random_state=42)\n",
    "    # df['style_cluster'] = gmm.fit_predict(scaled_identity)\n",
    "    \n",
    "    # 3. Use the frozen GMM (DO NOT use fit_predict)\n",
    "    # This ensures Cluster 2 ALWAYS = \"Heavy Sinker Specialist\"\n",
    "    df['style_cluster'] = gmm.predict(scaled_identity)\n",
    "\n",
    "    \n",
    "    # # Save the scaler and model for future use\n",
    "    # joblib.dump(scaler, 'pitcher_scaler_v1.pkl')\n",
    "    # joblib.dump(gmm, 'pitcher_model_v1.pkl')\n",
    "    # print(\"üíæ Models saved to your project folder!\")\n",
    "\n",
    "    # 4. Define the Tactical Labels (Mapped from your Profile Results)\n",
    "    cluster_map = {\n",
    "            0: \"Diverse Technician\",\n",
    "            1: \"High-Octane Power Arm\",\n",
    "            2: \"Elite Contact Manager\",\n",
    "            3: \"Corner Specialist\",\n",
    "            4: \"Vertical Specialist\",\n",
    "            5: \"Versatile Tactician\",\n",
    "            6: \"Vertical Power Lead\"\n",
    "        }\n",
    "    df['pitcher_archetype_label'] = df['style_cluster'].map(cluster_map)\n",
    "\n",
    "    # 5. Outlier Detection\n",
    "    iso = IsolationForest(contamination=0.04, random_state=42)\n",
    "    df['is_unicorn'] = iso.fit_predict(scaled_identity)\n",
    "    \n",
    "    def profile_pitcher_clusters(df):\n",
    "        # Defining the tactical metrics we want to see\n",
    "        # profile_metrics = [\n",
    "        #     'style_cluster', 'fb_velo', 'ffour_usage', 'sinker_usage', \n",
    "        #     'offspeed_usage', 'whiff_pct', 'paint_pct', 'vaa_plus_pct'\n",
    "        # ]\n",
    "        \n",
    "        profile_metrics = [\n",
    "        'style_cluster', \n",
    "        # DNA\n",
    "        'ffour_usage', 'sinker_usage', 'ffour_vaa_pct', 'velo_gap_pct', 'paint_pct',\n",
    "        # RESULTS\n",
    "        'fb_velo', 'whiff_pct', 'suppression_pct']\n",
    "        \n",
    "        # Calculate the mean for each cluster\n",
    "        profile = df[profile_metrics].groupby('style_cluster').mean().round(2)\n",
    "        \n",
    "        # Sort by whiff_pct to see the \"Dominance Hierarchy\"\n",
    "        #return profile.sort_values(by='whiff_pct', ascending=False)\n",
    "        return df[profile_metrics].groupby('style_cluster').mean().round(2)\n",
    "    \n",
    "    # Usage:\n",
    "    pitcher_profile_table = profile_pitcher_clusters(df)\n",
    "    print(pitcher_profile_table)\n",
    "    \n",
    "    # 6. Grading Logic\n",
    "    def calculate_pitcher_grade(row):\n",
    "        stuff_plus = row['stuff_plus_pct']\n",
    "        location_plus = row['location_plus_pct']\n",
    "        \n",
    "        base_score = (stuff_plus * 0.60) + (location_plus * 0.40)\n",
    "        \n",
    "        if row.get('is_starter') == 1: base_score += 5 \n",
    "        if row.get('total_appearances', 0) < 5: base_score -= 10 \n",
    "\n",
    "        if base_score >= 85: grade = 'A+'\n",
    "        elif base_score >= 75: grade = 'A'\n",
    "        elif base_score >= 60: grade = 'B'\n",
    "        elif base_score >= 45: grade = 'C'\n",
    "        else: grade = 'F'\n",
    "            \n",
    "        return grade, stuff_plus, location_plus\n",
    "\n",
    "    df[['overall_grade', 'stuff_plus_final', 'location_plus_final']] = df.apply(\n",
    "        lambda x: pd.Series(calculate_pitcher_grade(x)), axis=1\n",
    "    )\n",
    "\n",
    "    # 7. Scouting Report Generation\n",
    "    def generate_scouting_report(row):\n",
    "        tags = []\n",
    "        # Header includes Archetype Label\n",
    "        summary_header = f\"[{row['overall_grade']} {row['pitcher_archetype_label']}] ({row['hand']})\"\n",
    "        \n",
    "        # Tags\n",
    "        if row['stuff_plus_pct'] >= 90: tags.append(\"üí£ PURE FILTH\")\n",
    "        if row['location_plus_pct'] >= 90: tags.append(\"üéØ SURGEON\")\n",
    "        if row['is_unicorn'] == -1: tags.append(\"ü¶Ñ UNICORN\")\n",
    "        \n",
    "        # Platoon Logic\n",
    "        platoon = row['platoon_identity']\n",
    "        if platoon == \"MATCHUP PROOF\": tags.append(\"üõ°Ô∏è PLATOON NEUTRAL\")\n",
    "        elif platoon == \"PLATOON SENSITIVE\": tags.append(\"‚ö†Ô∏è SPLIT RISK\")\n",
    "\n",
    "        # Narrative Body\n",
    "        analysis = f\"Tactically identified as a {row['matchup_role']}. \"\n",
    "        if \"NORTH-SOUTH\" in row['attack_profile']:\n",
    "            analysis += \"Dominates vertically; elite matchup vs low-ball hitters. \"\n",
    "        elif \"EAST-WEST\" in row['attack_profile']:\n",
    "            analysis += \"East-West specialist; ideal for inducing ground balls. \"\n",
    "\n",
    "        tag_str = \" | \".join(list(set(tags)))\n",
    "        return tag_str, f\"{summary_header} ‚Äî TAGS: {tag_str} ‚Äî SUMMARY: {analysis.strip()}\"\n",
    "\n",
    "    df['archetype_tags'], df['scouting_summary'] = zip(*df.apply(generate_scouting_report, axis=1))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def update_dim_pitcher_archetypes(engine):\n",
    "    \"\"\"\n",
    "    SQL to extract the necessary metrics for the Python model.\n",
    "    \"\"\"\n",
    "    query = text(\"\"\"\n",
    "    WITH attack_zone_stats AS (\n",
    "    SELECT \n",
    "        p.*,\n",
    "        -- Define Command/Paint Zones\n",
    "        CASE \n",
    "            WHEN ABS(p.plate_x) <= 0.67 AND p.plate_z BETWEEN (p.sz_bot + 0.33) AND (p.sz_top - 0.33) THEN 'heart'\n",
    "            WHEN ABS(p.plate_x) <= 1.1 AND p.plate_z BETWEEN (p.sz_bot - 0.33) AND (p.sz_top + 0.33) THEN 'shadow'\n",
    "            WHEN ABS(p.plate_x) <= 1.5 AND p.plate_z BETWEEN (p.sz_bot - 0.75) AND (p.sz_top + 0.75) THEN 'chase'\n",
    "            ELSE 'waste'\n",
    "        END as attack_zone,\n",
    "        CASE WHEN p.description IN ('swinging_strike', 'swinging_strike_blocked', 'missed_bunt') THEN 1 ELSE 0 END as is_whiff,\n",
    "        CASE WHEN p.description IN ('swinging_strike', 'swinging_strike_blocked', 'missed_bunt', 'foul', 'foul_tip', 'hit_into_play') THEN 1 ELSE 0 END as is_swing\n",
    "    FROM fact_statcast_pitches p\n",
    "    ),\n",
    "    vaa_base_calc AS (\n",
    "        SELECT \n",
    "            az.*,\n",
    "            CASE WHEN az.pitch_type IN ('FA', 'FF', 'FC') THEN \n",
    "                -ATAN((az.vz0 + (az.az * ((-az.vy0 - SQRT(az.vy0^2 - (2 * az.ay * (50 - (17/12))))) / az.ay))) / \n",
    "                (-SQRT(az.vy0^2 - (2 * az.ay * (50 - (17/12)))))) * (180/3.14159) \n",
    "            END as individual_ff_vaa\n",
    "        FROM attack_zone_stats az\n",
    "    ),\n",
    "    aggregated_stats AS (\n",
    "        SELECT \n",
    "            p.pitcher,\n",
    "            p.p_throws,\n",
    "            COUNT(*) as total_pitches,        \n",
    "            AVG(p.release_extension) as avg_extension,\n",
    "            COALESCE(ROUND(AVG(CASE WHEN p.pitch_type IN ('FA', 'FF', 'FT', 'FC', 'SI') THEN p.release_speed + ((p.release_extension - 6.2) * 2) END)::numeric, 1), 0) as perceived_fb_velo,\n",
    "            (AVG(CASE WHEN p.pitch_type IN ('FA', 'FF') THEN p.pfx_z * 12 END) - \n",
    "            AVG(CASE WHEN p.pitch_type IN ('CH', 'FS', 'SI') THEN p.pfx_z * 12 END)) as v_break_gap_raw,\n",
    "            \n",
    "            ROUND(100.0 * SUM(p.is_whiff) / NULLIF(SUM(p.is_swing), 0), 2) as whiff_rate_raw,\n",
    "            ROUND(100.0 * SUM(CASE WHEN p.launch_speed_angle = 6 THEN 1 ELSE 0 END) / \n",
    "                NULLIF(SUM(CASE WHEN p.type = 'X' THEN 1 ELSE 0 END), 0), 2) as barrel_rate_raw,        \n",
    "            \n",
    "            ROUND(100.0 * SUM(CASE WHEN p.attack_zone = 'shadow' THEN 1 ELSE 0 END) / COUNT(*), 1) as paint_raw,\n",
    "            ROUND(100.0 * SUM(CASE WHEN p.attack_zone IN ('shadow', 'chase') THEN 1 ELSE 0 END) / COUNT(*), 1) as command_raw,        \n",
    "            \n",
    "            AVG(CASE WHEN p.stand = 'L' THEN p.estimated_woba_using_speedangle END) as xwoba_vs_lhb,\n",
    "            AVG(CASE WHEN p.stand = 'R' THEN p.estimated_woba_using_speedangle END) as xwoba_vs_rhb,           \n",
    "            \n",
    "            COALESCE(ROUND(AVG(CASE WHEN p.pitch_type IN ('FA', 'FF', 'FT', 'FC', 'SI') THEN p.release_speed END)::numeric, 1), 0) as fb_velo,\n",
    "            COALESCE(ROUND(AVG(CASE WHEN p.pitch_type IN ('CH', 'FS', 'FO', 'SC', 'ST', 'SL', 'KC', 'GY', 'SV', 'CS', 'KN', 'EP') THEN p.release_speed END)::numeric, 1), 0) as offspeed_velo,                                                                                                                                                                    \n",
    "            \n",
    "            ROUND(100.0 * SUM(CASE WHEN p.pitch_type IN ('FA', 'FF', 'FC') THEN 1 ELSE 0 END) / COUNT(*), 1) as ffour_usage,\n",
    "            ROUND(100.0 * SUM(CASE WHEN p.pitch_type IN ('SI', 'FT') THEN 1 ELSE 0 END) / COUNT(*), 1) as sinker_usage,\n",
    "            ROUND(100.0 * SUM(CASE WHEN p.pitch_type IN ('CU', 'SL', 'KC', 'ST', 'SV', 'CS', 'KN') THEN 1 ELSE 0 END) / COUNT(*), 1) as bb_usage,\n",
    "            ROUND(100.0 * SUM(CASE WHEN p.pitch_type IN ('CH', 'FS', 'FO', 'SC', 'ST', 'SL', 'KC', 'GY', 'SV', 'CS', 'KN', 'EP') THEN 1 ELSE 0 END) / COUNT(*), 1) as offspeed_usage,        \n",
    "            \n",
    "            COALESCE(ROUND(AVG(CASE WHEN p.pitch_type IN ('FA', 'FF', 'FT', 'FC', 'SI') THEN p.release_speed END)::numeric - \n",
    "                        AVG(CASE WHEN p.pitch_type IN ('CH', 'FS', 'FO', 'SC', 'ST', 'SL', 'KC', 'GY', 'SV', 'CS', 'KN', 'EP') THEN p.release_speed END)::numeric, 1), 0) as velo_gap,        \n",
    "            COALESCE(ROUND(AVG(p.individual_ff_vaa)::numeric, 2), 0) as ffour_vaa,\n",
    "            COALESCE(ROUND(AVG(CASE WHEN p.pitch_type IN ('SI', 'FT') THEN -ATAN((p.vz0 + (p.az * ((-p.vy0 - SQRT(p.vy0^2 - (2 * p.ay * (50 - (17/12))))) / p.ay))) / (-SQRT(p.vy0^2 - (2 * p.ay * (50 - (17/12)))))) * (180/3.14159) END)::numeric, 2), 0) as sinker_vaa,\n",
    "            COALESCE(ROUND(AVG(CASE WHEN p.pitch_type IN ('CU', 'SL', 'KC', 'ST', 'SV', 'CS', 'KN') THEN -ATAN((p.vz0 + (p.az * ((-p.vy0 - SQRT(p.vy0^2 - (2 * p.ay * (50 - (17/12))))) / p.ay))) / (-SQRT(p.vy0^2 - (2 * p.ay * (50 - (17/12)))))) * (180/3.14159) END)::numeric, 2), 0) as bb_vaa,\n",
    "            COALESCE(ROUND(AVG(CASE WHEN p.pitch_type IN ('CH', 'FS', 'FO', 'SC', 'EP') THEN -ATAN((p.vz0 + (p.az * ((-p.vy0 - SQRT(p.vy0^2 - (2 * p.ay * (50 - (17/12))))) / p.ay))) / (-SQRT(p.vy0^2 - (2 * p.ay * (50 - (17/12)))))) * (180/3.14159) END)::numeric, 2), 0) as offspeed_vaa,\n",
    "\n",
    "            COUNT(DISTINCT game_pk) as total_appearances,\n",
    "            (COUNT(*) / COUNT(DISTINCT game_pk)) as avg_pitches_per_app,\n",
    "            CASE WHEN (COUNT(*) / COUNT(DISTINCT game_pk)) >= 40 AND COUNT(DISTINCT game_pk) >= 3 THEN 1 ELSE 0 END as is_starter,\n",
    "            \n",
    "            STDDEV(p.release_pos_x) as release_x_std,\n",
    "            STDDEV(p.release_pos_z) as release_z_std,\n",
    "            (STDDEV(p.release_pos_x) + STDDEV(p.release_pos_z)) as tunnel_raw,\n",
    "            AVG(p.individual_ff_vaa - ((-0.68 * p.plate_z) - 3.8)) as vaa_above_expected_raw,       \n",
    "            -- RAW STUFF+ (Process)\n",
    "            ( (AVG(p.release_speed) * 0.4) + (AVG(p.release_extension) * 0.2) + (AVG(ABS(p.pfx_x)) * 12 * 0.2) + (AVG(p.pfx_z) * 12 * 0.2) ) as stuff_raw,\n",
    "            -- RAW LOCATION+ (Process)\n",
    "            ( (SUM(CASE WHEN p.attack_zone = 'shadow' THEN 1 ELSE 0 END)::float / COUNT(*)) * 0.6 + (SUM(CASE WHEN p.attack_zone = 'heart' THEN 0 ELSE 1 END)::float / COUNT(*)) * 0.4 ) as location_raw\n",
    "\n",
    "        FROM vaa_base_calc p\n",
    "        GROUP BY p.pitcher, p.p_throws\n",
    "        HAVING COUNT(*) > 100 AND AVG(p.release_speed) > 84\n",
    "    ),\n",
    "    ranked_stats AS (\n",
    "        SELECT \n",
    "            ast.*,\n",
    "            ROUND((PERCENT_RANK() OVER (ORDER BY fb_velo))::numeric, 2) * 100 as velo_pct,\n",
    "            COALESCE(ROUND((PERCENT_RANK() OVER (PARTITION BY (offspeed_usage > 0) ORDER BY offspeed_velo))::numeric, 2) * 100, 0) as offspeed_velo_pct,\n",
    "            COALESCE(ROUND((PERCENT_RANK() OVER (PARTITION BY (offspeed_usage > 0) ORDER BY velo_gap))::numeric, 2) * 100, 0) as velo_gap_pct,                   \n",
    "            ROUND((PERCENT_RANK() OVER (ORDER BY whiff_rate_raw))::numeric, 2) * 100 as whiff_pct,\n",
    "            ROUND((PERCENT_RANK() OVER (ORDER BY barrel_rate_raw DESC))::numeric, 2) * 100 as suppression_pct,\n",
    "            ROUND((PERCENT_RANK() OVER (ORDER BY command_raw))::numeric, 2) * 100 as command_pct,\n",
    "            ROUND((PERCENT_RANK() OVER (ORDER BY paint_raw))::numeric, 2) * 100 as paint_pct,            \n",
    "            ROUND((PERCENT_RANK() OVER (ORDER BY perceived_fb_velo))::numeric, 2) * 100 as perceived_velo_pct,\n",
    "            COALESCE(ROUND((PERCENT_RANK() OVER (PARTITION BY (offspeed_usage > 0 OR sinker_usage > 0) ORDER BY v_break_gap_raw))::numeric, 2) * 100, 0) as movement_gap_pct,\n",
    "            ROUND((PERCENT_RANK() OVER (ORDER BY avg_extension))::numeric, 2) * 100 as extension_pct,           \n",
    "            COALESCE(ROUND((PERCENT_RANK() OVER (PARTITION BY (ffour_usage > 0) ORDER BY ffour_vaa))::numeric, 2) * 100, 0) as ffour_vaa_pct,\n",
    "            COALESCE(ROUND((PERCENT_RANK() OVER (PARTITION BY (sinker_usage > 0) ORDER BY sinker_vaa DESC))::numeric, 2) * 100, 0) as sinker_vaa_pct,\n",
    "            COALESCE(ROUND((PERCENT_RANK() OVER (PARTITION BY (bb_usage > 0) ORDER BY bb_vaa DESC))::numeric, 2) * 100, 0) as bb_vaa_pct,\n",
    "            COALESCE(ROUND((PERCENT_RANK() OVER (PARTITION BY (offspeed_usage > 0) ORDER BY offspeed_vaa DESC))::numeric, 2) * 100, 0) as offspeed_vaa_pct,\n",
    "            ROUND((100 - (ABS(COALESCE(xwoba_vs_lhb, 0.320) - COALESCE(xwoba_vs_rhb, 0.320)) * 100))::numeric, 2) as neutrality_pct,\n",
    "            ROUND((PERCENT_RANK() OVER (ORDER BY tunnel_raw DESC))::numeric, 2) * 100 as tunnel_pct,\n",
    "            ROUND((PERCENT_RANK() OVER (ORDER BY vaa_above_expected_raw))::numeric, 2) * 100 as vaa_plus_pct,\n",
    "            ROUND((PERCENT_RANK() OVER (ORDER BY stuff_raw))::numeric, 2) * 100 as stuff_plus_pct,\n",
    "            ROUND((PERCENT_RANK() OVER (ORDER BY location_raw))::numeric, 2) * 100 as location_plus_pct\n",
    "        FROM aggregated_stats ast\n",
    "    )\n",
    "    SELECT \n",
    "        CONCAT(pn.first_name_chadwick, ' ', pn.last_name_chadwick) as full_name,\n",
    "        rs.p_throws as hand,\n",
    "        rs.*,\n",
    "        -- MATCHUP COLUMN 1: ATTACK PROFILE (Rise vs Run)\n",
    "        CASE \n",
    "            WHEN vaa_plus_pct > 75 THEN 'NORTH-SOUTH (High Rise)'\n",
    "            WHEN sinker_usage > 25 THEN 'EAST-WEST (Sinker/Run)'\n",
    "            WHEN movement_gap_pct > 75 THEN 'DECEPTIVE (High Break)'\n",
    "            ELSE 'BALANCED'\n",
    "        END as attack_profile,\n",
    "        -- MATCHUP COLUMN 2: ROLE IDENTITY\n",
    "        CASE \n",
    "            WHEN rs.whiff_pct > 75 AND rs.location_plus_pct > 75 THEN 'DOMINANT ACE'\n",
    "            WHEN rs.whiff_pct > 75 AND rs.location_plus_pct < 40 THEN 'POWER ARMS (High Risk)'\n",
    "            WHEN rs.location_plus_pct > 75 AND rs.whiff_pct < 45 THEN 'PITCH TO CONTACT SURGEON'\n",
    "            ELSE 'ROTATION STABILIZER'\n",
    "        END as matchup_role,\n",
    "        -- MATCHUP COLUMN 3: PLATOON RESISTANCE\n",
    "        CASE \n",
    "            WHEN rs.neutrality_pct > 75 THEN 'MATCHUP PROOF'\n",
    "            WHEN rs.neutrality_pct < 35 THEN 'PLATOON SENSITIVE'\n",
    "            ELSE 'STANDARD SPLITS'\n",
    "        END as platoon_identity,\n",
    "        ROUND((perceived_velo_pct * 0.25 + ffour_vaa_pct * 0.25 + whiff_pct * 0.5), 0) as ffour_quality_score,\n",
    "        ROUND((movement_gap_pct * 0.25 + offspeed_vaa_pct * 0.25 + whiff_pct * 0.5), 0) as offspeed_quality_score,   \n",
    "        CASE \n",
    "            WHEN (ffour_vaa_pct > 80 AND ffour_usage < 20) THEN 'UNDERUSED ELITE FASTBALL'\n",
    "            WHEN (bb_vaa_pct > 80 AND bb_usage < 15) THEN 'UNDERUSED ELITE BREAKING'\n",
    "            WHEN (offspeed_vaa_pct > 80 AND offspeed_usage < 15) THEN 'UNDERUSED ELITE OFFSPD'\n",
    "            ELSE 'OPTIMIZED'\n",
    "        END as breakout_potential\n",
    "    FROM ranked_stats rs\n",
    "    JOIN dim_player pn ON rs.pitcher = pn.key_mlbam\n",
    "    ORDER BY stuff_plus_pct DESC;\n",
    "    \"\"\")\n",
    "    df = pd.read_sql(query, engine)\n",
    "\n",
    "    return run_scouting_model(df)\n",
    "\n",
    "# Execute\n",
    "pitcher_archetypes = update_dim_pitcher_archetypes(engine)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85833304",
   "metadata": {},
   "source": [
    "Hitters model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988e6393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ Creating dim_hitter_archetype...\n",
      "   ‚ùå ETL Failed during extraction or loading: name '__file__' is not defined\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sqlalchemy.engine import Engine\n",
    "from sqlalchemy import text\n",
    "from datetime import date, timedelta\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "def create_dim_hitter_archetypes(engine: Engine):\n",
    "    try:\n",
    "        print(\"üíæ Creating dim_hitter_archetype...\")\n",
    "        def run_hitter_scouting_model(df):\n",
    "            \"\"\"\n",
    "            Stabilized Hitter Model: Uses Bayesian-weighted metrics to define \n",
    "            archetypes and calculate grades.\n",
    "            \"\"\"\n",
    "            \n",
    "            # 1. Identity Features (The DNA)\n",
    "            # We use 'stabilized_ev' and 'neutrality_raw' to ensure cluster stability\n",
    "            identity_features = [\n",
    "                'chase_pct_raw', 'zone_swing_raw', 'first_pitch_swing_raw',\n",
    "                'avg_la', 'pull_pct_raw', 'two_strike_contact_raw',\n",
    "                'woba_vs_hard', 'woba_vs_break', 'woba_vs_offspeed',\n",
    "                'neutrality_raw', 'stabilized_ev'\n",
    "            ]\n",
    "            \n",
    "            # 2. Effectiveness Scores (Grade Components)\n",
    "            # Power is now grounded in stabilized EV\n",
    "            df['power_score'] = (\n",
    "                (df['ev_pct'] * 0.50) + \n",
    "                (df['barrel_pct'] * 0.50)\n",
    "            ).round(1)\n",
    "            \n",
    "            # Eye combines discipline with 'Battle' (2-strike) ability\n",
    "            df['discipline_score'] = (\n",
    "                (df['discipline_pct'] * 0.60) + \n",
    "                (df['battle_pct'] * 0.40)\n",
    "            ).round(1)\n",
    "            \n",
    "            # 1. Load the .env file \n",
    "            # Since .env is in the same folder as this script, we can just load it\n",
    "            load_dotenv()\n",
    "\n",
    "            # 2. Get the path from the environment variable\n",
    "            # If it's not found, we provide a 'fallback' default\n",
    "            input_folder = os.getenv('INPUT_DIR', '../input')\n",
    "\n",
    "            # 3. Construct the full paths to your files\n",
    "            # We use abspath to make sure Python doesn't get confused by the current working directory\n",
    "            base_path = os.path.dirname(os.path.abspath(__file__))\n",
    "            scaler_path = os.path.abspath(os.path.join(base_path, input_folder, 'hitter_scaler_v1.pkl'))\n",
    "            model_path = os.path.abspath(os.path.join(base_path, input_folder, 'hitter_model_v1.pkl'))\n",
    "\n",
    "            # 4. Load the files\n",
    "            scaler = joblib.load(scaler_path)\n",
    "            gmm    = joblib.load(model_path)\n",
    "\n",
    "            # 3. Clustering (Archetype Definition)\n",
    "            scaler = StandardScaler()\n",
    "            # Filling NaNs with league average proxies for safety\n",
    "            #scaled_data = scaler.fit_transform(df[identity_features].fillna(df[identity_features].median()))\n",
    "            scaled_data = scaler.transform(df[identity_features].fillna(df[identity_features].median()))\n",
    "            \n",
    "            # 7 Clusters allows for enough nuance (Sluggers, Pests, Specialists, etc.)\n",
    "            gmm = GaussianMixture(n_components=7, random_state=42, n_init=10)\n",
    "            df['hitter_cluster'] = gmm.predict(scaled_data)\n",
    "\n",
    "            # # SAVE THE MODELS (Run once, then comment out)\n",
    "            # joblib.dump(scaler, 'hitter_scaler_v1.pkl')\n",
    "            # joblib.dump(gmm, 'hitter_model_v1.pkl')\n",
    "                        \n",
    "            # 4. Professional Hitter Archetype Mapping\n",
    "            # Note: Validate these against your printed profile table!\n",
    "            hitter_map = {\n",
    "                0: \"Discipline Specialist\",  # Low chase, high walks, moderate power\n",
    "                1: \"Pull-Side Power Slugger\", # High LA, High Pull%, High EV\n",
    "                2: \"Contact-Oriented Pest\",   # High 2-strike contact, low LA, low K%\n",
    "                3: \"All-Fields Technician\",   # Neutrality high, line drive plane\n",
    "                4: \"Aggressive Free-Swinger\", # High first-pitch swing, high chase\n",
    "                5: \"Modern Three-True-Outcome\", # High LA, High Whiff, High EV\n",
    "                6: \"High-Traffic Slap Hitter\" # Low LA, high zone swing, high speed/contact\n",
    "            }\n",
    "            df['hitter_archetype_label'] = df['hitter_cluster'].map(hitter_map)\n",
    "            \n",
    "            # 5. Outlier Detection (Unicorns)\n",
    "            iso = IsolationForest(contamination=0.03, random_state=42)\n",
    "            df['is_hitter_unicorn'] = iso.fit_predict(scaled_data)\n",
    "            \n",
    "            # def profile_hitter_clusters(df):\n",
    "            #     profile_metrics = [\n",
    "            #         'hitter_cluster',\n",
    "            #         # DNA (Identity)\n",
    "            #         'chase_pct_raw', 'zone_swing_raw', 'avg_la', 'pull_pct_raw', 'two_strike_contact_raw',\n",
    "            #         # Results\n",
    "            #         'ev_pct', 'barrel_pct', 'woba_reliability_pct', 'discipline_pct'\n",
    "            #     ]\n",
    "            #     return df[profile_metrics].groupby('hitter_cluster').mean().round(2)\n",
    "\n",
    "            # # Usage: Run this and print the result to see the groups\n",
    "            # hitter_profile_table = profile_hitter_clusters(df)\n",
    "            # print(hitter_profile_table)\n",
    "            \n",
    "            # 5. Overall Grade Calculation\n",
    "            def calculate_scouting_grade(row, mode='hitter'):\n",
    "                \"\"\"\n",
    "                Applies the 20-80 Scouting Scale (Standardized).\n",
    "                A+ = 80 Grade (Generational)\n",
    "                A  = 70 Grade (Elite All-Star)\n",
    "                B  = 60 Grade (Plus)\n",
    "                C  = 50 Grade (Average)\n",
    "                \"\"\"\n",
    "                # 1. Get the combined Z-score from SQL\n",
    "                z_score = row.get('combined_scouting_z', 0)\n",
    "                \n",
    "                # 2. Determine sample size based on player type\n",
    "                if mode == 'hitter':\n",
    "                    sample = row.get('total_pitches_faced', 0)\n",
    "                else:\n",
    "                    sample = row.get('total_pitches_thrown', 0)\n",
    "                    \n",
    "                # 3. Apply Reliability Penalty (Prevents small-sample \"fluke\" A's)\n",
    "                if sample < 500:\n",
    "                    z_score -= 1.0  # Moves a lucky 'A' down to a 'B' or 'C'\n",
    "                elif sample < 1000:\n",
    "                    z_score -= 0.4  # Slight penalty for unproven consistency\n",
    "                    \n",
    "                # 4. Universal Grade Thresholds\n",
    "                if z_score >= 2.4:\n",
    "                    return 'A+'\n",
    "                elif z_score >= 1.5:\n",
    "                    return 'A'\n",
    "                elif z_score >= 0.6:\n",
    "                    return 'B'\n",
    "                elif z_score >= -0.5:\n",
    "                    return 'C'\n",
    "                else:\n",
    "                    return 'D/F'\n",
    "\n",
    "            # Usage:\n",
    "            df['overall_grade'] = df.apply(lambda x: calculate_scouting_grade(x, mode='hitter'), axis=1)\n",
    "\n",
    "\n",
    "            # # 6. Scouting Report Generation\n",
    "            # def generate_hitter_report(row):\n",
    "            #     tags = []\n",
    "                \n",
    "            #     # Logic for tags\n",
    "            #     if row['power_score'] >= 90: tags.append(\"üî• ELITE POWER\")\n",
    "            #     if row['discipline_score'] >= 90: tags.append(\"üéØ DISCIPLINE MASTER\")\n",
    "            #     if row['two_strike_identity'] == 'ELITE SPOILER': tags.append(\"ü¶ü PEST\")\n",
    "            #     if row['neutrality_pct'] > 85: tags.append(\"üõ°Ô∏è MATCHUP PROOF\")\n",
    "            #     if row['is_hitter_unicorn'] == -1: tags.append(\"ü¶Ñ UNICORN\")\n",
    "\n",
    "            #     # Vertical Profile Analysis\n",
    "            #     v_desc = f\"Attacks the {row['vertical_profile']}.\"\n",
    "                \n",
    "            #     # Build Summary\n",
    "            #     conf_prefix = \"PROVISIONAL: \" if \"PROVISIONAL\" in row['data_confidence'] else \"\"\n",
    "            #     header = f\"[{row['overall_grade']}] {conf_prefix}{row['full_name']} ({row['hand']})\"\n",
    "                \n",
    "            #     tag_str = \" | \".join(tags)\n",
    "            #     body = f\"{v_desc} Handles {row['swing_plane']} path. \"\n",
    "                \n",
    "            #     # Platoon Insight\n",
    "            #     if row['neutrality_pct'] < 30:\n",
    "            #         body += f\"Extreme platoon splits detected; high risk against {row['hand']}HP. \"\n",
    "            #     else:\n",
    "            #         body += \"Balanced splits make them difficult to platoon against. \"\n",
    "\n",
    "            #     return tag_str, f\"{header}\\nTAGS: {tag_str}\\nSUMMARY: {body}\"\n",
    "\n",
    "            # df['hitter_tags'], df['hitter_summary'] = zip(*df.apply(generate_hitter_report, axis=1))\n",
    "            \n",
    "            # return df\n",
    "            \n",
    "            # 6. Scouting Report Generation (Updated for new labels)\n",
    "            def generate_hitter_report(row):\n",
    "                tags = []\n",
    "                header = f\"[{row['overall_grade']} {row['hitter_archetype_label']}] ({row['hand']})\"\n",
    "                \n",
    "                if row['power_score'] >= 90: tags.append(\"üî• ELITE POWER\")\n",
    "                if row['discipline_score'] >= 90: tags.append(\"üéØ DISCIPLINE MASTER\")\n",
    "                if row['two_strike_identity'] == 'ELITE SPOILER': tags.append(\"ü¶ü PEST\")\n",
    "                if row['is_hitter_unicorn'] == -1: tags.append(\"ü¶Ñ UNICORN\")\n",
    "\n",
    "                tag_str = \" | \".join(tags)\n",
    "                body = f\"Tactically identified as a {row['hitter_archetype_label']}. \"\n",
    "                body += f\"Attacks the {row['vertical_profile']} with a {row['swing_plane']} path. \"\n",
    "                \n",
    "                return tag_str, f\"{header}\\nTAGS: {tag_str}\\nSUMMARY: {body}\"\n",
    "\n",
    "                df['hitter_tags'], df['hitter_summary'] = zip(*df.apply(generate_hitter_report, axis=1))\n",
    "                \n",
    "                return df\n",
    "\n",
    "        def update_dim_hitter_archetypes(engine):\n",
    "            \"\"\"\n",
    "            SQL to extract the necessary metrics for the Python model.\n",
    "            \"\"\"\n",
    "            query = text(\"\"\"\n",
    "            WITH constants AS (\n",
    "                SELECT \n",
    "                    0.312 as lg_woba,    -- Actual 2024-25 league average\n",
    "                    88.4  as lg_ev,      -- Current league avg exit velocity\n",
    "                    0.045 as woba_sd,    -- Fixed Standard Deviation for wOBA\n",
    "                    3.8   as ev_sd,      -- Fixed Standard Deviation for Exit Velocity\n",
    "                    0.040 as barrel_sd,  -- Fixed Standard Deviation for Barrel Rate\n",
    "                    500   as m_woba,     -- Reliability threshold for wOBA\n",
    "                    150   as m_ev        -- Reliability threshold for EV\n",
    "            ),\n",
    "            attack_zone_stats AS (\n",
    "                SELECT \n",
    "                    p.*,\n",
    "                    CASE WHEN p.strikes = 2 THEN 1 ELSE 0 END as is_two_strike,\n",
    "                    CASE WHEN p.inning >= 7 AND ABS(p.bat_score - p.fld_score) <= 2 THEN 1 ELSE 0 END as is_clutch,\n",
    "                    CASE WHEN p.zone > 9 AND p.description IN ('swinging_strike', 'foul', 'hit_into_play', 'swinging_strike_blocked') THEN 1 ELSE 0 END as is_chase,\n",
    "                    CASE WHEN p.zone <= 9 AND p.description IN ('swinging_strike', 'foul', 'hit_into_play', 'swinging_strike_blocked') THEN 1 ELSE 0 END as is_zone_swing,\n",
    "                    CASE \n",
    "                        WHEN (p.stand = 'R' AND p.hc_x < 125) OR (p.stand = 'L' AND p.hc_x > 125) THEN 1 \n",
    "                        ELSE 0 \n",
    "                    END as is_pull\n",
    "                FROM fact_statcast_pitches p\n",
    "            ),\n",
    "            hitter_base_stats AS (\n",
    "                SELECT \n",
    "                    p.batter,\n",
    "                    p.stand AS bat_side,\n",
    "                    COUNT(*) AS total_pitches_faced,\n",
    "                    COUNT(CASE WHEN p.type = 'X' THEN 1 END) as balls_in_play,\n",
    "                    -- Bayesian Stabilized Metrics\n",
    "                    ((SUM(p.woba_value) + (MAX(c.m_woba) * MAX(c.lg_woba))) / (COUNT(*) + MAX(c.m_woba))) as stabilized_woba,\n",
    "                    ((SUM(p.launch_speed) + (MAX(c.m_ev) * MAX(c.lg_ev))) / (NULLIF(COUNT(CASE WHEN p.type = 'X' THEN 1 END), 0) + MAX(c.m_ev))) as stabilized_ev,\n",
    "                    -- Raw Stats for Clustering & Context\n",
    "                    AVG(CASE WHEN p.pitch_type IN ('FF', 'FA', 'FT', 'SI', 'FC') THEN p.woba_value END) AS woba_vs_hard,\n",
    "                    AVG(CASE WHEN p.pitch_type IN ('SL', 'ST', 'CU', 'KC', 'SV', 'CS', 'GY', 'KN') THEN p.woba_value END) AS woba_vs_break,\n",
    "                    AVG(CASE WHEN p.pitch_type IN ('CH', 'FS', 'FO', 'SC', 'EP') THEN p.woba_value END) AS woba_vs_offspeed,            \n",
    "                    ROUND(SUM(p.is_chase)::numeric / NULLIF(SUM(CASE WHEN p.zone > 9 THEN 1 ELSE 0 END), 0) * 100, 1) as chase_pct_raw,\n",
    "                    ROUND(SUM(p.is_zone_swing)::numeric / NULLIF(SUM(CASE WHEN p.zone <= 9 THEN 1 ELSE 0 END), 0) * 100, 1) as zone_swing_raw,\n",
    "                    ROUND(SUM(CASE WHEN p.balls = 0 AND p.strikes = 0 AND p.description IN ('swinging_strike', 'foul', 'hit_into_play') THEN 1 ELSE 0 END)::numeric / \n",
    "                        NULLIF(SUM(CASE WHEN p.balls = 0 AND p.strikes = 0 THEN 1 ELSE 0 END), 0) * 100, 1) as first_pitch_swing_raw,\n",
    "                    ROUND(SUM(CASE WHEN p.description IN ('swinging_strike', 'swinging_strike_blocked') THEN 1 ELSE 0 END)::numeric / \n",
    "                        NULLIF(SUM(CASE WHEN p.description IN ('swinging_strike', 'foul', 'hit_into_play') THEN 1 ELSE 0 END), 0) * 100, 1) as whiff_pct_hitter,      \n",
    "                    AVG(p.launch_speed) AS avg_ev,\n",
    "                    AVG(p.launch_angle) AS avg_la,\n",
    "                    SUM(CASE WHEN p.launch_speed_angle = 6 THEN 1 ELSE 0 END)::float / NULLIF(SUM(CASE WHEN p.type = 'X' THEN 1 ELSE 0 END), 0) AS barrel_rate_raw,\n",
    "                    AVG(CASE WHEN p.plate_z > (p.sz_top + p.sz_bot)/2 THEN p.woba_value END) as woba_high_raw,\n",
    "                    AVG(CASE WHEN p.plate_z <= (p.sz_top + p.sz_bot)/2 THEN p.woba_value END) as woba_low_raw,      \n",
    "                    ROUND(SUM(CASE WHEN p.is_two_strike = 1 AND p.description IN ('foul', 'hit_into_play') THEN 1 ELSE 0 END)::numeric / \n",
    "                        NULLIF(SUM(CASE WHEN p.is_two_strike = 1 AND p.description IN ('swinging_strike', 'foul', 'hit_into_play') THEN 1 ELSE 0 END), 0) * 100, 1) as two_strike_contact_raw,       \n",
    "                    AVG(CASE WHEN p.is_clutch = 1 THEN p.woba_value END) as clutch_woba_raw,\n",
    "                    100 - (ABS(COALESCE(AVG(CASE WHEN p.p_throws = 'L' THEN p.woba_value END), 0.320) - \n",
    "                            COALESCE(AVG(CASE WHEN p.p_throws = 'R' THEN p.woba_value END), 0.320)) * 100) as neutrality_raw,\n",
    "                    ROUND(SUM(p.is_pull)::numeric / NULLIF(SUM(CASE WHEN p.type = 'X' THEN 1 ELSE 0 END), 0) * 100, 1) as pull_pct_raw\n",
    "                FROM attack_zone_stats p, constants c\n",
    "                GROUP BY p.batter, p.stand\n",
    "                HAVING COUNT(*) > 150\n",
    "            ),\n",
    "            hitter_ranked AS (\n",
    "                SELECT \n",
    "                    hb.*,\n",
    "                    -- UNIVERSAL Z-SCORE CALCULATION\n",
    "                    (hb.stabilized_ev - 88.5) / 3.5 as ev_z,\n",
    "                    (hb.stabilized_woba - 0.320) / 0.045 as woba_z,\n",
    "                    (hb.barrel_rate_raw - 0.075) / 0.040 as barrel_z,       \n",
    "                    -- Percentiles (kept for existing columns)\n",
    "                    ROUND((PERCENT_RANK() OVER (ORDER BY avg_ev))::numeric, 2) * 100 AS ev_pct,\n",
    "                    ROUND((PERCENT_RANK() OVER (ORDER BY barrel_rate_raw))::numeric, 2) * 100 AS barrel_pct,\n",
    "                    ROUND((PERCENT_RANK() OVER (ORDER BY stabilized_woba))::numeric, 2) * 100 AS woba_reliability_pct,\n",
    "                    ROUND((1 - PERCENT_RANK() OVER (ORDER BY chase_pct_raw))::numeric, 2) * 100 AS discipline_pct,     \n",
    "                    ROUND((PERCENT_RANK() OVER (ORDER BY first_pitch_swing_raw))::numeric, 2) * 100 AS aggression_pct,\n",
    "                    ROUND((PERCENT_RANK() OVER (ORDER BY woba_high_raw))::numeric, 2) * 100 AS high_ball_pct,\n",
    "                    ROUND((PERCENT_RANK() OVER (ORDER BY woba_low_raw))::numeric, 2) * 100 AS low_ball_pct,\n",
    "                    ROUND((PERCENT_RANK() OVER (ORDER BY pull_pct_raw))::numeric, 2) * 100 AS pull_pct,      \n",
    "                    ROUND((PERCENT_RANK() OVER (ORDER BY two_strike_contact_raw))::numeric, 2) * 100 AS battle_pct,\n",
    "                    ROUND((PERCENT_RANK() OVER (ORDER BY clutch_woba_raw))::numeric, 2) * 100 AS clutch_pct,\n",
    "                    ROUND((PERCENT_RANK() OVER (ORDER BY neutrality_raw))::numeric, 2) * 100 as neutrality_pct,       \n",
    "                    ROUND((PERCENT_RANK() OVER (ORDER BY woba_vs_hard))::numeric, 2) * 100 as woba_hard_pct,\n",
    "                    ROUND((PERCENT_RANK() OVER (ORDER BY woba_vs_break))::numeric, 2) * 100 as woba_break_pct,\n",
    "                    ROUND((PERCENT_RANK() OVER (ORDER BY woba_vs_offspeed))::numeric, 2) * 100 as woba_offspeed_pct\n",
    "                FROM hitter_base_stats hb\n",
    "            )\n",
    "            SELECT \n",
    "                CONCAT(pn.first_name_chadwick, ' ', pn.last_name_chadwick) AS full_name,\n",
    "                hr.bat_side as hand,\n",
    "                hr.*,\n",
    "                -- UNIVERSAL ANCHOR: Matches Pitcher Model Scale\n",
    "                ((hr.woba_z * 0.5) + (hr.barrel_z * 0.3) + (hr.ev_z * 0.2)) as combined_scouting_z,\n",
    "                CASE \n",
    "                    WHEN total_pitches_faced > 1500 THEN 'VERIFIED ELITE SAMPLE'\n",
    "                    WHEN total_pitches_faced > 600 THEN 'STABILIZED'\n",
    "                    ELSE 'PROVISIONAL (Small Sample)'\n",
    "                END as data_confidence,\n",
    "                CASE \n",
    "                    WHEN avg_la > 18 THEN 'UPPERCUT (Flyball)'\n",
    "                    WHEN avg_la < 8 THEN 'DOWNWARD (Groundball)'\n",
    "                    ELSE 'LEVEL (Line Drive)'\n",
    "                END AS swing_plane,\n",
    "                CASE \n",
    "                    WHEN battle_pct > 80 THEN 'ELITE SPOILER'\n",
    "                    WHEN battle_pct < 25 THEN 'FREE SWINGER'\n",
    "                    ELSE 'STANDARD'\n",
    "                END AS two_strike_identity,\n",
    "                CASE\n",
    "                    WHEN high_ball_pct > 75 AND low_ball_pct < 40 THEN 'HIGH-BALL HUNTER'\n",
    "                    WHEN low_ball_pct > 75 AND high_ball_pct < 40 THEN 'LOW-BALL GOLFER'\n",
    "                    ELSE 'ALL-ZONE THREAT'\n",
    "                END AS vertical_profile\n",
    "            FROM hitter_ranked hr\n",
    "            JOIN dim_player pn ON hr.batter = pn.key_mlbam\n",
    "            ORDER BY combined_scouting_z DESC;\n",
    "            \"\"\")\n",
    "            df = pd.read_sql(query, engine)\n",
    "            \n",
    "            return run_hitter_scouting_model(df)\n",
    "\n",
    "        # Execute function\n",
    "        hitter_archetypes = update_dim_hitter_archetypes(engine)\n",
    "\n",
    "        # Add the calculation_date\n",
    "        hitter_archetypes['calculation_date'] = datetime.now()\n",
    "\n",
    "        # Load to SQL\n",
    "        hitter_archetypes.to_sql(\n",
    "        'dim_hitter_archetypes', \n",
    "        engine, \n",
    "        if_exists='replace',\n",
    "        index=False, \n",
    "        chunksize=5000\n",
    "        )\n",
    "        \n",
    "        print(f\"   ‚úÖ Successfully added {len(hitter_archetypes)} new rows of data.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå ETL Failed during extraction or loading: {e}\")\n",
    "        \n",
    "#create_dim_hitter_archetypes(engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "858fab06",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '__file__' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Add source directory to path\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m app_dir \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;18;43m__file__\u001b[39;49m)\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m      9\u001b[0m source_dir \u001b[38;5;241m=\u001b[39m app_dir\u001b[38;5;241m.\u001b[39mparent\n\u001b[0;32m     10\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mstr\u001b[39m(source_dir))\n",
      "\u001b[1;31mNameError\u001b[0m: name '__file__' is not defined"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "from sqlalchemy.engine import Engine\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Add source directory to path\n",
    "app_dir = Path(__file__).parent.parent\n",
    "source_dir = app_dir.parent\n",
    "sys.path.insert(0, str(source_dir))\n",
    "\n",
    "from connection_engine import create_connection_postgresql\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables - check multiple locations\n",
    "env_paths = [\n",
    "    source_dir / \"utils\" / \".env\",  # Original location: Source/utils/.env\n",
    "    app_dir / \"utils\" / \".env\",      # App location: Source/app/utils/.env\n",
    "    source_dir / \".env\"              # Fallback: Source/.env\n",
    "]\n",
    "\n",
    "env_loaded = False\n",
    "for env_path in env_paths:\n",
    "    if env_path.exists():\n",
    "        load_dotenv(dotenv_path=str(env_path), override=True)\n",
    "        env_loaded = True\n",
    "        break\n",
    "\n",
    "# If no .env file found, try default load_dotenv (current directory)\n",
    "if not env_loaded:\n",
    "    load_dotenv(override=True)\n",
    "    \n",
    "\n",
    "def get_db_engine() -> Engine:\n",
    "    \"\"\"Get or create database engine\"\"\"\n",
    "    if st.session_state.db_engine is None:\n",
    "        try:\n",
    "            # Ensure .env is loaded before creating connection (check multiple locations)\n",
    "            env_paths = [\n",
    "                source_dir / \"utils\" / \".env\",  # Source/utils/.env\n",
    "                app_dir / \"utils\" / \".env\",      # Source/app/utils/.env\n",
    "                source_dir / \".env\"              # Source/.env\n",
    "            ]\n",
    "            \n",
    "            env_loaded = False\n",
    "            for env_path in env_paths:\n",
    "                if env_path.exists():\n",
    "                    load_dotenv(dotenv_path=str(env_path), override=True)\n",
    "                    env_loaded = True\n",
    "                    break\n",
    "            \n",
    "            if not env_loaded:\n",
    "                load_dotenv(override=True)  # Try default location\n",
    "            \n",
    "            st.session_state.db_engine = create_connection_postgresql()\n",
    "        except KeyError as e:\n",
    "            # Provide helpful error message with possible locations\n",
    "            possible_locations = [\n",
    "                str(source_dir / \"utils\" / \".env\"),\n",
    "                str(app_dir / \"utils\" / \".env\"),\n",
    "                str(source_dir / \".env\")\n",
    "            ]\n",
    "            st.error(\n",
    "                f\"Database connection error: Missing environment variable '{e}'. \"\n",
    "                f\"Please check your .env file. Expected locations:\\n\"\n",
    "                f\"- {possible_locations[0]}\\n\"\n",
    "                f\"- {possible_locations[1]}\\n\"\n",
    "                f\"- {possible_locations[2]}\"\n",
    "            )\n",
    "            return None\n",
    "        except Exception as e:\n",
    "            st.error(f\"Database connection error: {e}\")\n",
    "            return None\n",
    "    return st.session_state.db_engine\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ccff58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully imported connection_engine\n",
      "‚úÖ Loaded .env from: C:\\Development\\python_projects\\Code\\projects\\baseball_analytics\\Sandbox\\.env\n",
      "Connecting to database...\n",
      "üõú  Connecting to the database...\n",
      "   ‚úÖ Database connection established.\n",
      "‚úÖ Database connection successful!\n",
      "üîó Connection test: Valid\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "from sqlalchemy.engine import Engine\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 1. HANDLE DIRECTORY PATHS (Notebook compatible)\n",
    "try:\n",
    "    # If running as a .py script\n",
    "    base_path = Path(__file__).resolve().parent\n",
    "except NameError:\n",
    "    # If running in a Jupyter Notebook (.ipynb)\n",
    "    base_path = Path(os.getcwd()).resolve()\n",
    "\n",
    "# Adjust these based on your actual folder structure\n",
    "# Based on your previous code: Source/app/pages/...\n",
    "app_dir = base_path \n",
    "source_dir = app_dir.parent\n",
    "sys.path.insert(0, str(source_dir))\n",
    "\n",
    "# 2. IMPORT DATABASE UTILS\n",
    "# Note: Ensure connection_engine.py is in your source_dir\n",
    "try:\n",
    "    from connection_engine import create_connection_postgresql\n",
    "    print(\"‚úÖ Successfully imported connection_engine\")\n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import Error: {e}\")\n",
    "    print(f\"Current sys.path: {sys.path[0]}\")\n",
    "\n",
    "# 3. LOAD ENVIRONMENT VARIABLES\n",
    "env_paths = [\n",
    "    source_dir / \"utils\" / \".env\",\n",
    "    app_dir / \"utils\" / \".env\",\n",
    "    source_dir / \".env\",\n",
    "    base_path / \".env\"\n",
    "]\n",
    "\n",
    "env_loaded = False\n",
    "for env_path in env_paths:\n",
    "    if env_path.exists():\n",
    "        load_dotenv(dotenv_path=str(env_path), override=True)\n",
    "        print(f\"‚úÖ Loaded .env from: {env_path}\")\n",
    "        env_loaded = True\n",
    "        break\n",
    "\n",
    "if not env_loaded:\n",
    "    print(\"‚ö†Ô∏è No .env file found in search paths. Falling back to default.\")\n",
    "    load_dotenv(override=True)\n",
    "\n",
    "# 4. DATABASE ENGINE FUNCTION (Modified for Notebook testing)\n",
    "# We use a global variable instead of st.session_state\n",
    "_DB_ENGINE = None\n",
    "\n",
    "def get_db_engine() -> Engine:\n",
    "    \"\"\"Get or create database engine (Notebook version)\"\"\"\n",
    "    global _DB_ENGINE\n",
    "    \n",
    "    if _DB_ENGINE is None:\n",
    "        try:\n",
    "            print(\"Connecting to database...\")\n",
    "            _DB_ENGINE = create_connection_postgresql()\n",
    "            print(\"‚úÖ Database connection successful!\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Database connection error: {e}\")\n",
    "            return None\n",
    "    return _DB_ENGINE\n",
    "\n",
    "# 5. TEST THE CONNECTION\n",
    "if __name__ == \"__main__\":\n",
    "    engine = get_db_engine()\n",
    "    if engine:\n",
    "        try:\n",
    "            with engine.connect() as conn:\n",
    "                print(\"üîó Connection test: Valid\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Connection test failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PY_312_DEVELOPMENT",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
